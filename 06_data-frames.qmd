
# Intro to dataframes

```{r}
#| label: set-up
#| include: false

# set options
knitr::opts_chunk$set(
  tidy = FALSE, 
  message = FALSE,
	warning = FALSE)

options(htmltools.dir.version = FALSE)

```


**Learning Objectives**

After completing this lab you should be able to 

* read a data from a csv or tab-delimited file into R as a `data.frame`.
* describe what a `data.frame` is.
* inspect the contents of a data frame to summarize the content.
* write a `data.frame` to file.

For each of our modules we will have a project-folder with an `Rproject`, `*.qmd`-files, and sub-directories for data, scripts, and results as described in our `Rproject` Tutorial. You should have a directory on your Desktop or Documents folder on your laptop (name it something like `bi349`) as a home directory for all of our project folders this semester. 

[If you have not already, go ahead and download the research compendium for this module using this link](https://drive.google.com/drive/folders/1Sh4mtvdii1k_vU4-mfvgIGwJsZvo8MOt?usp=sharing), make sure the directory is unzipped and move it to your `bi328` directory. You can open the `Rproj` for this module either by double clicking on it which will launch `Rstudio` or by opening `Rstudio` and then using `File > Open Project` or by clicking on the `Rproject` icon in the top right of your program window and selecting `Open Project`. 

Once you have opened a project you should see the project name in the top right corner^[Pro tip: If you run into issues where a quarto document won't render or file paths aren't working (especially if things were working previously) one of your first steps should be to double check that the correct `Rproj` is loaded.].

There should be a document names `06_data-frames.qmd` in your project directory. Use that file to work through this tutorial - you will hand in your rendered ("knitted") `quarto` file as your homework assignment. So, first thing in the `YAML` header, change the author to your name. You will use this `quarto` document to record your answers. Remember to use comments to annotate your code; at minimum you should have one comment per code set^[You should do this whether you are adding code yourself or using code from our manual, even if it isn't commented in the manual... especially when the code is already included for you, add comments to describe how the function works/what it does as we introduce it during the participatory coding session so you can refer back to it.] you may of course add as many comments as you need to be able to recall what you did]. Similarly, take notes in the document as we discuss discussion/reflection questions but make sure that you go back and clean them up for "public consumption".

Let's start by loading the packages we will need for this activity.

```{r}

# load libraries
library(tidyverse)
library(knitr)

```

## Reading data into R

`library(tidyverse)` is actually loading a set of packages used for data science that share a common design philosophy, and "grammar". One of the packages we loaded is called `readr` which contains functions for reading in and parsing files.

At the end of Chapter 5 when we were exploring the usefulness of spreadsheets for data entry and management. You would have export the excel file with the catch data as `*.csv` (comma delimited) and as a tab-delimited text file (`*.txt` or `*.tsv` if exporting from google sheets).


::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Give it a whirl

Use `?read_delim` to pull up the help page for the function we will using and explore the arguments. How do you think we read in our csv file?

:::


::: {.callout-tip collapse=true}

## Solution

`read_delim` has two required arguments, the **path** (`data/longline_catchdata.csv`) which tells `R` where your file is located and the **delimiter** in this case a comma (`,`) tells `R` how columns are separated from each other.

```{r eval=FALSE}

# read catch data
catch <- read_delim("data/longline_catchdata.csv", delim = ",")

```

As we access data sets that are not as "clean" as the one we have here, you will find that some of the other arguments apart from specifying the delimiter will come in handy - but don't worry about those for now.

:::

Execute the code. If you look over in your environment pane you should now see the object `catch`. This is your dataframe. Click on it, you should see the command `View(catch)` in your console and a tab `catch` appear in your top left pane.

::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Give it a whirl

Based on how you read in the csv file how would you read in the tab-delimited version?

:::


::: {.callout-tip collapse=true}

## Solution

We need to change delimiter to indicate that it is tab-delimited. In this case, we would specify it as `\t` is "computer" for tab. 
```{r}

# read catch data
catch <- read_delim("data/longline_catchdata.txt", delim = "\t")

```

Another delimiter you might encounter are white space (`" "`) but technically it could be anything. 

:::

When you loaded your data set you should have seem an message along the lines of `parsed with column specification` and information on the number of columns and their data type. What this means is that `read_delim()` looks through the first 1,000 rows for each column and guesses the data type - usually this works pretty well though occasionally we will have to either specify the data types manually using the `col_types` argument or convert the data type later on.

Let's use `class()` to figure out what type of object we are dealing with.

```{r}

class(catch)

```

You can see that this object actually has multiple classes attached to it. The last one in the list is `data.frame` which is the standard format for (rectangular) tabular data.

Recall from our tutorial on vectors that each column in a `data.frame` is an atomic vector, they must all have the same length (hence, "rectangular") and each must contain the same data type (characters, integers, ...).

The other three have the same basic properties as a `data.frame` along with some additional features. The `tbl` (pronounced tibble) was designed to be at the center of the `tidyverse` which means that when you use `readr` functions it will automatically be read in as a tibble and `data.frame`. If you do some exploring and/or troubleshooting on the web you will likely run into tibbles but for our intents of purposes we will use `data.frame` when talking about data in a rectangual, tabular shape.


## Inspecting your `data.frame`

You have of course already peaked at the data when you opened it in excel to export it in a text-based format. But not infrequently, you may access data from a public database or a collaborator might share a text-based formatted data set with you and the first thing that you are going to want to do is figure out what information is contained in the data set.

::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Consider this

You know that this data set is the result from a long-lining survey and you're now basically an expert in formatting data - what information do you expect to find in this data set? How would you expect it to be formatted if this is a 'tidy data set'.

:::


::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Give it a whirl

There are several functions that you can use for a preliminary inspection of your data, including figuring out what dimensions it has and what information is contained in your data set.

Call the following functions on your object and describe what each function does, what information you can learn about your data set from executing them, and when these could be helpful. 

* `dim()`, `nrow()`, `ncol()`
* `str()`, `summary()`
* `head()`, `tail()`
* `colnames()`, `rownames()`
* `View()`

:::


## Subsetting your dataframe

Similar to the way we were able to subset vectors, we can do the same things with our `data.frames` using rows and columns as our "coordinates" in the format `data_frame[row_index, column_index]`.


### Using coordinates

So for example we can extract the first row and column from our `catch` object as

```{r}

catch[1, 1]

```


::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Give it a whirl

How would you extract the 5th column from the third row?

:::


You can select multiple rows or columns by specifying them using a vector.

```{r}

catch[c(1, 20, 40), c(2, 5)]

```

You can also select a set of adjacent rows (columns) using `:` as so

```{r}

catch[500:505, 2:5]

```

You can exclude indices using `-`

```{r}

catch[1:5, -1]

```

You can select all columns of a given row by leaving the column index blank; for example if we want to extract the first row.

```{r}

catch[1, ]

```


::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Give it a whirl

How would you extract the entire 5th column?

:::


::: {.callout-tip collapse=true}

## Solution

There are quite a few ways to do this: 

* you can use indices by number (as we have done up until this point)
* instead of index numbers you can use the column name

Here are two options using indices:

```{r}

catch[, 1]

catch[1]

```

Instead of using indices you can also call their column names directly - both of these options will return a `data.frame`.

```{r}

catch["Site"]

catch[, "Site"]

```

:::

### Extracting columns as vectors

Using `[]` will always return a subset of your dataframe as a data frame. Occassionally, we might want to extract the column as a vector. You can do this using square brackets `[[]]` or `$`.

```{r}

catch[["Site"]]

catch$Site

```

::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Give it a whirl

Create a vector of all the species in the data set called `species`.

:::


If you call the vector by typing its name (`species`) in the console you will notice that it repeats the species names.

::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Give it a whirl

Execute the following code chunk and describe what this function does:

```{r}
#| eval: false

unique(species)

```

:::


Using indices might seem a little bit clunky, e.g. you have to know which column and row is which by position but it has its practical applications and is computationally very fast. For most of our data wrangling we will be using functions from the tidyverse packages `dplyr` and `tidyr` which work a little bit more intuitively.


## Write `data.frame` to file

Frequently, we will process raw data sets and then need to write intermediate or final results to file, for example to share them with collaborators. Here, the `readr` packages comes in handy. 

::: {.callout-note icon=false}

## {{< fa clipboard-question >}}   Give it a whirl

Create a subset of our data set consisting of the first 100 rows and containing information on the species, sex and fork length. Then use the help page for the function `write_delim()` to figure out how to write out a tab-delimited file into your `data` folder.

:::
