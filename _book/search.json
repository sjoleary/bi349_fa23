[
  {
    "objectID": "10_relational-data.html#composition-of-elasmobranch-communities-compare-across-sites",
    "href": "10_relational-data.html#composition-of-elasmobranch-communities-compare-across-sites",
    "title": "10  Relational data",
    "section": "10.1 Composition of elasmobranch communities compare across sites",
    "text": "10.1 Composition of elasmobranch communities compare across sites\nLet’s start by reading in the data set we will use for this analysis3.3 This is a data set that has been cleaned up to contain only the elasmobranchs caught during the survey since that is the taxonomic group we are interested in\n\nelasmos &lt;- read_delim(\"data/longline_elasmobranchs.txt\", delim = \"\\t\")\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nProduce a table that contains the number of times a species was caught at each site and overall during the long-lining survey and give a brief description of the pattern(s) you see. Briefly, compare the list of species that were caught to the species identified in the longterm TWPD gill net monitoring program.\n\n\n\n\n\n\n\n\n Did it!\n\n\n\n[Your answer here]\n\n\nYour table should look something like this.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies\nAransas_Bay\nCorpus_Christi_Bay\nRedfish_Bay\nTotal\n\n\n\n\nCarcharhinus_brevipinna\n12\n46\n12\n70\n\n\nCarcharhinus_leucas\n3\n4\n1\n8\n\n\nCarcharhinus_limbatus\n1\n1\n0\n2\n\n\nCarcharhinus_porosus\n0\n1\n0\n1\n\n\nHypanus_americanus\n3\n1\n7\n11\n\n\nHypanus_sabina\n9\n2\n0\n11\n\n\nRhinoptera_bonasus\n0\n0\n1\n1\n\n\nRhizoprionodon_terraenovae\n1\n5\n8\n14\n\n\nSphyrna_lewini\n0\n4\n0\n4\n\n\nSphyrna_tiburo\n1\n18\n16\n35\n\n\n\nTable 10.1: Number of individuals per caught per site and overall across all sites and years.\n\n\n\n\n\n\n\n\nProtip\n\n\n\nYou can use replace(is.na(.), 0) to replace NA values in all columns with a 0.\n\n\nWe are not only interested in which species are observed at each site, we also want to know what at what life stages different species are using the estuaries. Typically, we can classify sharks as young-of-the-year (YOY), juveniles (JUV), or mature (MAT). There are ways to observe this in the field, for example YOY can be identified using their umbilical scar and in male sharks whether or not the claspers are calcified is an indication of maturity.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nDetermine how many individuals have information on their life history stage.\n\n\n\n\n\n\n\n\n Did it!\n\n\n\n[Your answer here]\n\n\nAnother way to determine the life history stage is to used previously information on length-at-maturity and how quickly YOY grow during their first year of life. This information is species-specific and has been determined for various species using life-history studies that rely on data sets that contain information on size, level of maturity and age4.4 Sharks can be aged using their vertebrae similar to how we can use growth rings on trees to age them.\nFor example, (Carlson and Baremore 2005) determined the following length/history stage relationships for spinner sharks (C. brevipinna)\n\nCarlson, John K., and Ivy Baremore. 2005. “Growth Dynamics of the Spinner Shark (Carcharhinus Brevipinna) Off the United States Southeast and Gulf of Mexico Coasts: A Comparison of Methods.” Fishery Bulletin 103 (2). https://aquadocs.org/handle/1834/26223.\n\nYOY\n\nfemales &lt; 844mm\nmales &lt; 812mm\n\nJuveniles\n\nfemales 844 - 1360mm\nmales 812 - 1380mm\n\nmature (adults)\n\nfemales &gt; 1360 mm\nmales &gt; 1380 mm\n\n\nWhile (Neer, Thompson, and Carlson 2005) published these details for bull sharks (C. leucas)\n\nNeer, J. A., B. A. Thompson, and John K. Carlson. 2005. “Age and Growth of Carcharhinus Leucas in the Northern Gulf of Mexico: Incorporating Variability in Size at Birth - Neer - 2005 - Journal of Fish Biology - Wiley Online Library.” Journal of Fish Biology 67 (2): 370–83. https://onlinelibrary.wiley.com/doi/full/10.1111/j.0022-1112.2005.00743.x.\n\nYOY\n\nfemales &lt; 700mm\nmales &lt; 700mm\n\nJuveniles\n\nfemales 700 - 2250mm\nmales 700 - 2100mm\n\nmature (adults)\n\nfemales &gt; 2250mm\nmales &gt; 2100mm\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nFirst, conceptually describe how you could add this information to your data sheet in excel as a new column called Estimated_Stage.\n\n\nNow, let’s consider how we could use our data wrangling skills to add a new column Estimated_Stage that contains life history stage based on length estimates. Let’s first work this out for the two species above to keep it simple.\nWhen confronted with a more complex problems like this it can be helpful to first walk through the individual steps necessary5.5 Many people find it helpful to write things out in ‘pseudo-code’ first and then work out what the code needs to look like for the specific language they are working in\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly outline what you think our approach should look like - even if you don’t know the functions you need to achieve this.\n\n\nThere are two approaches we can take.\n\n\n\n\n\n\nSolution 1\n\n\n\n\n\nThe first solution involves sub-setting your data.frame using filter() to contain only individuals that fulfill the conditions of specific length ranges that fit the ranges above for each life history stage and the add a new column with the correctly assigned life history stage6.\n\n# C. brevipinna, Carlson & Baremore 2005\n\nC.brevipinna_YOY &lt;- filter(elasmos, Species==\"Carcharhinus_brevipinna\" & Sex==\"M\" & FL&lt;=812 | Species==\"Carcharhinus_brevipinna\" & Sex==\"F\" & FL&lt;=844 | Species==\"Carcharhinus_brevipinna\" & Sex==\"U\" & FL&lt;=844) %&gt;%\n  mutate(Estimated_Stage=\"YOY\")\n\nC.brevipinna_JUV &lt;- filter(elasmos, Species==\"Carcharhinus_brevipinna\" & Sex==\"M\" & FL&gt;812 & FL&lt;=1380 | Species==\"Carcharhinus_brevipinna\" & Sex==\"F\" & FL&gt;844 & FL&lt;=1360 | Species==\"Carcharhinus_brevipinna\" & Sex==\"U\" & FL&gt;844 & FL&lt;=1360) %&gt;%\n  mutate(Estimated_Stage=\"JUV\")\n\nC.brevipinna_MAT &lt;- filter(elasmos, Species==\"Carcharhinus_brevipinna\" & Sex==\"M\" & FL&gt;1380 | Species==\"Carcharhinus_brevipinna\" & Sex==\"F\" & FL&gt;1360 | Species==\"Carcharhinus_brevipinna\" & Sex==\"U\" & FL&gt;1360) %&gt;%\n  mutate(Estimated_Stage=\"MAT\")\n\n\n# C. leucas, Neer et al. 2005\n\nC.leucas_YOY &lt;- filter(elasmos, Species==\"Carcharhinus_leucas\" & FL&lt;=700) %&gt;%\n  mutate(Estimated_Stage=\"YOY\")\n\nC.leucas_JUV &lt;- filter(elasmos, Species==\"Carcharhinus_leucas\" & Sex==\"M\" & FL&gt;700 & FL&lt;=2100 | Species==\"Carcharhinus_leucas\" & Sex==\"F\" & FL&gt;700 & FL&lt;=2250 | Species==\"Carcharhinus_leucas\" & Sex==\"U\" & FL&gt;700 & FL&lt;=2250) %&gt;%\n  mutate(Estimated_Stage=\"JUV\")\n\nC.leucas_MAT &lt;- filter(elasmos, Species==\"Carcharhinus_leucas\" & Sex==\"M\" & FL&gt;2100 | Species==\"Carcharhinus_leucas\" & Sex==\"F\" & FL&gt;2250 | Species==\"Carcharhinus_leucas\" & Sex==\"U\" & FL&gt;2250) %&gt;%\n  mutate(Estimated_Stage=\"MAT\")\n\nNow you have a bunch of individual data.frames that we need to put back together into a single data.frame. We can do this using bind_rows() which will combine data.frames that have the same set of columns.\n\nelasmos_stage &lt;- bind_rows(C.brevipinna_YOY, C.brevipinna_JUV, C.brevipinna_MAT,\n                           C.leucas_YOY, C.leucas_JUV, C.leucas_MAT)\n\n\n\n\n6 Remember, you can use & and | to combine two conditionsThis solution fits into our general scheme of “split-apply-combine” - except that we actually created multiple objects during our “split” stage. Is there a way to do this without creating individual objects?\n\n\n\n\n\n\nSolution 2\n\n\n\n\n\nIndeed, our second option circumvents having to first create subsets of the initial data.frame using something called a “conditional mutate”.\n\nelasmos_stage &lt;- elasmos %&gt;%\n  filter(Species %in% c(\"Carcharhinus_leucas\", \"Carcharhinus_brevipinna\")) %&gt;%\n  mutate(Estimated_Stage = case_when(Species == \"Carcharhinus_brevipinna\" & Sex==\"M\" & FL&lt;=812 |\n                                       Species == \"Carcharhinus_brevipinna\" & Sex==\"F\" & FL&lt;=844 |\n                                       Species == \"Carcharhinus_brevipinna\" & Sex==\"U\" & FL&lt;=844 ~ \"YOY\",\n         Species==\"Carcharhinus_brevipinna\" & Sex==\"M\" & FL&gt;812 & FL&lt;=1380 |\n           Species==\"Carcharhinus_brevipinna\" & Sex==\"F\" & FL&gt;844 & FL&lt;=1360 |\n           Species==\"Carcharhinus_brevipinna\" & Sex==\"U\" & FL&gt;844 & FL&lt;=1360 ~ \"JUV\",\n         Species==\"Carcharhinus_brevipinna\" & Sex==\"M\" & FL&gt;1380 |\n           Species==\"Carcharhinus_brevipinna\" & Sex==\"F\" & FL&gt;1360 |\n           Species==\"Carcharhinus_brevipinna\" & Sex==\"U\" & FL&gt;1360 ~ \"MAT\",\n         Species==\"Carcharhinus_leucas\" & FL&lt;=700 ~ \"YOY\",\n         Species==\"Carcharhinus_leucas\" & Sex==\"M\" & FL&gt;700 & FL&lt;=2100 | \n           Species==\"Carcharhinus_leucas\" & Sex==\"F\" & FL&gt;700 & FL&lt;=2250 | \n           Species==\"Carcharhinus_leucas\" & Sex==\"U\" & FL&gt;700 & FL&lt;=2250 ~ \"JUV\",\n         Species==\"Carcharhinus_leucas\" & Sex==\"M\" & FL&gt;2100 | \n           Species==\"Carcharhinus_leucas\" & Sex==\"F\" & FL&gt;2250 | \n           Species==\"Carcharhinus_leucas\" & Sex==\"U\" & FL&gt;2250 ~ \"MAT\"))\n\nThis is of course a fairly complicated conditional mutate as we are generally combining multiple conditions per category. In this case we could also leave out the | and instead add a ~ STAGE to each line depending on our coding preferences.\n\n\n\nNormally, we would have to extend our code to estimate life history stage for all of our sampled individuals but I have done this for you and you can load that file from your data folder.\n\nelasmos &lt;- read_delim(\"data/elasmos_complete.txt\", delim = \"\\t\")\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nUse this data set to create a table with the number of individuals per life history stage caught at each site.\n\n\nThis is what you table should look like.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies\nSite\nTotal\nYOY\nJUV\nMAT\nUND\n\n\n\n\nCarcharhinus_brevipinna\nAransas_Bay\n12\n11\n0\n0\n1\n\n\nCarcharhinus_brevipinna\nCorpus_Christi_Bay\n46\n45\n0\n0\n1\n\n\nCarcharhinus_brevipinna\nRedfish_Bay\n12\n8\n3\n0\n1\n\n\nCarcharhinus_leucas\nAransas_Bay\n3\n0\n3\n0\n0\n\n\nCarcharhinus_leucas\nCorpus_Christi_Bay\n4\n4\n0\n0\n0\n\n\nCarcharhinus_leucas\nRedfish_Bay\n1\n0\n1\n0\n0\n\n\nCarcharhinus_limbatus\nAransas_Bay\n1\n0\n1\n0\n0\n\n\nCarcharhinus_limbatus\nCorpus_Christi_Bay\n1\n1\n0\n0\n0\n\n\nCarcharhinus_porosus\nCorpus_Christi_Bay\n1\n0\n1\n0\n0\n\n\nHypanus_americanus\nAransas_Bay\n3\n0\n0\n3\n0\n\n\nHypanus_americanus\nCorpus_Christi_Bay\n1\n0\n0\n1\n0\n\n\nHypanus_americanus\nRedfish_Bay\n7\n0\n3\n4\n0\n\n\nHypanus_sabina\nAransas_Bay\n9\n0\n0\n9\n0\n\n\nHypanus_sabina\nCorpus_Christi_Bay\n2\n0\n0\n2\n0\n\n\nRhinoptera_bonasus\nRedfish_Bay\n1\n0\n0\n1\n0\n\n\nRhizoprionodon_terraenovae\nAransas_Bay\n1\n1\n0\n0\n0\n\n\nRhizoprionodon_terraenovae\nCorpus_Christi_Bay\n5\n5\n0\n0\n0\n\n\nRhizoprionodon_terraenovae\nRedfish_Bay\n8\n8\n0\n0\n0\n\n\nSphyrna_lewini\nCorpus_Christi_Bay\n4\n1\n3\n0\n0\n\n\nSphyrna_tiburo\nAransas_Bay\n1\n0\n1\n0\n0\n\n\nSphyrna_tiburo\nCorpus_Christi_Bay\n18\n0\n14\n3\n1\n\n\nSphyrna_tiburo\nRedfish_Bay\n16\n1\n9\n6\n0\n\n\n\nTable 10.2: Number of individuals per species caught at each site by life history stage.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly describe your results to compare total catch across sites accounting for differences in life history stage.\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nSubset your data to contain only YOY and generate a table to investigate whether they were caught across all years sampling occured. Summarize your results in 2-3 sentences.\n\n\nThis is what your table should look like:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSite\nSpecies\n2015\n2016\n2017\n2018\n\n\n\n\nAransas_Bay\nCarcharhinus_brevipinna\n7\n0\n3\n1\n\n\nAransas_Bay\nRhizoprionodon_terraenovae\n0\n0\n1\n0\n\n\nCorpus_Christi_Bay\nCarcharhinus_brevipinna\n0\n6\n16\n23\n\n\nCorpus_Christi_Bay\nCarcharhinus_leucas\n1\n3\n0\n0\n\n\nCorpus_Christi_Bay\nCarcharhinus_limbatus\n0\n1\n0\n0\n\n\nCorpus_Christi_Bay\nRhizoprionodon_terraenovae\n0\n3\n1\n1\n\n\nCorpus_Christi_Bay\nSphyrna_lewini\n0\n0\n1\n0\n\n\nRedfish_Bay\nCarcharhinus_brevipinna\n1\n0\n3\n4\n\n\nRedfish_Bay\nRhizoprionodon_terraenovae\n4\n4\n0\n0\n\n\nRedfish_Bay\nSphyrna_tiburo\n1\n0\n0\n0\n\n\n\nTable 10.3: Number of YOY caught at each site in each sampling year."
  },
  {
    "objectID": "10_relational-data.html#comparison-of-cpue-per-species-across-sites",
    "href": "10_relational-data.html#comparison-of-cpue-per-species-across-sites",
    "title": "10  Relational data",
    "section": "10.2 Comparison of CPUE per species across sites",
    "text": "10.2 Comparison of CPUE per species across sites\n\n\n\n\n\n\n Consider this\n\n\n\nConsider disadvantages of using absolute counts of occurrence to compare composition across sites. What measure could you use instead of total catch to fix this issue?\n\n\nCatch-per-unit-effort (CPUE) is an indirect measure of abundance. Essentially, it is a way to measure relative abundance and be able to account for differences in sampling effort - the key is defining how you will measure “effort”.\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly discuss what measures we could use to determine effort.\n\n\nWe are going to calculate effort as “hook hours”.\nTo do this we need to know how many hooks were on the line per set7 and how long the entire line was in the water per set (this is called soak time), then we can easily calculate hook hours of each set as the number of hooks multiplied by the soak time. And then we can divide the number of e.g. sharks caught on a set (“catch) by hook hours (”effort”) to calculate CPUE.7 A set means that baited hooks on leaders (individual lines) where attached to the main line and that main line was then “set” in the water for a given period of time before pulling it back in and determining which fish were caught on hooks.\nYour data folder contains as tab-delimited file with set meta-data. This includes information that describes the set itself including date of the set, site, soak time, and location and also parameters describing the conditions of the set such as temperature, salinity, depth, and dissolved oxygen.\nLet’s read in the data set.\n\nset_meta &lt;- read_delim(\"data/set_data.txt\", delim = \"\\t\")\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nTake a quick look at the data set to determine what columns are included and what information we can learn about each individual set. How can you amend the data set to include hook hours?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nCorrect, a simple mutate() will do the trick.\n\nset_meta &lt;- set_meta %&gt;%\n  mutate(Hook_Hours = Hooks * Soak_Time)\n\n\n\n\nNext we need to count the number of sharks caught per set.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nIf we look at our elasmo data.frame you will notice that we have a column called Set but that number indicates the nth set of a give sample day. How can you add a column called Set_ID that consists of the date and the set number?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nelasmos &lt;- elasmos %&gt;%\n  unite(Set_ID, Year, Month, Day, Set, sep = \"_\", remove = FALSE) %&gt;%\n  arrange(Set_ID)\n\n\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nNow create a new object called elasmos_set that contains the number of sharks caught per set.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\n\nelasmos_set &lt;- elasmos %&gt;%\n  count(Set_ID)\n\n\n\n\nNow we have two data.frames one contains the information on how many sharks were caught per set and a second one that contains information about the set, including hook hours. This means that our next step will need to be to combine these two data sets.\n\n\n\n\n\n\n Consider this\n\n\n\nEarlier we learned about bind_rows() which allows us to combine two data.frames that contain identical columns, i.e. row-wise. There is an equivalent function called bind_columns() which allows us to combine data.frames column-wise.\nConsider what the problem would be in using bind_columns() to combine these two data sets.\n\n\nHaving multiple tables containing data pertaining to the same question is referred to as relational data - we are interested in how the contents of a pair of table related to each other, not just the individual data sets. Combining two tables is called a join. In this case the type of join we want to execute is called a mutating join which means we can add new variables from one data.frame (set_meta) to matching observations in another (elasmos_set).\nIn order to do that we need to have one column (the key) that way the function can match observations in one data.frame by that key and then copy the matching observations in the columns from the second data.frame across.\nWhen performing a join, new columns are added to the right. We will use the function full_join() which means that all the rows from the left and right data.frame will be retained - when we used count() that excluded sets where no sharks were caught, by using a full_join() we can add those back in.\nWe currently do not have a matching column between the two data sets, so our first step will be to add a new column called Set_ID to our set_meta data.frame, then we can use full_join() to join the two tables. The argument by can be used to specify the column to use as the key. For our example here we have a column with the same name - in general, the function is “smart” enough to identify shared columns and so you do not necessarily have to specify it.\n\n\nYou can pull up the help page using ?full_join to learn how to join tables that have multiple columns in common or that might have a column in common though it is named differently between the two tables.\nNote the notation elasmo_set &lt;- full_join(elasmos_set, set_meta, by = \"Set_ID\") will produce the same result as the syntax we are using here.\n\n# add set id column\nset_meta &lt;- set_meta %&gt;%\n  unite(Set_ID, Year, Month, Day, Set, sep = \"_\", remove = FALSE)\n\n# join data sets\nelasmos_set &lt;- elasmos_set %&gt;%\n  full_join(set_meta) %&gt;%\n  replace_na(list(n = 0))\n\nNow we can calculate CPUE for sharks per site.\n\nelasmos_set &lt;- elasmos_set %&gt;%\n  mutate(CPUE = n/Hook_Hours)\n\nAnd from that we can easily calculate mean and standard deviation CPUE of catching sharks by site.\n\n\n\n\n\n\n\nSite\nmean_CPUE\nstd_CPUE\n\n\n\n\nAransas_Bay\n0.0048954\n0.0089735\n\n\nCorpus_Christi_Bay\n0.0135243\n0.0185803\n\n\nRedfish_Bay\n0.0069282\n0.0114742\n\n\n\nTable 10.4: mean +/- sd CPUE\n\n\nWe are going to perform a Kruskal-Wallis rank sum test to determine if there is significant heterogeneity among sites8.8 You are probably more familiar with the framework of using an ANOVA to test for significant heterogeneity and pairwise t-tests to test for equality of means of a set of values. KW is similar but is a non-parametric approach and does not make assumptions about the distribution of values.\n\n# KW to test for significant heterogeneity\nkruskal.test(CPUE ~ Site, data = elasmos_set)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  CPUE by Site\nKruskal-Wallis chi-squared = 12.325, df = 2, p-value = 0.002106\n\n\nAnd we will follow that using a Dunn’s test for pairwise comparisons.\n\n# post-hoc Dunn test\ndunnTest(CPUE ~ Site, data = elasmos_set, method = \"bh\")\n\n                        Comparison          Z      P.unadj       P.adj\n1 Aransas_Bay - Corpus_Christi_Bay -3.3553910 0.0007925288 0.002377586\n2        Aransas_Bay - Redfish_Bay -0.7980727 0.4248282807 0.424828281\n3 Corpus_Christi_Bay - Redfish_Bay  2.5669868 0.0102586520 0.015387978\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly describe your results and discuss what this result could mean for our overarching question of identifying shark nurseries.\n\n\nOf course, we are interested how CPUE compares across species and sites.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nChoose one species and calculate the CPUE per set. For convenience convert CPUE to effort per 1000 hook hours and then calculate the mean CPUE per 1000 hooks per site for that species.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThis is what that could look like for a single species.\n\nspecies &lt;- \"Carcharhinus_brevipinna\"\n\nspecies_CPUE &lt;- elasmos %&gt;%\n  filter(Species == species) %&gt;%\n  count(Set_ID) %&gt;%\n  full_join(set_meta) %&gt;%\n  replace_na(list(n = 0)) %&gt;%\n  mutate(CPUE = n/Hook_Hours,\n         CPUE_1000 = CPUE * 1000) %&gt;%\n  group_by(Site) %&gt;%\n  summarize(mean_CPUE = mean(CPUE_1000))\n\n\n\n\nFor better presentation, we probably want to convert that do a wider data set; your results should look like this.\n\n\n\n\n\n\nAransas_Bay\nCorpus_Christi_Bay\nRedfish_Bay\n\n\n\n\n1.91\n7.88\n1.76\n\n\n\nCatch per unit effort (1000 hook hours) for each site.\n\nWe actually want to have this information for all species, rather than create individual data.frames for each species and then combine those using bind_rows(), I will show you a more efficient way of coding this using a for loop.\n\n# create empty list\nspecies_CPUE &lt;- list()\n\n# calculate hook hours for each species per site\nfor(species in unique(elasmos$Species)){\n  \n  species_CPUE[[species]] &lt;- elasmos %&gt;%\n    filter(Species == species) %&gt;%\n    count(Set_ID) %&gt;%\n    full_join(set_meta) %&gt;%\n    replace_na(list(n = 0)) %&gt;%\n    mutate(CPUE = n/Hook_Hours,\n           CPUE_1000 = CPUE * 1000)\n\n}\n\n# combine data frames in list into single \nCPUE &lt;- bind_rows(species_CPUE, .id = \"Species\")\n\nNext, we would want to run KW tests to determine if there are significant differences among sites for each species.\n\n# create empty dataframe for results\nresults &lt;- setNames(data.frame(matrix(ncol = 2, nrow = 0)), \n                    c(\"Species\", \"pvalue\")) %&gt;%\n  mutate(Species = as.character(Species),\n         pvalue = as.numeric(pvalue))\n\nfor(species in unique(CPUE$Species)){\n  \n  # filter CPUE per species\n  tmp &lt;- CPUE %&gt;%\n    filter(Species == species)\n  \n  # KW to test for significant heterogeneity\n  KW &lt;- kruskal.test(CPUE ~ Site, data = tmp)\n  \n  # extract p-value\n  df &lt;- data.frame(\"Species\" = species,\n                   \"pvalue\" = as.numeric(KW$p.value))\n  \n  results &lt;- bind_rows(results, df)\n\n}\n\nLet’s calculate mean CPUE per species and site, turn that into a wide table for easier comparison and add the p-values.\n\nCPUE_sign &lt;- CPUE %&gt;%\n    group_by(Species, Site) %&gt;%\n    summarize(mean_CPUE = mean(CPUE_1000)) %&gt;%\n    pivot_wider(names_from = Site, values_from = mean_CPUE) %&gt;%\n    left_join(results) %&gt;%\n    arrange(Species)\n\nOnce we’ve run that code to wrangle and transform our data we can compare CPUE for each species and site.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies\nAransas_Bay\nCorpus_Christi_Bay\nRedfish_Bay\npvalue\n\n\n\n\nCarcharhinus_brevipinna\n1.91\n7.88\n1.76\n0.00\n\n\nCarcharhinus_leucas\n0.49\n0.52\n0.14\n0.54\n\n\nCarcharhinus_limbatus\n0.14\n0.18\n0.00\n0.60\n\n\nCarcharhinus_porosus\n0.00\n0.15\n0.00\n0.37\n\n\nHypanus_americanus\n0.49\n0.14\n1.08\n0.25\n\n\nHypanus_sabina\n1.50\n0.29\n0.00\n0.00\n\n\nRhinoptera_bonasus\n0.00\n0.00\n0.16\n0.37\n\n\nRhizoprionodon_terraenovae\n0.14\n0.90\n1.29\n0.22\n\n\nSphyrna_lewini\n0.00\n0.50\n0.00\n0.02\n\n\nSphyrna_tiburo\n0.22\n2.96\n2.49\n0.00\n\n\n\nTable 10.5: Catch per unit effort (per 1000 hook hours) for each species by site, p-value indicates whether there are significant differences among sites for a given species.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nUse the table with CPUE per species in your lab manual to briefly describe the results comparing CPUE per species and site and relate that to our overarching question of identifying shark nurseries9.\n\n\n9 Normally, we would want to run additional pairwise tests for each species where there are significant differences among sites, but we’ll skip that step for now and stick to the big picture."
  },
  {
    "objectID": "10_relational-data.html#comparison-of-cpue-for-different-life-history-stages",
    "href": "10_relational-data.html#comparison-of-cpue-for-different-life-history-stages",
    "title": "10  Relational data",
    "section": "10.3 Comparison of CPUE for different life history stages",
    "text": "10.3 Comparison of CPUE for different life history stages\nOf course, we are not only interested in which species were caught at each site, we also want to know what life history stages those individuals were at when they were caught.\nWe will use a similar strategy as above to create a data frame with CPUE per site, species, and life history stage and produce a table comparing the means.\n\n# create empty list\nspecies_CPUE &lt;- list()\n\n# calculate hook hours for each species per site\nfor(species in unique(elasmos$Species)){\n  \n  for(stage in unique(elasmos$Estimated_Stage)){\n    \n      species_CPUE[[paste(species, stage, sep = \":\")]] &lt;- elasmos %&gt;%\n        filter(Species == species & Estimated_Stage == stage) %&gt;%\n        count(Set_ID) %&gt;%\n        full_join(set_meta) %&gt;%\n        replace_na(list(n = 0)) %&gt;%\n        mutate(Estimate_Stage = stage, \n               CPUE = n/Hook_Hours,\n               CPUE_1000 = CPUE * 1000)\n\n  }\n  \n}\n\n# combine data frames in list into single \nCPUE &lt;- bind_rows(species_CPUE, .id = \"Species_Stage\") %&gt;%\n  select(Species_Stage, Set_ID, Site, Hooks, Soak_Time, Hook_Hours, CPUE, CPUE_1000) %&gt;%\n  separate(Species_Stage, into = c(\"Species\", \"Stage\"), sep = \":\", remove = FALSE) %&gt;%\n    group_by(Species_Stage, Site) %&gt;%\n    summarize(mean_CPUE = mean(CPUE_1000)) %&gt;%\n    pivot_wider(names_from = Site, values_from = mean_CPUE) %&gt;%\n    filter(if_any(c(Aransas_Bay, Corpus_Christi_Bay, Redfish_Bay), ~ . &gt; 0)) %&gt;%\n    separate(Species_Stage, into = c(\"Species\", \"Stage\"), sep = \":\") %&gt;%\n    filter(!Stage == \"UND\")\n\nThis will produce the following table summarizing the results.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpecies\nStage\nAransas_Bay\nCorpus_Christi_Bay\nRedfish_Bay\n\n\n\n\nCarcharhinus_brevipinna\nJUV\n0.0000\n0.0000\n0.4586\n\n\nCarcharhinus_brevipinna\nYOY\n1.7477\n7.7283\n1.1510\n\n\nCarcharhinus_leucas\nJUV\n0.4940\n0.0000\n0.1357\n\n\nCarcharhinus_leucas\nYOY\n0.0000\n0.5209\n0.0000\n\n\nCarcharhinus_limbatus\nJUV\n0.1443\n0.0000\n0.0000\n\n\nCarcharhinus_limbatus\nYOY\n0.0000\n0.1794\n0.0000\n\n\nCarcharhinus_porosus\nJUV\n0.0000\n0.1480\n0.0000\n\n\nHypanus_americanus\nJUV\n0.0000\n0.0000\n0.4745\n\n\nHypanus_americanus\nMAT\n0.4872\n0.1444\n0.6095\n\n\nHypanus_sabina\nMAT\n1.4967\n0.2940\n0.0000\n\n\nRhinoptera_bonasus\nMAT\n0.0000\n0.0000\n0.1614\n\n\nRhizoprionodon_terraenovae\nYOY\n0.1443\n0.8970\n1.2884\n\n\nSphyrna_lewini\nJUV\n0.0000\n0.3768\n0.0000\n\n\nSphyrna_lewini\nYOY\n0.0000\n0.1210\n0.0000\n\n\nSphyrna_tiburo\nJUV\n0.2217\n2.3098\n1.4763\n\n\nSphyrna_tiburo\nMAT\n0.0000\n0.4455\n0.8716\n\n\nSphyrna_tiburo\nYOY\n0.0000\n0.0000\n0.1468\n\n\n\nTable 10.6: Comparison of CPUE by life history stage for all observed life history stages in Aransas, Corpus Christi, and Redfish Bay.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly describe the results comparing CPUE per life history stage and site; these results are all statistically significant.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nRelate your all of our results back to the overarching question of identifying shark nurseries in Texas Bays and Estuaries to write a short conclusion in terms of what this study has (or has not demonstrated)."
  },
  {
    "objectID": "07_data-transformation-i.html#data-wrangling",
    "href": "07_data-transformation-i.html#data-wrangling",
    "title": "7  Data Transformation: Organizing rows & Columns",
    "section": "7.1 Data Wrangling",
    "text": "7.1 Data Wrangling\nNow that we have a data frame to play with, let’s explore some data wrangling options using dplyr. The d stands for data and the plyr stands for plyers - this package is designed to manipulate data frames3. We are going to focus on the central actions (verbs) that will allow you to manipulate the data frame.3 This is also known as data wrangling or data munging, manipulating is not a negative thing in this case it means you can clean up and format the data in appropriate way to fit the questions you are asking and allow to to transform the information in a helpful way so that you can apply analysis and modeling as needed in the next step\nThe main advantages to using a command line program like R/code compared to a spreadsheet program such as Excel or Google sheets are:\n\nYou aren’t manipulating the raw data set - if you make a mistake or accidentally overwrite something you haven’t made any permanent damage.\nYou can manipulate data sets too large to easily handle in a spreadsheet\nIf you update your data set or have a second identically formatted data set you just have to re-run the code.\n\nBe sure to record all the steps (code chunks) in your quarto document - both the examples given here and the applications you will be asked to make. You can copy and paste, but you will find that writing out the code will help you get more used to syntax, how auto complete etc. works. Be sure to annotate/comment your code as reminders while we go through new functions in class, and that you take the time to go over your comments before submitting your knotted *.html document.\nThese are central concepts that you will use and reuse throughout the semester so you will likely want to refer back to this document. A good way to create a “cheatsheet” would be to for example for each function write a short description of what it does in general before each code chunk, then make your comment in the code specific to your example. Similarly use normal text to refer to the question numbers in this manual as you work through the problem sets."
  },
  {
    "objectID": "07_data-transformation-i.html#selecting-and-organizing-columns",
    "href": "07_data-transformation-i.html#selecting-and-organizing-columns",
    "title": "7  Data Transformation: Organizing rows & Columns",
    "section": "7.2 Selecting and organizing columns",
    "text": "7.2 Selecting and organizing columns\nLet’s start by loading our data set.\n\n# read catch data\ncatch &lt;- read_delim(\"data/longline_catchdata.txt\", delim = \"\\t\")\n\n\n\n\n\n\n\nBe mindful\n\n\n\nWe will make heavy use of the magrittr pipe %&gt;% this smester which allows you to link commands together; think of it as “and now do this”. R for Data Science (2e) implements the native R pipe |&gt;. For our intents and purposes they are identical.\nBecause we are mostly interested in what the individual functions (verbs) do we will not always assign a new object, but just having it print to the console/below the code chunk we will be able to immediately assess the affect. By piping our function to head() it will print just the first 6 lines.\n\n\nThe function select() is used to select a subset of columns from a data set.\nFor example, you can select just the Site and Species columns4.4 Remember, the function head() allows you to just print the first few lines of the dataframe to the console, otherwise you can end up with several thousand lines!\n\ncatch %&gt;%\n  select(Site, Species) %&gt;%\n  head()\n\n# A tibble: 6 × 2\n  Site        Species      \n  &lt;chr&gt;       &lt;chr&gt;        \n1 Aransas_Bay Bagre_marinus\n2 Aransas_Bay Bagre_marinus\n3 Aransas_Bay Bagre_marinus\n4 Aransas_Bay Bagre_marinus\n5 Aransas_Bay Bagre_marinus\n6 Aransas_Bay Bagre_marinus\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you select just Day, Month, and Year columns?\n\n\nYou can also specify individual columns to eliminate by name. For example, the PCL column doesn’t contain any information (all NAs).\n\ncatch %&gt;%\n  select(-PCL) %&gt;%\n  head()\n\n# A tibble: 6 × 11\n  Site      Species Sex   Observed_Stage    FL   STL Hook_Size   Set   Day Month\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Aransas_… Bagre_… U     &lt;NA&gt;             287   353        10     1    28     7\n2 Aransas_… Bagre_… U     &lt;NA&gt;             425   495        10     1    28     7\n3 Aransas_… Bagre_… U     &lt;NA&gt;             416   502        15     1    28     7\n4 Aransas_… Bagre_… U     &lt;NA&gt;             416   507        10     1    28     7\n5 Aransas_… Bagre_… U     &lt;NA&gt;             418   510        15     1    28     7\n6 Aransas_… Bagre_… U     &lt;NA&gt;             434   515        10     1    28     7\n# ℹ 1 more variable: Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you eliminate hook size from the data set?\n\n\nYou can also eliminate multiple columns by name, for example you would remove Day, Month and Year like this:\n\ncatch %&gt;%\n  select(-Day, -Month, -Year) %&gt;%\n  head()\n\n# A tibble: 6 × 9\n  Site        Species     Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set\n  &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Aransas_Bay Bagre_mari… U     &lt;NA&gt;              NA   287   353        10     1\n2 Aransas_Bay Bagre_mari… U     &lt;NA&gt;              NA   425   495        10     1\n3 Aransas_Bay Bagre_mari… U     &lt;NA&gt;              NA   416   502        15     1\n4 Aransas_Bay Bagre_mari… U     &lt;NA&gt;              NA   416   507        10     1\n5 Aransas_Bay Bagre_mari… U     &lt;NA&gt;              NA   418   510        15     1\n6 Aransas_Bay Bagre_mari… U     &lt;NA&gt;              NA   434   515        10     1\n\n\nIf you want to re-arrange columns in your data frame, you would also use select().\n\ncatch %&gt;%\n  select(FL, Sex, Day) %&gt;%\n  head()\n\n# A tibble: 6 × 3\n     FL Sex     Day\n  &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt;\n1   287 U        28\n2   425 U        28\n3   416 U        28\n4   416 U        28\n5   418 U        28\n6   434 U        28\n\n\n\n\n\n\n\n\nProtip\n\n\n\nIf you wanted to move a set of columns to the front, but not not want to have to type in all the other column names you can use everything().\n\ncatch %&gt;%\n  select(Day, Month, Year, everything()) %&gt;%\n  head()\n\n# A tibble: 6 × 12\n    Day Month  Year Site        Species   Sex   Observed_Stage   PCL    FL   STL\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    28     7  2015 Aransas_Bay Bagre_ma… U     &lt;NA&gt;              NA   287   353\n2    28     7  2015 Aransas_Bay Bagre_ma… U     &lt;NA&gt;              NA   425   495\n3    28     7  2015 Aransas_Bay Bagre_ma… U     &lt;NA&gt;              NA   416   502\n4    28     7  2015 Aransas_Bay Bagre_ma… U     &lt;NA&gt;              NA   416   507\n5    28     7  2015 Aransas_Bay Bagre_ma… U     &lt;NA&gt;              NA   418   510\n6    28     7  2015 Aransas_Bay Bagre_ma… U     &lt;NA&gt;              NA   434   515\n# ℹ 2 more variables: Hook_Size &lt;dbl&gt;, Set &lt;dbl&gt;\n\n\n\n\nThere you go, creating subsets of columns: Simple as that."
  },
  {
    "objectID": "07_data-transformation-i.html#separating-uniting-columns",
    "href": "07_data-transformation-i.html#separating-uniting-columns",
    "title": "7  Data Transformation: Organizing rows & Columns",
    "section": "7.3 Separating & uniting columns",
    "text": "7.3 Separating & uniting columns\nOccasionally you will find that you want to combine the contents of two columns into a single column (e.g. first name, last name) or at other times you may want to separate the contents of a column over multiple columns (e.g. dates).\nFor example, you may have noticed that the Species is entered as genus_species - what if you wanted to have two separate columns with that information?\nThe function separate() will split the contents from one column across two or more columns. To do this you need to specify the new column names (into = c(\"column1\", \"column2\")), and what pattern should be used to determine where the content should be split (sep = \"pattern\").\n\ncatch %&gt;%\n  separate(Species, into = c(\"species\", \"genus\"), sep = \"_\", remove = FALSE) %&gt;%\n  head()\n\n# A tibble: 6 × 14\n  Site    Species species genus Sex   Observed_Stage   PCL    FL   STL Hook_Size\n  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 Aransa… Bagre_… Bagre   mari… U     &lt;NA&gt;              NA   287   353        10\n2 Aransa… Bagre_… Bagre   mari… U     &lt;NA&gt;              NA   425   495        10\n3 Aransa… Bagre_… Bagre   mari… U     &lt;NA&gt;              NA   416   502        15\n4 Aransa… Bagre_… Bagre   mari… U     &lt;NA&gt;              NA   416   507        10\n5 Aransa… Bagre_… Bagre   mari… U     &lt;NA&gt;              NA   418   510        15\n6 Aransa… Bagre_… Bagre   mari… U     &lt;NA&gt;              NA   434   515        10\n# ℹ 4 more variables: Set &lt;dbl&gt;, Day &lt;dbl&gt;, Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nIn some cases, there might not be a distinct pattern that you can use to identify where to split the column content. In this case it may be more helpful to use the position (e.g. “split at”third character from the left”) Look up the separate() function in the help tab and determine how you could split the Year column so you get two new columns by splitting off the last two digits (i.e. 2021 would be 20 and 21). Then eliminate the column containing the first two digits.\n\n\nIn other cases you might have information in two columns that you want to combine into a single column. This can be accomplished using the function unite().\nFor example, if we wanted to create a column called date that had the day, month, and year of each sampling trip separated by an _.\n\ncatch %&gt;%\n  unite(Date, Day, Month, Year, sep = \"_\", remove = FALSE) %&gt;%\n  head()\n\n# A tibble: 6 × 13\n  Site      Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set Date \n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n1 Aransas_… Bagre_… U     &lt;NA&gt;              NA   287   353        10     1 28_7…\n2 Aransas_… Bagre_… U     &lt;NA&gt;              NA   425   495        10     1 28_7…\n3 Aransas_… Bagre_… U     &lt;NA&gt;              NA   416   502        15     1 28_7…\n4 Aransas_… Bagre_… U     &lt;NA&gt;              NA   416   507        10     1 28_7…\n5 Aransas_… Bagre_… U     &lt;NA&gt;              NA   418   510        15     1 28_7…\n6 Aransas_… Bagre_… U     &lt;NA&gt;              NA   434   515        10     1 28_7…\n# ℹ 3 more variables: Day &lt;dbl&gt;, Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nCreate a data set with the following columns in this sequence and print the first few rows to the console.\n\nSet_ID (combining day, month, year, and set)\nGenus\nSpecies\nFL\nSTL"
  },
  {
    "objectID": "07_data-transformation-i.html#sorting-dataframes-by-a-specific-column-content",
    "href": "07_data-transformation-i.html#sorting-dataframes-by-a-specific-column-content",
    "title": "7  Data Transformation: Organizing rows & Columns",
    "section": "7.4 Sorting dataframes by a specific column content",
    "text": "7.4 Sorting dataframes by a specific column content\nUntil you want to visualize a table how the rows are arranged is not really important. However, for example, when generating reports you might want values to be listed in a specific way. This can be done using the function arrange().\nFor example, if we wanted to sort our dataframe based on the Observed_Stage column we could do the following:\n\ncatch %&gt;%\n  arrange(Observed_Stage)\n\n# A tibble: 2,325 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Redfish… Sphyrn… M     MAT              622   668   850        10     1     8\n 2 Redfish… Sphyrn… M     MAT              656   710   869        10     1     8\n 3 Redfish… Sphyrn… F     MAT              708   770   979        15     2     8\n 4 Corpus_… Sphyrn… M     MAT              695   757   954        10     2    12\n 5 Corpus_… Sphyrn… F     MAT              760   861  1090        10     2    12\n 6 Corpus_… Sphyrn… M     MAT              621   689   856        10     2    27\n 7 Redfish… Sphyrn… F     MAT              781   853  1020        10     4    29\n 8 Redfish… Sphyrn… M     MAT              721   783   980        10     3    11\n 9 Redfish… Carcha… U     UND               NA    NA    NA        15     2    16\n10 Corpus_… Sphyrn… U     UND               NA    NA    NA        10     1    27\n# ℹ 2,315 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would sort your table by Sex?\n\n\nBy default, characters are sorted alphabetically, numeric columns from smallest to largest value. If you want to order your values from largest to smallest, you can specify that using desc()\n\ncatch %&gt;%\n  arrange(desc(FL))\n\n# A tibble: 2,325 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Aransas… Carcha… F     &lt;NA&gt;            1042  1140  1410        15     1    25\n 2 Redfish… Carcha… F     &lt;NA&gt;             812   900  1090        15     1    16\n 3 Redfish… Carcha… M     &lt;NA&gt;             792   882  1092        15     2    16\n 4 Corpus_… Sphyrn… F     MAT              760   861  1090        10     2    12\n 5 Redfish… Sphyrn… F     MAT              781   853  1020        10     4    29\n 6 Corpus_… Sciaen… U     &lt;NA&gt;              NA   841   950        10     3    25\n 7 Redfish… Carcha… M     &lt;NA&gt;             740   840  1010        15     3    29\n 8 Redfish… Carcha… M     &lt;NA&gt;             740   820  1020        10     4     1\n 9 Aransas… Carcha… M     &lt;NA&gt;             720   812   912        15     4    22\n10 Redfish… Sphyrn… M     MAT              721   783   980        10     3    11\n# ℹ 2,315 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would sort your site column from Z to A?"
  },
  {
    "objectID": "07_data-transformation-i.html#filtering-subsetting-rows",
    "href": "07_data-transformation-i.html#filtering-subsetting-rows",
    "title": "7  Data Transformation: Organizing rows & Columns",
    "section": "7.5 Filtering (subsetting) rows",
    "text": "7.5 Filtering (subsetting) rows\nFrequently, we are less interested in being able to sort columns by content, rather, we want to extract a subset of rows based on specific content.\nThe function filter() is used to subset a data frame by row based on regular expressions and the boolean operators we previously encounter to describe the content of sets of rows.\nFor example, we might a data.frame with only Gafftop sail catfish (Bagre marinus)5.5 Remember for exact matches we use == not =\n\ncatch %&gt;%\n  filter(Species == \"Bagre_marinus\")\n\n# A tibble: 1,511 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Aransas… Bagre_… U     &lt;NA&gt;              NA   287   353        10     1    28\n 2 Aransas… Bagre_… U     &lt;NA&gt;              NA   425   495        10     1    28\n 3 Aransas… Bagre_… U     &lt;NA&gt;              NA   416   502        15     1    28\n 4 Aransas… Bagre_… U     &lt;NA&gt;              NA   416   507        10     1    28\n 5 Aransas… Bagre_… U     &lt;NA&gt;              NA   418   510        15     1    28\n 6 Aransas… Bagre_… U     &lt;NA&gt;              NA   434   515        10     1    28\n 7 Aransas… Bagre_… U     &lt;NA&gt;              NA   427   520        15     1    28\n 8 Aransas… Bagre_… U     &lt;NA&gt;              NA   446   532        10     1    28\n 9 Aransas… Bagre_… U     &lt;NA&gt;              NA   465   538        10     1    28\n10 Aransas… Bagre_… U     &lt;NA&gt;              NA   450   539        10     1    28\n# ℹ 1,501 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you select only rows containing Scalloped Hammerheads (Sphyrna lewini)?”\n\n\nIf we want all rows but Gafftop sailfish you can use a ! to say “not that” instead of having to list all the species that you do want to keep6.6 This is frequently called “blacklisting”, while creating a list of content that you do want to keep would be referred to as “whitelisting”.\n\ncatch %&gt;%\n  filter(!Species == \"Bagre_marinus\")\n\n# A tibble: 814 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Redfish… Rhizop… M     &lt;NA&gt;             351   378   433        15     1    29\n 2 Redfish… Sphyrn… F     &lt;NA&gt;             470   430   600        10     3    29\n 3 Redfish… Hypanu… F     &lt;NA&gt;              NA    NA   670        15     3    29\n 4 Redfish… Hypanu… F     &lt;NA&gt;              NA    NA   340        10     3    29\n 5 Redfish… Hypanu… M     &lt;NA&gt;              NA    NA   810        10     4    29\n 6 Corpus_… Carcha… F     &lt;NA&gt;             609   670   820        15     1    30\n 7 Corpus_… Sphyrn… M     &lt;NA&gt;             495   485   615        10     2    24\n 8 Corpus_… Sphyrn… F     &lt;NA&gt;             550   370   720        10     2    24\n 9 Corpus_… Sphyrn… M     &lt;NA&gt;             470   505   645        10     3    24\n10 Corpus_… Sphyrn… F     &lt;NA&gt;             540   565   720        10     3    24\n# ℹ 804 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you create a dataframe without Scalloped Hammerheads (Sphyrna lewini) entries?\n\n\nSometimes you might want to select rows that match one of a set of values7. In this case we would use %in% to indicate “keep any of these”.7 Recall, the function c() (concatenate) creates a vector\n\ncatch %&gt;%\n  filter(Species %in% c(\"Sciades_felis\", \"Bagre_marinus\", \"Synodus_foetens\"))\n\n# A tibble: 2,166 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Aransas… Bagre_… U     &lt;NA&gt;              NA   287   353        10     1    28\n 2 Aransas… Bagre_… U     &lt;NA&gt;              NA   425   495        10     1    28\n 3 Aransas… Bagre_… U     &lt;NA&gt;              NA   416   502        15     1    28\n 4 Aransas… Bagre_… U     &lt;NA&gt;              NA   416   507        10     1    28\n 5 Aransas… Bagre_… U     &lt;NA&gt;              NA   418   510        15     1    28\n 6 Aransas… Bagre_… U     &lt;NA&gt;              NA   434   515        10     1    28\n 7 Aransas… Bagre_… U     &lt;NA&gt;              NA   427   520        15     1    28\n 8 Aransas… Bagre_… U     &lt;NA&gt;              NA   446   532        10     1    28\n 9 Aransas… Bagre_… U     &lt;NA&gt;              NA   465   538        10     1    28\n10 Aransas… Bagre_… U     &lt;NA&gt;              NA   450   539        10     1    28\n# ℹ 2,156 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\nAgain, if you wanted everything but rows containing those values you would preface it with a !.\n\ncatch %&gt;%\n  filter(!Species %in% c(\"Sciades_felis\", \"Bagre_marinus\", \"Synodus_foetens\"))\n\n# A tibble: 159 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Redfish… Rhizop… M     &lt;NA&gt;             351   378   433        15     1    29\n 2 Redfish… Sphyrn… F     &lt;NA&gt;             470   430   600        10     3    29\n 3 Redfish… Hypanu… F     &lt;NA&gt;              NA    NA   670        15     3    29\n 4 Redfish… Hypanu… F     &lt;NA&gt;              NA    NA   340        10     3    29\n 5 Redfish… Hypanu… M     &lt;NA&gt;              NA    NA   810        10     4    29\n 6 Corpus_… Carcha… F     &lt;NA&gt;             609   670   820        15     1    30\n 7 Corpus_… Sphyrn… M     &lt;NA&gt;             495   485   615        10     2    24\n 8 Corpus_… Sphyrn… F     &lt;NA&gt;             550   370   720        10     2    24\n 9 Corpus_… Sphyrn… M     &lt;NA&gt;             470   505   645        10     3    24\n10 Corpus_… Sphyrn… F     &lt;NA&gt;             540   565   720        10     3    24\n# ℹ 149 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you subset a data frame to contain only entries for different species in the genus Carcharhinus aka the sharky-sharks? There are four species in the data set - bullsharks (Carcharhinus leucas), spinner sharks (Carcharhinus brevipinna), blacktip sharks (Carcharhinus limbatus), and smalltail sharks (Carcharhinus porosus).\n\n\nFor numbers you likely aren’t just searching for exact matches, you also want to be able to set threshold values and select everything above or below. For example, you can select all rows with values greater than a certain value using &gt;.\n\ncatch %&gt;%\n  filter(FL &gt; 440)\n\n# A tibble: 907 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Aransas… Bagre_… U     &lt;NA&gt;              NA   446   532        10     1    28\n 2 Aransas… Bagre_… U     &lt;NA&gt;              NA   465   538        10     1    28\n 3 Aransas… Bagre_… U     &lt;NA&gt;              NA   450   539        10     1    28\n 4 Aransas… Bagre_… U     &lt;NA&gt;              NA   496   565        10     1    28\n 5 Aransas… Bagre_… U     &lt;NA&gt;              NA   476   569        10     1    28\n 6 Aransas… Bagre_… U     &lt;NA&gt;              NA   495   570        10     1    28\n 7 Aransas… Bagre_… U     &lt;NA&gt;              NA   490   575        10     1    28\n 8 Aransas… Bagre_… U     &lt;NA&gt;              NA   486   581        10     1    28\n 9 Aransas… Bagre_… U     &lt;NA&gt;              NA   503   589        10     1    28\n10 Aransas… Bagre_… U     &lt;NA&gt;              NA   489   590        10     1    28\n# ℹ 897 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nCreate a data frame containing only entries with a forklength shorter than 300mm, then create a data frame that contains only entries with a forklength equal to or smaller than 300mm.\n\n\nIn this second piece of code you used a single boolean operator to include two conditions, “smaller than” and “equal two”. That is a special case of wanting to retain data than fulfills one of either of two conditions and we have a specific boolean operator that can combine the two.\nThis is not always the case, for example, you might want to retain data that fulfills conditions in two different columns. In this case you can combine expressions using & to indicate that it must fulfill all conditions indicated or | to indicate that it must retain at least one of the.\nFor example to select only scalloped hammerheads that are also smaller than 300 cm you would use\n\ncatch %&gt;%\n  filter(Species == \"Sphyrna_lewini\" & FL &lt; 300)\n\n# A tibble: 1 × 12\n  Site      Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Corpus_C… Sphyrn… F     &lt;NA&gt;             192   210   280        15     3     6\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you subset a data frame to contain only entries for different species in the genus Carcharhinus that have a forklength larger than 500 cm?\n\n\nBy contrast, if you wanted all entries that are either gafftops or a fork length smaller than 300 cm you could use the following code:\n\ncatch %&gt;%\n  filter(Species == \"Sphyrna_lewini\" | FL &lt; 300)\n\n# A tibble: 409 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Aransas… Bagre_… U     &lt;NA&gt;              NA   287   353        10     1    28\n 2 Aransas… Bagre_… U     &lt;NA&gt;              NA   285   314        10     2    28\n 3 Corpus_… Bagre_… U     &lt;NA&gt;              NA   299   348        10     1    30\n 4 Corpus_… Bagre_… U     &lt;NA&gt;              NA   297   367        10     2    30\n 5 Corpus_… Bagre_… U     &lt;NA&gt;              NA   298   362        10     3    30\n 6 Corpus_… Bagre_… U     &lt;NA&gt;              NA   290   350        10     2    24\n 7 Redfish… Bagre_… U     &lt;NA&gt;              NA   254   284        10     4     8\n 8 Aransas… Bagre_… U     &lt;NA&gt;              NA    50   574        10     1    25\n 9 Aransas… Bagre_… U     &lt;NA&gt;              NA   280   340         3     3    25\n10 Redfish… Bagre_… U     &lt;NA&gt;              NA   294   353        10     4    16\n# ℹ 399 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you select fish that have a forklength either smaller than 200 cm or larger than 300cm?"
  },
  {
    "objectID": "07_data-transformation-i.html#sneak-peak-grouping-rows-for-specific-wrangling-actions",
    "href": "07_data-transformation-i.html#sneak-peak-grouping-rows-for-specific-wrangling-actions",
    "title": "7  Data Transformation: Organizing rows & Columns",
    "section": "7.6 Sneak peak: grouping rows for specific wrangling actions",
    "text": "7.6 Sneak peak: grouping rows for specific wrangling actions\nWe have already see that it can be helpful to subset rows based on conditions that are met by the content of more than one column. In those cases, we were creating conditions based on Boolean operators.\nIn many cases we might be interested in subsetting a dataframe in a way where our conditions cannot be expressed by a TRUE/FALSE scenario using Boolean operators.\nFor example, we might want to extract the data entry for the longest fish in the data set based on forklength.\nThe function max() can be used to get the maximum value for a vector of numbers. In this case, the vector we are looking at is the FL column of the catch dataframe.\n\ncatch %&gt;%\n  filter(FL == max(FL, na.rm = TRUE))\n\n# A tibble: 1 × 12\n  Site      Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Aransas_… Carcha… F     &lt;NA&gt;            1042  1140  1410        15     1    25\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\nThat’s great, now we now what the largest fish is that we caught.\nWhat about if we wanted to subset the dataframe to retain the largest fish based on forklength for each species?\n\n\n\n\n\n\n Consider this\n\n\n\nConceptually lay out the individual steps that you would need to complete to do this (don’t worry about whether or not you actually know how to code this).\n\n\nThe tidyverse has a central concept call “split-apply-combine”, which means that occasionally we want to group entries in a dataframe (split), do some sort of manipulation (apply), but end up with a single data frame (combine). We will look at how useful this is in the next chapter but let’s take a quick sneak peak at how this is implemented in dplyr using group_by().\n\ncatch %&gt;%\n  group_by(Species) %&gt;%\n  filter(FL == max(FL, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# A tibble: 12 × 12\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Corpus_… Bagre_… U     &lt;NA&gt;              NA   575   640        10     2    24\n 2 Aransas… Rhizop… F     &lt;NA&gt;             580   637   790        10     2    25\n 3 Aransas… Carcha… F     &lt;NA&gt;            1042  1140  1410        15     1    25\n 4 Redfish… Carcha… F     &lt;NA&gt;             812   900  1090        15     1    16\n 5 Corpus_… Sphyrn… F     MAT              760   861  1090        10     2    12\n 6 Aransas… Carcha… F     &lt;NA&gt;             690   757   940        10     2    22\n 7 Corpus_… Sphyrn… F     &lt;NA&gt;             520   578   770        10     1    21\n 8 Corpus_… Carcha… U     &lt;NA&gt;             335   415   475        10     1     3\n 9 Aransas… Sciade… U     &lt;NA&gt;              NA   480   548        10     2    18\n10 Aransas… Sciade… U     &lt;NA&gt;              NA   480   580        10     2    18\n11 Corpus_… Sciaen… U     &lt;NA&gt;              NA   841   950        10     3    25\n12 Corpus_… Synodu… U     &lt;NA&gt;              NA   173   185        10     3    30\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\nThis is also an example of how we can use the pipe (%&gt;%) to string a bunch of commands, in this example we are saying “take the object catch, and then group rows by Species and then for each group retain only the maximum forklength value for that group and then ungroup them again.”\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you group rows by Species and then retain the individual caught on the largest hook size for each species?\n\n\n\n\n\n\n\n\nProtip\n\n\n\nSpecifically for cases where we want to retain the largest or smallest values, we can use family of of functions called slice() which allow us to subset rows based on their position.\nFor example, we can retain the largest 5 individuals per species based on forklength using slice_max()\n\ncatch %&gt;%\n  group_by(Species) %&gt;%\n  slice_max(order_by = FL, n = 5)\n\n# A tibble: 66 × 12\n# Groups:   Species [14]\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Corpus_… Bagre_… U     &lt;NA&gt;              NA   575   640        10     2    24\n 2 Corpus_… Bagre_… U     &lt;NA&gt;              NA   574   676        10     2    21\n 3 Aransas… Bagre_… U     &lt;NA&gt;              NA   565    NA        10     1    17\n 4 Redfish… Bagre_… U     &lt;NA&gt;              NA   564   651        15     1    29\n 5 Aransas… Bagre_… U     &lt;NA&gt;              NA   555   541        10     3    13\n 6 Aransas… Bagre_… U     &lt;NA&gt;              NA   555    NA        15     1    17\n 7 Redfish… Carcha… F     &lt;NA&gt;             812   900  1090        15     1    16\n 8 Redfish… Carcha… M     &lt;NA&gt;             792   882  1092        15     2    16\n 9 Redfish… Carcha… M     &lt;NA&gt;             740   820  1020        10     4     1\n10 Redfish… Carcha… M     &lt;NA&gt;             660   722   880        10     1    20\n# ℹ 56 more rows\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;"
  },
  {
    "objectID": "07_data-transformation-i.html#create-a-subset-with-only-unique-entries",
    "href": "07_data-transformation-i.html#create-a-subset-with-only-unique-entries",
    "title": "7  Data Transformation: Organizing rows & Columns",
    "section": "7.7 Create a subset with only unique entries",
    "text": "7.7 Create a subset with only unique entries\nOccasionally, you might want to create a subset of the data set that shows only the unique (distinct) entries for a specific column; this is especially common during an exploratory analysis of a data set that you are getting an overview of. This can be achieved using the function distinct().\nFor example, we might want to know which years the survey took place.\n\ncatch %&gt;%\n  distinct(Year)\n\n# A tibble: 4 × 1\n   Year\n  &lt;dbl&gt;\n1  2015\n2  2016\n3  2017\n4  2018\n\n\nNotice how that dropped all the other columns. You can switch that off using .keep_all = FALSE.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you produce a table with only one representative per species?\n\n\nYou can also combine columns. For example if we wanted to determine the individual sets of the data set we could use\n\ncatch %&gt;%\n  distinct(Day, Month, Year, Set)\n\n# A tibble: 197 × 4\n     Day Month  Year   Set\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1    28     7  2015     1\n 2    28     7  2015     2\n 3    28     7  2015     3\n 4    28     7  2015     4\n 5    29     7  2015     1\n 6    29     7  2015     2\n 7    29     7  2015     4\n 8    30     7  2015     1\n 9    30     7  2015     2\n10    30     7  2015     3\n# ℹ 187 more rows\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you produce a table showing all the species caught per station using distinct(), presented as arranged alphabetically by Site and Species within Site?"
  },
  {
    "objectID": "09_tidy-data.html#producing-tidy-data-sets",
    "href": "09_tidy-data.html#producing-tidy-data-sets",
    "title": "9  Tidy data",
    "section": "9.1 Producing tidy data sets",
    "text": "9.1 Producing tidy data sets\nThe last set of functions that we need to get comfortable with allow us to create tidy data sets.\n\n\n\n\n\n\n Consider this\n\n\n\nList the three characteristics of a tidy data set. Explain why a tidy data set is sometimes also describe as a long data set.\n\n\nLet’s read out data set back into our R session.\n\n# read catch data\ncatch &lt;- read_delim(\"data/longline_catchdata.txt\", delim = \"\\t\")\n\n\n\n\n\n\n\n Consider this\n\n\n\nTake a look at our data set and argue whether or not it is a tidy data set. The easiest way to do this is to determine if it fullfills all the characteristics.\n\n\nLet’s quickly reformat our catch data as follows\n\ncatch_length &lt;- catch %&gt;%\n  unite(SetID, Year, Month, Day, Set, sep = \"_\") %&gt;%\n  select(SetID, Site, Species, Sex, PCL, FL, STL)\n\nhead(catch_length)\n\n# A tibble: 6 × 7\n  SetID       Site        Species       Sex     PCL    FL   STL\n  &lt;chr&gt;       &lt;chr&gt;       &lt;chr&gt;         &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 2015_7_28_1 Aransas_Bay Bagre_marinus U        NA   287   353\n2 2015_7_28_1 Aransas_Bay Bagre_marinus U        NA   425   495\n3 2015_7_28_1 Aransas_Bay Bagre_marinus U        NA   416   502\n4 2015_7_28_1 Aransas_Bay Bagre_marinus U        NA   416   507\n5 2015_7_28_1 Aransas_Bay Bagre_marinus U        NA   418   510\n6 2015_7_28_1 Aransas_Bay Bagre_marinus U        NA   434   515\n\n\nWe can turn this into a tidy data set using pivot_longer(). To do this we have to identify columns that will be used as the key (cols =) and then name the column that will hold those values (names_to()) and the column that will hold the value (values_to()).\nIn this case, we have made three observations about length for each specimen, in order to have rows with unique observations we want a column that identifies what type of observation was made, for example called Measurement. This is called the “key” because it allows us to “unlock” what type of measurement the individual observation is, i.e. this column will let us know whether an observation (row) is pre-caudal length, fork length, or stretch total length.\nWe will designate another column Length to hold the values for each measurement.\nWe can identify the columns that need to be gathered either by name or since we have re-arranged our dataframe so they are the last columns by column number.\n\ntidy_length &lt;- catch_length %&gt;%\n  pivot_longer(names_to = \"Measurement\", values_to = \"Length\", cols = 5:7)\n\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly outline advantages to using tidy data sets.\n\n\nWith this data set it would be straightforward for us to e.g. calculate mean values for each length measurement by species using group_by() and summarize().\n\ntidy_length %&gt;%\n  group_by(Species, Measurement) %&gt;%\n  summarize(mean = mean(Length, na.rm = TRUE))\n\n# A tibble: 42 × 3\n# Groups:   Species [14]\n   Species                 Measurement  mean\n   &lt;chr&gt;                   &lt;chr&gt;       &lt;dbl&gt;\n 1 Bagre_marinus           FL           433.\n 2 Bagre_marinus           PCL          NaN \n 3 Bagre_marinus           STL          517.\n 4 Carcharhinus_brevipinna FL           644.\n 5 Carcharhinus_brevipinna PCL          583.\n 6 Carcharhinus_brevipinna STL          804.\n 7 Carcharhinus_leucas     FL           769 \n 8 Carcharhinus_leucas     PCL          691.\n 9 Carcharhinus_leucas     STL          936.\n10 Carcharhinus_limbatus   FL           613.\n# ℹ 32 more rows"
  },
  {
    "objectID": "09_tidy-data.html#convert-a-tidy-data-set-to-wide-format",
    "href": "09_tidy-data.html#convert-a-tidy-data-set-to-wide-format",
    "title": "9  Tidy data",
    "section": "9.2 Convert a tidy data set to wide format",
    "text": "9.2 Convert a tidy data set to wide format\nDespite all the advantages of tidy data sets you can see from the table above that frequently when we are presenting results in a table it may be advantageous in terms of layout to have a non-tidy format.\nThis can be done using pivot_wider() which works like pivot_longer() but in reverse. You designate which column is the key (names_from =), i.e. these will become the column names in the new table. Then you need to identify which column in your current data frame contains the values that should be filled out/spread into the columns that will be generated from your key (values_from =).\nSince we don’t have values for precaudal length, we probably want to use filter() to remove those rows first.\n\n\nMore notes on naming things … recall, that we said that filenames should not contain spaces or special characters? We set similar rules for naming objects. Well, column names is a similar conundrum. Including spaces or species characters as a column name creates problems when we are using functions like select() to subset by column name or mutate() to create new columns based on exisiting columns. Similarly, if the column name is a number you will have problems. If you do have unconvential column names you can rename them using rename() or you can use backticks and either side of the name to indicate that it is a column name.\n\ntidy_length %&gt;%\n  filter(!Measurement == \"PCL\") %&gt;%\n  group_by(Species, Measurement) %&gt;%\n  summarize(mean = mean(Length, na.rm = TRUE)) %&gt;%\n  pivot_wider(names_from = \"Measurement\", values_from = \"mean\")\n\n# A tibble: 14 × 3\n# Groups:   Species [14]\n   Species                       FL   STL\n   &lt;chr&gt;                      &lt;dbl&gt; &lt;dbl&gt;\n 1 Bagre_marinus               433.  517.\n 2 Carcharhinus_brevipinna     644.  804.\n 3 Carcharhinus_leucas         769   936.\n 4 Carcharhinus_limbatus       613.  776.\n 5 Carcharhinus_porosus        415   475 \n 6 Hypanus_americanus          NaN   954.\n 7 Hypanus_sabina              NaN   349.\n 8 Rhinoptera_bonasus          NaN   819 \n 9 Rhizoprionodon_terraenovae  412   510.\n10 Sciades_felis               299.  343.\n11 Sciaenops_ocellatus         793   932.\n12 Sphyrna_lewini              471.  628 \n13 Sphyrna_tiburo              622.  792.\n14 Synodus_foetens             173   185 \n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nCalculate the number of individuals per species caught per month in 2018 and present that data in a wide formate to make it easy to compare the number of species (species) per month (columns). As a bonus create an additional column with total catch of that species for 2018."
  },
  {
    "objectID": "08_data-transformation-ii.html#adding-new-variables",
    "href": "08_data-transformation-ii.html#adding-new-variables",
    "title": "8  Data Transformation:",
    "section": "8.1 Adding new variables",
    "text": "8.1 Adding new variables\nSo,turns out selecting columns and filtering based on content in rows is pretty straightforward.\nBut frequently when we are processing our raw data sets we end up wanting to compute additional metrics or use the existing raw data to create new categories.\nThe function mutate() can be used to create new columns. Frequently, this is done based on columns already existing in the data frame. This is a very powerful function with endless possibilities, but we are going to stick to some of the basics for now3.3 Rest assured if your answer is “Oh, could I …” the answer is “Yes”.\nLet’s say you wanted create a column that contained the difference between the fork length and the stretch total length4:4 By default mutate() appends (adds) the new column as the last column. So we can see our results better we’ll used select() to move it to be the first column in the dataframe)\n\ncatch %&gt;%\n  mutate(difference = STL - FL) %&gt;%\n  select(difference, everything())\n\n# A tibble: 2,325 × 13\n   difference Site      Species Sex   Observed_Stage   PCL    FL   STL Hook_Size\n        &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1         66 Aransas_… Bagre_… U     &lt;NA&gt;              NA   287   353        10\n 2         70 Aransas_… Bagre_… U     &lt;NA&gt;              NA   425   495        10\n 3         86 Aransas_… Bagre_… U     &lt;NA&gt;              NA   416   502        15\n 4         91 Aransas_… Bagre_… U     &lt;NA&gt;              NA   416   507        10\n 5         92 Aransas_… Bagre_… U     &lt;NA&gt;              NA   418   510        15\n 6         81 Aransas_… Bagre_… U     &lt;NA&gt;              NA   434   515        10\n 7         93 Aransas_… Bagre_… U     &lt;NA&gt;              NA   427   520        15\n 8         86 Aransas_… Bagre_… U     &lt;NA&gt;              NA   446   532        10\n 9         73 Aransas_… Bagre_… U     &lt;NA&gt;              NA   465   538        10\n10         89 Aransas_… Bagre_… U     &lt;NA&gt;              NA   450   539        10\n# ℹ 2,315 more rows\n# ℹ 4 more variables: Set &lt;dbl&gt;, Day &lt;dbl&gt;, Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\nYou should now have a column called difference at the end of the data frame5.5 Instead of - to substract, you can other mathematical operators such as + to add , * to multiple, and / to divide values when creating a new column.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you create a new column called ratio, that is the ratio of the fork to stretch total length?\n\n\nYou can also create a column that contains a logical value (TRUE/FALSE). For example we might need a column that indicates if the Sex is unknown.\n\ncatch %&gt;%\n  mutate(unknown_sex = Sex == \"U\") %&gt;%\n  select(unknown_sex, everything())\n\n# A tibble: 2,325 × 13\n   unknown_sex Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size\n   &lt;lgl&gt;       &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   287   353        10\n 2 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   425   495        10\n 3 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   416   502        15\n 4 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   416   507        10\n 5 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   418   510        15\n 6 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   434   515        10\n 7 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   427   520        15\n 8 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   446   532        10\n 9 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   465   538        10\n10 TRUE        Aransas… Bagre_… U     &lt;NA&gt;              NA   450   539        10\n# ℹ 2,315 more rows\n# ℹ 4 more variables: Set &lt;dbl&gt;, Day &lt;dbl&gt;, Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\nYou should know have a column called unknown_sex where if the animal that was caught was not sexed contains the value TRUE, if it was identified as male or female it would say FALSE.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you create a new column called post_2017 that is TRUE if fish were caught after 2017?\n\n\n\n\nFor that last problem, a “conditional mutate” using an ifelse statement (if this then do that, else do that) could have come in handy. Another option is case_when() which allows you to create multiple sets of conditions as opposed to ifelse which sets up a TRUE/FALSE dichotomy (file this information away for “maybe useful later”)."
  },
  {
    "objectID": "08_data-transformation-ii.html#group_by-and-mutate",
    "href": "08_data-transformation-ii.html#group_by-and-mutate",
    "title": "8  Data Transformation:",
    "section": "8.2 group_by() and mutate()",
    "text": "8.2 group_by() and mutate()\nMany problems in data science require you to split your data set into subsets according to some grouping variable, apply a function, and then combine the results. dplyr is designed to make this straightforward; you have already sen an example of this while you were learning about filter().\nSimilarly, you can combine mutate() with group_by().\n\n\nThe function mean() will calculate the mean value of a vector of numbers, the argument na.rm=TRUE tells the function to ignore any NA-values in the data set.\nFor example, let’s say you wanted to create a column that is the difference between the fork length of an individual and the mean fork length of that species.\n\ncatch %&gt;%\n  group_by(Species) %&gt;%\n  mutate(diff_mean = FL-mean(FL, na.rm = TRUE))\n\n# A tibble: 2,325 × 13\n# Groups:   Species [14]\n   Site     Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Aransas… Bagre_… U     &lt;NA&gt;              NA   287   353        10     1    28\n 2 Aransas… Bagre_… U     &lt;NA&gt;              NA   425   495        10     1    28\n 3 Aransas… Bagre_… U     &lt;NA&gt;              NA   416   502        15     1    28\n 4 Aransas… Bagre_… U     &lt;NA&gt;              NA   416   507        10     1    28\n 5 Aransas… Bagre_… U     &lt;NA&gt;              NA   418   510        15     1    28\n 6 Aransas… Bagre_… U     &lt;NA&gt;              NA   434   515        10     1    28\n 7 Aransas… Bagre_… U     &lt;NA&gt;              NA   427   520        15     1    28\n 8 Aransas… Bagre_… U     &lt;NA&gt;              NA   446   532        10     1    28\n 9 Aransas… Bagre_… U     &lt;NA&gt;              NA   465   538        10     1    28\n10 Aransas… Bagre_… U     &lt;NA&gt;              NA   450   539        10     1    28\n# ℹ 2,315 more rows\n# ℹ 3 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;, diff_mean &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you create a new column called that contains the difference between the fork length of an individual and the mean fork length of that species for each month?"
  },
  {
    "objectID": "08_data-transformation-ii.html#create-new-data.frame-based-on-another",
    "href": "08_data-transformation-ii.html#create-new-data.frame-based-on-another",
    "title": "8  Data Transformation:",
    "section": "8.3 Create new data.frame based on another",
    "text": "8.3 Create new data.frame based on another\nNot infrequently we are more interested in summary (descriptive) stats of a data set rather than all the raw data - Tidyverse got you covered with the function summarize().\nFor example, we might want to calculate the mean and standard deviation of the measured fork length.\n\ncatch %&gt;%\n  summarize(mean_FL = mean(FL, na.rm = TRUE),\n            sd_FL = sd(FL, na.rm = TRUE))\n\n# A tibble: 1 × 2\n  mean_FL sd_FL\n    &lt;dbl&gt; &lt;dbl&gt;\n1    406.  103.\n\n\n\n\nRemember, that earlier we’ve have used the function max() to obtain the largest value in a vector.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow could you use summarize to get the maximum forklength?\n\n\nThat’s cool but really we could have also just used\n\nmean(catch$FL, na.rm = TRUE)\n\n[1] 405.9179\n\nmax(catch$FL, na.rm = TRUE)\n\n[1] 1140\n\n\nto get that information, since we are only interested in one column (vector).\nsummarize() becomes especially powerful once we leverage group_by() to start calculating summary stats for entries grouped by a grouping variable.\nFor example we can calculate summary stats by species and generate a table to include in a report.\n\ncatch %&gt;%\n  group_by(Species) %&gt;%\n  summarize(mean_FL = mean(FL, na.rm = TRUE),\n           median_FL = median(FL, na.rm = TRUE),\n           max_FL = max(FL, na.rm = TRUE),\n           min_FL = min(FL, na.rm = TRUE),\n           sd_FL = sd(FL, na.rm = TRUE)) %&gt;%\n  ungroup()\n\n# A tibble: 14 × 6\n   Species                    mean_FL median_FL max_FL min_FL sd_FL\n   &lt;chr&gt;                        &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Bagre_marinus                 433.      445     575     45  65.4\n 2 Carcharhinus_brevipinna       644.      648     900    489  69.2\n 3 Carcharhinus_leucas           769       702    1140    624 167. \n 4 Carcharhinus_limbatus         613.      579     757    538 101. \n 5 Carcharhinus_porosus          415       415     415    415  NA  \n 6 Hypanus_americanus            NaN        NA    -Inf    Inf  NA  \n 7 Hypanus_sabina                NaN        NA    -Inf    Inf  NA  \n 8 Rhinoptera_bonasus            NaN        NA    -Inf    Inf  NA  \n 9 Rhizoprionodon_terraenovae    412       396     637    306  73.6\n10 Sciades_felis                 299.      297     480    102  41.9\n11 Sciaenops_ocellatus           793       793     841    745  67.9\n12 Sphyrna_lewini                471.      548.    578    210 174. \n13 Sphyrna_tiburo                622.      605     861    370 114. \n14 Synodus_foetens               173       173     173    173  NA  \n\n\n\n\n\n\n\n\n Consider this\n\n\n\nIf you look closely you should see that you are getting a few NA, NaN, -Inf, and Inf values - any guesses why? You might want to pull up the catch data frame in the view panel to see what is going on with those species.\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow could you use summarize() to calculate a range of summary stats for the stretch total length for individuals grouped by sex?\n\n\nSo far, we have been manipulating our data frame using code and printing it directly to the console (and our quarto document). This can be useful for example to generate tables for reports. However, in many cases we want to create a new object that has been manipulated according to our code and then we will further process, visualize, or analyze that dataframe down the line.\n\nsummary &lt;- catch %&gt;%\n  group_by(Species) %&gt;%\n  summarize(mean_FL = mean(FL, na.rm = TRUE),\n           median_FL = median(FL, na.rm = TRUE),\n           max_FL = max(FL, na.rm = TRUE),\n           min_FL = min(FL, na.rm = TRUE),\n           sd_FL = sd(FL, na.rm = TRUE)) %&gt;%\n  ungroup()\n\nWhen you execute this code, you’ll notice that the code (and probably a warning) is printed to the console but there is no output. Instead, if you look at the environment in the bottom left panel you should now see a new object called summary. Per usual, you can pull that up in the Editor/View pane (top left) using either View(summary) in the console or by clicking on the object in the environment.\nYou will be presenting results in reports over the course of the semester, when you knit an quarto file you will get tables formatted in a standard way according to defaults in the resulting html file. If you want finer control over the output, you can use the kable() function. This will allow you to further format the table, for example, you may specify the number of digits printed using the argument digits =.\nBy adding a chunk options for a label as #| label: tbl-sum-stats and table caption as #| tbl-cap: \"Summary statistics for the forklength of each species, you can further modify the output that adheres to typical reporting standards for reports and research articles.\n\nkable(\n  summary,\n  digits = 1\n)\n\n\n\n\n\n\nSpecies\nmean_FL\nmedian_FL\nmax_FL\nmin_FL\nsd_FL\n\n\n\n\nBagre_marinus\n433.4\n445.0\n575\n45\n65.4\n\n\nCarcharhinus_brevipinna\n643.7\n648.0\n900\n489\n69.2\n\n\nCarcharhinus_leucas\n769.0\n702.0\n1140\n624\n167.3\n\n\nCarcharhinus_limbatus\n613.2\n579.0\n757\n538\n101.0\n\n\nCarcharhinus_porosus\n415.0\n415.0\n415\n415\nNA\n\n\nHypanus_americanus\nNaN\nNA\n-Inf\nInf\nNA\n\n\nHypanus_sabina\nNaN\nNA\n-Inf\nInf\nNA\n\n\nRhinoptera_bonasus\nNaN\nNA\n-Inf\nInf\nNA\n\n\nRhizoprionodon_terraenovae\n412.0\n396.0\n637\n306\n73.6\n\n\nSciades_felis\n298.9\n297.0\n480\n102\n41.9\n\n\nSciaenops_ocellatus\n793.0\n793.0\n841\n745\n67.9\n\n\nSphyrna_lewini\n470.8\n547.5\n578\n210\n174.4\n\n\nSphyrna_tiburo\n621.5\n605.0\n861\n370\n114.4\n\n\nSynodus_foetens\n173.0\n173.0\n173\n173\nNA\n\n\n\nTable 8.1: Summary statistics for the forklength of each species in the catch data"
  },
  {
    "objectID": "08_data-transformation-ii.html#combining-verbs",
    "href": "08_data-transformation-ii.html#combining-verbs",
    "title": "8  Data Transformation:",
    "section": "8.4 Combining verbs",
    "text": "8.4 Combining verbs\nWe’ve already combined most of our dplyr verbs with group_by().\nWhen you are wrangling data you will find that making use of the pipe (%&gt;%) to combine select(), filter(), mutate(), and summarize() as a series of commands will be necessary to get your data set in the correct format and further process it.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nExecutre the following the code chunk. Then describe what each line is doing to manipulate the data frame.\n\ncatch %&gt;%\n  select(-PCL, -Hook_Size) %&gt;%\n  separate(Species, into = c(\"genus\", \"species\"), remove = TRUE) %&gt;%\n  unite(Date, Day, Month, Year) %&gt;%\n  filter(genus == \"Carcharhinus\" & Sex %in% c(\"F\", \"M\")) %&gt;%\n  group_by(Site, genus, species, Sex) %&gt;%\n  filter(FL == max(FL)) %&gt;%\n  arrange(species)\n\n# A tibble: 11 × 9\n# Groups:   Site, genus, species, Sex [11]\n   Site               genus species Sex   Observed_Stage    FL   STL   Set Date \n   &lt;chr&gt;              &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n 1 Aransas_Bay        Carc… brevip… M     &lt;NA&gt;             640   792     3 22_9…\n 2 Redfish_Bay        Carc… brevip… F     &lt;NA&gt;             900  1090     1 16_6…\n 3 Redfish_Bay        Carc… brevip… M     &lt;NA&gt;             882  1092     2 16_6…\n 4 Corpus_Christi_Bay Carc… brevip… M     &lt;NA&gt;             699   860     1 25_1…\n 5 Corpus_Christi_Bay Carc… brevip… F     &lt;NA&gt;             704   880     4 2_10…\n 6 Aransas_Bay        Carc… leucas  F     &lt;NA&gt;            1140  1410     1 25_5…\n 7 Corpus_Christi_Bay Carc… leucas  F     YOY              694   854     2 10_6…\n 8 Aransas_Bay        Carc… leucas  M     &lt;NA&gt;             812   912     4 22_9…\n 9 Redfish_Bay        Carc… leucas  M     &lt;NA&gt;             840  1010     3 29_9…\n10 Aransas_Bay        Carc… limbat… F     &lt;NA&gt;             757   940     2 22_6…\n11 Corpus_Christi_Bay Carc… limbat… M     &lt;NA&gt;             610   770     2 30_8…\n\n\n\n\nGenerate the code that will manipulate the data frame as follows6:6 some bullet points may require more than one line of code; you do not have to perform the steps in the sequence presented, play around a little bit to see how to code this more efficiently\n\n\n\n\n\n\n Give it a whirl\n\n\n\nChallenge 1:\n\norder columns so Day, Month, Year, Set are at the beginning.\nretain all male individuals in the genus Carcharhinus.\nget rid of columns containing information on observed stage, precaudal length, and hook size\n\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nChallenge 2:\n\ncreate a new variable called Set_ID consisting of Day, Month, Year, and Set number.\ndetermine the number of individuals per species per set7.\n\n7 There is a function called n() that allows us to count rows fulfilling a specific condition\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nChallenge 3:\n\nremove all gafftops\ncalculate mean forklength for each species by sex and month of the year."
  },
  {
    "objectID": "B_shark-wrangling.html#essential-fish-habitat-shark-nurseries",
    "href": "B_shark-wrangling.html#essential-fish-habitat-shark-nurseries",
    "title": "Data/Shark wrangling",
    "section": "Essential fish habitat: Shark Nurseries",
    "text": "Essential fish habitat: Shark Nurseries\nThe Magnuson-Stevens Act (1996) defined essential fish habitat as “those waters and substrate necessary to fish for spawning, breeding, feeding or growth to maturity”, i.e. they are habitats necessary for an organism to complete their life cycle. Identifying essential fish habitats is critical for management and conservation plans because it enables policy makers to prioritize certain ecosystems.\nWhile some elasmobranchs (sharks, rays, skates) inhabit estuaries year round, many use the estuaries for specific purposes such as feeding, mating, gestation, parturition or as nurseries and only inhabit them during specific life history stages. Estuaries are heavily impacted by humans - overfishing, pollution, habitat destruction and altered flow regimes all affect the biological communities they support.\nBroadly, shark nurseries are areas where young are born and/or reside in during maturation. Typically, these would areas that provide additional protection (e.g. mangroves for hiding) and plenty of food.\nShark Nurseries have three defining criteria(Heupel et al. 2018; Heupel, Carlson, and Simpfendorfer 2007):\n\nHeupel, Michelle R., Shiori Kanno, Ana P. B. Martins, Colin A. Simpfendorfer, Michelle R. Heupel, Shiori Kanno, Ana P. B. Martins, and Colin A. Simpfendorfer. 2018. “Advances in Understanding the Roles and Benefits of Nursery Areas for Elasmobranch Populations.” Marine and Freshwater Research 70 (7): 897–907. https://doi.org/10.1071/MF18081.\n\nHeupel, Michelle R., John K. Carlson, and Colin A. Simpfendorfer. 2007. “Shark Nursery Areas: Concepts, Definition, Characterization and Assumptions.” Marine Ecology Progress Series 337 (May): 287–97. https://doi.org/10.3354/meps337287.\n\nan area where sharks are more commonly encountered within compared to outside of.\nan area in which Young-of-the-year (YOY)/juveniles remain in or return to for extended periods of time.\nan area that is repeatedly used across years.\n\n\n\n\n\n\n\n Consider this\n\n\n\nDescribe how you could design a study to identify estuaries that are shark nurseries."
  },
  {
    "objectID": "B_shark-wrangling.html#identifying-shark-nurseries-on-the-texas-coast",
    "href": "B_shark-wrangling.html#identifying-shark-nurseries-on-the-texas-coast",
    "title": "Data/Shark wrangling",
    "section": "Identifying shark nurseries on the Texas Coast",
    "text": "Identifying shark nurseries on the Texas Coast\nTexas Parks and Wildlife (TPWD) defines eight major estuaries along the Texas coastline and performs regular shore-based gill net surveys for 10 week periods in April - June and September to November.\n\n\n\nFigure 1: Map of major estuaries located along the Texas coast in the northwest Gulf of Mexico (Plumlee et al. 2018).\n\n\nAnalysis of this survey has identify eight elasmobranch species present in these ecosystems (Plumlee et al. 2018):\n\nPlumlee, Jeffrey D., Kaylan M. Dance, Philip Matich, John A. Mohan, Travis M. Richards, Thomas C. TinHan, Mark R. Fisher, and R. J. David Wells. 2018. “Community Structure of Elasmobranchs in Estuaries Along the Northwest Gulf of Mexico.” Estuarine, Coastal and Shelf Science 204 (May): 103–13. https://doi.org/10.1016/j.ecss.2018.02.023.\n\nBull shark\nBonnethead\nCownose ray\nBlacktip shark\nAtlantic stingray\nAtlantic sharpnose shark\nSpinner shark\nScalloped hammerhead\nFinetooth shark\nLemon shark\n\nGill nets generally exclude individuals &gt; 2m.\nMore recently, a multi-year open water long-lining study targeting elasmobranchs was performed in three estuarine locations near Corpus Christi, TX that are considered putative shark nurseries. Here, the sampling period lasted from May to November (Swift and Portnoy 2021).\n\nSwift, Dominic G., and David S. Portnoy. 2021. “Identification and Delineation of Essential Habitat for Elasmobranchs in Estuaries on the Texas Coast.” Estuaries and Coasts 44 (3): 788–800. https://doi.org/10.1007/s12237-020-00797-y.\n\n\n\n\n\n\n Consider this\n\n\n\nDiscuss whether or not you would expect to get similar results from both studies and what factors could result in differences.\n\n\n\n\n\n\n\n\n Pointers\n\n\n\n\n\nHere are some things to consider:\n\ngear-bias (hook size, net-size)\nseasonality (peak use for many coastal elasmobranchs is May - Oct)\nspatial (land-based vs open ocean)\n\n\n\n\nThis study wanted to answer four questions to further understand whether these locations should be considered shark nurseries and therefore as essential fish habitat for specific elasmobranch species.\n\nHow does the composition of elasmobranch communities compare across sites?\nHow does the catch-per-unit-effort (CPUE) per species and life history compare across sites?\nWhat do the sex ratios look like?\nWhat environmental predictors can we use to predict presence of elasmobranchs?\n\nIn this module we will interact with the data set generated for this study to learn how to wrangle data sets using R in the tidyverse and then we will apply those skills to answer these questions."
  },
  {
    "objectID": "06_data-frames.html#reading-data-into-r",
    "href": "06_data-frames.html#reading-data-into-r",
    "title": "6  Intro to dataframes",
    "section": "6.1 Reading data into R",
    "text": "6.1 Reading data into R\nlibrary(tidyverse) is actually loading a set of packages used for data science that share a common design philosophy, and “grammar”. One of the packages we loaded is called readr which contains functions for reading in and parsing files.\nAt the end of Chapter 5 when we were exploring the usefulness of spreadsheets for data entry and management. You would have export the excel file with the catch data as *.csv (comma delimited) and as a tab-delimited text file (*.txt or *.tsv if exporting from google sheets).\n\n\n\n\n\n\n Give it a whirl\n\n\n\nUse ?read_delim to pull up the help page for the function we will using and explore the arguments. How do you think we read in our csv file?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nread_delim has two required arguments, the path (data/longline_catchdata.csv) which tells R where your file is located and the delimiter in this case a comma (,) tells R how columns are separated from each other.\n\n# read catch data\ncatch &lt;- read_delim(\"data/longline_catchdata.csv\", delim = \",\")\n\nAs we access data sets that are not as “clean” as the one we have here, you will find that some of the other arguments apart from specifying the delimiter will come in handy - but don’t worry about those for now.\n\n\n\nExecute the code. If you look over in your environment pane you should now see the object catch. This is your dataframe. Click on it, you should see the command View(catch) in your console and a tab catch appear in your top left pane.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nBased on how you read in the csv file how would you read in the tab-delimited version?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nWe need to change delimiter to indicate that it is tab-delimited. In this case, we would specify it as \\t is “computer” for tab.\n\n# read catch data\ncatch &lt;- read_delim(\"data/longline_catchdata.txt\", delim = \"\\t\")\n\nAnother delimiter you might encounter are white space (\" \") but technically it could be anything.\n\n\n\nWhen you loaded your data set you should have seem an message along the lines of parsed with column specification and information on the number of columns and their data type. What this means is that read_delim() looks through the first 1,000 rows for each column and guesses the data type - usually this works pretty well though occasionally we will have to either specify the data types manually using the col_types argument or convert the data type later on.\nLet’s use class() to figure out what type of object we are dealing with.\n\nclass(catch)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\nYou can see that this object actually has multiple classes attached to it. The last one in the list is data.frame which is the standard format for (rectangular) tabular data.\nRecall from our tutorial on vectors that each column in a data.frame is an atomic vector, they must all have the same length (hence, “rectangular”) and each must contain the same data type (characters, integers, …).\nThe other three have the same basic properties as a data.frame along with some additional features. The tbl (pronounced tibble) was designed to be at the center of the tidyverse which means that when you use readr functions it will automatically be read in as a tibble and data.frame. If you do some exploring and/or troubleshooting on the web you will likely run into tibbles but for our intents of purposes we will use data.frame when talking about data in a rectangual, tabular shape."
  },
  {
    "objectID": "06_data-frames.html#inspecting-your-data.frame",
    "href": "06_data-frames.html#inspecting-your-data.frame",
    "title": "6  Intro to dataframes",
    "section": "6.2 Inspecting your data.frame",
    "text": "6.2 Inspecting your data.frame\nYou have of course already peaked at the data when you opened it in excel to export it in a text-based format. But not infrequently, you may access data from a public database or a collaborator might share a text-based formatted data set with you and the first thing that you are going to want to do is figure out what information is contained in the data set.\n\n\n\n\n\n\n Consider this\n\n\n\nYou know that this data set is the result from a long-lining survey and you’re now basically an expert in formatting data - what information do you expect to find in this data set? How would you expect it to be formatted if this is a ‘tidy data set’.\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nThere are several functions that you can use for a preliminary inspection of your data, including figuring out what dimensions it has and what information is contained in your data set.\nCall the following functions on your object and describe what each function does, what information you can learn about your data set from executing them, and when these could be helpful.\n\ndim(), nrow(), ncol()\nstr(), summary()\nhead(), tail()\ncolnames(), rownames()\nView()"
  },
  {
    "objectID": "06_data-frames.html#subsetting-your-dataframe",
    "href": "06_data-frames.html#subsetting-your-dataframe",
    "title": "6  Intro to dataframes",
    "section": "6.3 Subsetting your dataframe",
    "text": "6.3 Subsetting your dataframe\nSimilar to the way we were able to subset vectors, we can do the same things with our data.frames using rows and columns as our “coordinates” in the format data_frame[row_index, column_index].\n\n6.3.1 Using coordinates\nSo for example we can extract the first row and column from our catch object as\n\ncatch[1, 1]\n\n# A tibble: 1 × 1\n  Site       \n  &lt;chr&gt;      \n1 Aransas_Bay\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you extract the 5th column from the third row?\n\n\nYou can select multiple rows or columns by specifying them using a vector.\n\ncatch[c(1, 20, 40), c(2, 5)]\n\n# A tibble: 3 × 2\n  Species         PCL\n  &lt;chr&gt;         &lt;dbl&gt;\n1 Bagre_marinus    NA\n2 Bagre_marinus    NA\n3 Bagre_marinus    NA\n\n\nYou can also select a set of adjacent rows (columns) using : as so\n\ncatch[500:505, 2:5]\n\n# A tibble: 6 × 4\n  Species       Sex   Observed_Stage   PCL\n  &lt;chr&gt;         &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt;\n1 Bagre_marinus U     &lt;NA&gt;              NA\n2 Bagre_marinus U     &lt;NA&gt;              NA\n3 Bagre_marinus U     &lt;NA&gt;              NA\n4 Bagre_marinus U     &lt;NA&gt;              NA\n5 Bagre_marinus U     &lt;NA&gt;              NA\n6 Bagre_marinus U     &lt;NA&gt;              NA\n\n\nYou can exclude indices using -\n\ncatch[1:5, -1]\n\n# A tibble: 5 × 11\n  Species     Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day Month\n  &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Bagre_mari… U     &lt;NA&gt;              NA   287   353        10     1    28     7\n2 Bagre_mari… U     &lt;NA&gt;              NA   425   495        10     1    28     7\n3 Bagre_mari… U     &lt;NA&gt;              NA   416   502        15     1    28     7\n4 Bagre_mari… U     &lt;NA&gt;              NA   416   507        10     1    28     7\n5 Bagre_mari… U     &lt;NA&gt;              NA   418   510        15     1    28     7\n# ℹ 1 more variable: Year &lt;dbl&gt;\n\n\nYou can select all columns of a given row by leaving the column index blank; for example if we want to extract the first row.\n\ncatch[1, ]\n\n# A tibble: 1 × 12\n  Site      Species Sex   Observed_Stage   PCL    FL   STL Hook_Size   Set   Day\n  &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Aransas_… Bagre_… U     &lt;NA&gt;              NA   287   353        10     1    28\n# ℹ 2 more variables: Month &lt;dbl&gt;, Year &lt;dbl&gt;\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHow would you extract the entire 5th column?\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nThere are quite a few ways to do this:\n\nyou can use indices by number (as we have done up until this point)\ninstead of index numbers you can use the column name\n\nHere are two options using indices:\n\ncatch[, 1]\n\n# A tibble: 2,325 × 1\n   Site       \n   &lt;chr&gt;      \n 1 Aransas_Bay\n 2 Aransas_Bay\n 3 Aransas_Bay\n 4 Aransas_Bay\n 5 Aransas_Bay\n 6 Aransas_Bay\n 7 Aransas_Bay\n 8 Aransas_Bay\n 9 Aransas_Bay\n10 Aransas_Bay\n# ℹ 2,315 more rows\n\ncatch[1]\n\n# A tibble: 2,325 × 1\n   Site       \n   &lt;chr&gt;      \n 1 Aransas_Bay\n 2 Aransas_Bay\n 3 Aransas_Bay\n 4 Aransas_Bay\n 5 Aransas_Bay\n 6 Aransas_Bay\n 7 Aransas_Bay\n 8 Aransas_Bay\n 9 Aransas_Bay\n10 Aransas_Bay\n# ℹ 2,315 more rows\n\n\nInstead of using indices you can also call their column names directly - both of these options will return a data.frame.\n\ncatch[\"Site\"]\n\n# A tibble: 2,325 × 1\n   Site       \n   &lt;chr&gt;      \n 1 Aransas_Bay\n 2 Aransas_Bay\n 3 Aransas_Bay\n 4 Aransas_Bay\n 5 Aransas_Bay\n 6 Aransas_Bay\n 7 Aransas_Bay\n 8 Aransas_Bay\n 9 Aransas_Bay\n10 Aransas_Bay\n# ℹ 2,315 more rows\n\ncatch[, \"Site\"]\n\n# A tibble: 2,325 × 1\n   Site       \n   &lt;chr&gt;      \n 1 Aransas_Bay\n 2 Aransas_Bay\n 3 Aransas_Bay\n 4 Aransas_Bay\n 5 Aransas_Bay\n 6 Aransas_Bay\n 7 Aransas_Bay\n 8 Aransas_Bay\n 9 Aransas_Bay\n10 Aransas_Bay\n# ℹ 2,315 more rows\n\n\n\n\n\n\n\n6.3.2 Extracting columns as vectors\nUsing [] will always return a subset of your dataframe as a data frame. Occassionally, we might want to extract the column as a vector. You can do this using square brackets [[]] or $.\n\ncatch[[\"Site\"]]\n\n   [1] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n   [4] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n   [7] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [10] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [13] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [16] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [19] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [22] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [25] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [28] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [31] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [34] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [37] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [40] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [43] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [46] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [49] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [52] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [55] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [58] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [61] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [64] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [67] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [70] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [73] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [76] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [79] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [82] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [85] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [88] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [91] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n  [94] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n  [97] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [100] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [103] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [106] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [109] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [112] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [115] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [118] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [121] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [124] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [127] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [130] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [133] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [136] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [139] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n [142] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [145] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [148] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n [151] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [154] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [157] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [160] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [163] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [166] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [169] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [172] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [175] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [178] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [181] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [184] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [187] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [190] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [193] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [196] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [199] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [202] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [205] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [208] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [211] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [214] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [217] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [220] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [223] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [226] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [229] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [232] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [235] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [238] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [241] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [244] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [247] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [250] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n [253] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [256] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [259] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [262] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [265] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [268] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [271] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [274] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [277] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [280] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [283] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [286] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [289] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [292] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [295] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [298] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [301] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [304] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [307] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [310] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [313] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [316] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [319] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [322] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [325] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [328] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [331] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [334] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [337] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [340] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [343] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [346] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [349] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [352] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [355] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [358] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [361] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [364] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [367] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [370] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [373] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [376] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [379] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [382] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [385] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [388] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [391] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [394] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [397] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [400] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [403] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [406] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [409] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [412] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n [415] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [418] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [421] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [424] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [427] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [430] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [433] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [436] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [439] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [442] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [445] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [448] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [451] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [454] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [457] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [460] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [463] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [466] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [469] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [472] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [475] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [478] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [481] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [484] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [487] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [490] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [493] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [496] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [499] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [502] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [505] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [508] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [511] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [514] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [517] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [520] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [523] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [526] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [529] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [532] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n [535] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [538] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n [541] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [544] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [547] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [550] \"Aransas_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [553] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [556] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [559] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [562] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [565] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [568] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [571] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [574] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [577] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [580] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [583] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [586] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [589] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [592] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [595] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [598] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [601] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [604] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [607] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [610] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [613] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [616] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [619] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [622] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [625] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [628] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [631] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [634] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [637] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n [640] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [643] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [646] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [649] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [652] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [655] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [658] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [661] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [664] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [667] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [670] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [673] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [676] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [679] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [682] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [685] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [688] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [691] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [694] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [697] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [700] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [703] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [706] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [709] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [712] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [715] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [718] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [721] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [724] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [727] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [730] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [733] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [736] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [739] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [742] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [745] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [748] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [751] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [754] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [757] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [760] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [763] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [766] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [769] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [772] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [775] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n [778] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [781] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [784] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [787] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [790] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [793] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [796] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [799] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [802] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [805] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [808] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n [811] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [814] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [817] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [820] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [823] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n [826] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [829] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [832] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n [835] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [838] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [841] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [844] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [847] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [850] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [853] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [856] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [859] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [862] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [865] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [868] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [871] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [874] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [877] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [880] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [883] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [886] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [889] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [892] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n [895] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [898] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [901] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [904] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [907] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [910] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [913] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [916] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [919] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [922] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [925] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [928] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [931] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [934] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [937] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [940] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [943] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [946] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [949] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [952] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [955] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [958] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [961] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [964] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [967] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [970] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [973] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [976] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n [979] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [982] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [985] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [988] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [991] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [994] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n [997] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1000] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1003] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1006] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1009] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1012] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1015] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1018] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1021] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1024] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1027] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1030] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1033] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1036] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1039] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1042] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1045] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1048] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1051] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1054] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1057] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1060] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1063] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1066] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1069] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1072] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1075] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1078] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1081] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1084] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1087] \"Aransas_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1090] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1093] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1096] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1099] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1102] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1105] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1108] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1111] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1114] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1117] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1120] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1123] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1126] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1129] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1132] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1135] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1138] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1141] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1144] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1147] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1150] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1153] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1156] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1159] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1162] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1165] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1168] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1171] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1174] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1177] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1180] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1183] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1186] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1189] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1192] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1195] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1198] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1201] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1204] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1207] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1210] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1213] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1216] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1219] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1222] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1225] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1228] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1231] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1234] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1237] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1240] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1243] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1246] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1249] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1252] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1255] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1258] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1261] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1264] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1267] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1270] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1273] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1276] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1279] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1282] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1285] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1288] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1291] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1294] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1297] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1300] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1303] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1306] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1309] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1312] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1315] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1318] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1321] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1324] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1327] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1330] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1333] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1336] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1339] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1342] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1345] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1348] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1351] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1354] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1357] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Corpus_Christi_Bay\"\n[1360] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1363] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1366] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1369] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1372] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1375] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1378] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1381] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1384] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1387] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1390] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1393] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1396] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1399] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1402] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1405] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1408] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1411] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1414] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1417] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1420] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1423] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1426] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1429] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1432] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1435] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1438] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1441] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1444] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1447] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1450] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1453] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1456] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1459] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1462] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1465] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1468] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1471] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1474] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1477] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1480] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[1483] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1486] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1489] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1492] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1495] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1498] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1501] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1504] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1507] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1510] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1513] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1516] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1519] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1522] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1525] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1528] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1531] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1534] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1537] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1540] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1543] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1546] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1549] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1552] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1555] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1558] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1561] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1564] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1567] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1570] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1573] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1576] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1579] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1582] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1585] \"Aransas_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1588] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1591] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1594] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[1597] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1600] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1603] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1606] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1609] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n[1612] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1615] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1618] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1621] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1624] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1627] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1630] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[1633] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[1636] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n[1639] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1642] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1645] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1648] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1651] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1654] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1657] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1660] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1663] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1666] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1669] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1672] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1675] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1678] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1681] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1684] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1687] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1690] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1693] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1696] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1699] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1702] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1705] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1708] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1711] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1714] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1717] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1720] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1723] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1726] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1729] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1732] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1735] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1738] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1741] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1744] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1747] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1750] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1753] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[1756] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1759] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1762] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1765] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1768] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1771] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1774] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[1777] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1780] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1783] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1786] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1789] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1792] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1795] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1798] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1801] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1804] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1807] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1810] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1813] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1816] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1819] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1822] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1825] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1828] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1831] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1834] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1837] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1840] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1843] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1846] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1849] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1852] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1855] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1858] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1861] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1864] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1867] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1870] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1873] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1876] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[1879] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1882] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1885] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1888] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1891] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1894] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1897] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1900] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1903] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1906] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1909] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1912] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1915] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1918] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1921] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1924] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1927] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1930] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1933] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1936] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1939] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1942] \"Aransas_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1945] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1948] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1951] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1954] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1957] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1960] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1963] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1966] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1969] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1972] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n[1975] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1978] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1981] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1984] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1987] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1990] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1993] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1996] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1999] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2002] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2005] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2008] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2011] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2014] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2017] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2020] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2023] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2026] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2029] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2032] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[2035] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2038] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2041] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2044] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2047] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2050] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2053] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2056] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2059] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2062] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2065] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Corpus_Christi_Bay\"\n[2068] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2071] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[2074] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2077] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2080] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2083] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2086] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2089] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2092] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2095] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2098] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2101] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2104] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2107] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2110] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2113] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2116] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2119] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[2122] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2125] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2128] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2131] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[2134] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2137] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2140] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[2143] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2146] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2149] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2152] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n[2155] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2158] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2161] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2164] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2167] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2170] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2173] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2176] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2179] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2182] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2185] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[2188] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2191] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2194] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2197] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2200] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2203] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2206] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2209] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2212] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2215] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2218] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2221] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2224] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2227] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2230] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2233] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2236] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2239] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2242] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2245] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2248] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2251] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2254] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2257] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2260] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2263] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2266] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2269] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2272] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2275] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2278] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2281] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2284] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2287] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2290] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2293] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Corpus_Christi_Bay\"\n[2296] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2299] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2302] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2305] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2308] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2311] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2314] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[2317] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2320] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2323] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n\ncatch$Site\n\n   [1] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n   [4] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n   [7] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [10] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [13] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [16] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [19] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [22] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [25] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [28] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [31] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [34] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [37] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n  [40] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [43] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [46] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [49] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [52] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [55] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [58] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [61] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [64] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [67] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [70] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [73] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [76] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [79] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [82] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [85] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [88] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n  [91] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n  [94] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n  [97] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [100] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [103] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [106] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [109] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [112] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [115] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [118] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [121] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [124] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [127] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [130] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [133] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [136] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [139] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n [142] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [145] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [148] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n [151] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [154] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [157] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [160] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [163] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [166] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [169] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [172] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [175] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [178] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [181] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [184] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [187] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [190] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [193] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [196] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [199] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [202] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [205] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [208] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [211] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [214] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [217] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [220] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [223] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [226] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [229] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [232] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [235] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [238] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [241] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [244] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [247] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [250] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n [253] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [256] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [259] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [262] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [265] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [268] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [271] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [274] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [277] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [280] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [283] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [286] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [289] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [292] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [295] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [298] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [301] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [304] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [307] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [310] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [313] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [316] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [319] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [322] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [325] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [328] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [331] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [334] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [337] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [340] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [343] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [346] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [349] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [352] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [355] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [358] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [361] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [364] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [367] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [370] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [373] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [376] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [379] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [382] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [385] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [388] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [391] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [394] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [397] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [400] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [403] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [406] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [409] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [412] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n [415] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [418] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [421] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [424] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [427] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [430] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [433] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [436] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [439] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [442] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [445] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [448] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [451] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [454] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [457] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [460] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [463] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [466] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [469] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [472] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [475] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [478] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [481] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [484] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [487] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [490] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [493] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [496] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [499] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [502] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [505] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [508] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [511] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [514] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [517] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [520] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [523] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [526] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [529] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [532] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n [535] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [538] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n [541] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [544] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [547] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [550] \"Aransas_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [553] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [556] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [559] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [562] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [565] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [568] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [571] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [574] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [577] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [580] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [583] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [586] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [589] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [592] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [595] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [598] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [601] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [604] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [607] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [610] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [613] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [616] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [619] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [622] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [625] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [628] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [631] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [634] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [637] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n [640] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [643] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [646] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [649] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [652] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [655] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [658] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [661] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [664] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [667] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [670] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [673] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [676] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [679] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [682] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [685] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [688] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [691] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [694] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [697] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [700] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [703] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [706] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [709] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [712] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [715] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [718] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [721] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [724] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [727] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [730] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [733] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [736] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [739] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [742] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [745] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [748] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [751] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [754] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [757] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [760] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [763] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [766] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [769] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [772] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [775] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n [778] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [781] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [784] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [787] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [790] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [793] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [796] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [799] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [802] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [805] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [808] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n [811] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [814] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [817] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [820] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [823] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n [826] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [829] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [832] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n [835] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [838] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [841] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [844] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [847] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [850] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [853] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [856] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [859] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [862] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [865] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [868] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [871] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [874] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [877] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [880] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [883] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [886] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [889] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [892] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n [895] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [898] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [901] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [904] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [907] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [910] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [913] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [916] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [919] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [922] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [925] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [928] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [931] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [934] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [937] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [940] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [943] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [946] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [949] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n [952] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [955] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [958] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [961] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [964] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [967] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [970] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [973] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n [976] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n [979] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [982] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [985] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [988] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [991] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n [994] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n [997] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1000] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1003] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1006] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1009] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1012] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1015] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1018] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1021] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1024] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1027] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1030] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1033] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1036] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1039] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1042] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1045] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1048] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1051] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1054] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1057] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1060] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1063] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1066] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1069] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1072] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1075] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1078] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1081] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1084] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1087] \"Aransas_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1090] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1093] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1096] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1099] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1102] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1105] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1108] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1111] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1114] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1117] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1120] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1123] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1126] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1129] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1132] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1135] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1138] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1141] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1144] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1147] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1150] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1153] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1156] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1159] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1162] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1165] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1168] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1171] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1174] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1177] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1180] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1183] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1186] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1189] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1192] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1195] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1198] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1201] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1204] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1207] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1210] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1213] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1216] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1219] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1222] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1225] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1228] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1231] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1234] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1237] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1240] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1243] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1246] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1249] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1252] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1255] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1258] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1261] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1264] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1267] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1270] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1273] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1276] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1279] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1282] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1285] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1288] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1291] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1294] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1297] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1300] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1303] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1306] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1309] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1312] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1315] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1318] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1321] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1324] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1327] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1330] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1333] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1336] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1339] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1342] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1345] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1348] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1351] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1354] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1357] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Corpus_Christi_Bay\"\n[1360] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1363] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1366] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1369] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1372] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1375] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1378] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1381] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1384] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1387] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1390] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1393] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1396] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1399] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1402] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1405] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1408] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1411] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1414] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1417] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1420] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1423] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1426] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1429] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1432] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1435] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1438] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1441] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1444] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1447] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1450] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1453] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1456] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1459] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1462] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1465] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1468] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1471] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1474] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1477] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1480] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[1483] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1486] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1489] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1492] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1495] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1498] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1501] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1504] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1507] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1510] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1513] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1516] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1519] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1522] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1525] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1528] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1531] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1534] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1537] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1540] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1543] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1546] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1549] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1552] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1555] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1558] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1561] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1564] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1567] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1570] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1573] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1576] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1579] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1582] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1585] \"Aransas_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1588] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1591] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1594] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[1597] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1600] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1603] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1606] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1609] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n[1612] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1615] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1618] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1621] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1624] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1627] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1630] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[1633] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[1636] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n[1639] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1642] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1645] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1648] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1651] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1654] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1657] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1660] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1663] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1666] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1669] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1672] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1675] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1678] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1681] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1684] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1687] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1690] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1693] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1696] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1699] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1702] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1705] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1708] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1711] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1714] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1717] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1720] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1723] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1726] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1729] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1732] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1735] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1738] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1741] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1744] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1747] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1750] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1753] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[1756] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1759] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1762] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1765] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1768] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1771] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1774] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[1777] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1780] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1783] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1786] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1789] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1792] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1795] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1798] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1801] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1804] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1807] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1810] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1813] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1816] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1819] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1822] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1825] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1828] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1831] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1834] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1837] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1840] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1843] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1846] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1849] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1852] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1855] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1858] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1861] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1864] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1867] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1870] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1873] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1876] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[1879] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1882] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1885] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1888] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1891] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1894] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[1897] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1900] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1903] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1906] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1909] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1912] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1915] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1918] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1921] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1924] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1927] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1930] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1933] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1936] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1939] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[1942] \"Aransas_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1945] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1948] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1951] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1954] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1957] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[1960] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1963] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1966] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1969] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[1972] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n[1975] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1978] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1981] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1984] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1987] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1990] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1993] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1996] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[1999] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2002] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2005] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2008] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2011] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2014] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2017] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2020] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2023] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2026] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2029] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2032] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[2035] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2038] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2041] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2044] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2047] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2050] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2053] \"Redfish_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2056] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2059] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2062] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2065] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Corpus_Christi_Bay\"\n[2068] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2071] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[2074] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2077] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2080] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2083] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2086] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2089] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2092] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2095] \"Aransas_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2098] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2101] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2104] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2107] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2110] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2113] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2116] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2119] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Redfish_Bay\"       \n[2122] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2125] \"Redfish_Bay\"        \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2128] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2131] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[2134] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2137] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2140] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Redfish_Bay\"       \n[2143] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2146] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2149] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2152] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Corpus_Christi_Bay\"\n[2155] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2158] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2161] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2164] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2167] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2170] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2173] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2176] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2179] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2182] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2185] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Aransas_Bay\"       \n[2188] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2191] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2194] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2197] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2200] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2203] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2206] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2209] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2212] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2215] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2218] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2221] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2224] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2227] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2230] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2233] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2236] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2239] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2242] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2245] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2248] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2251] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2254] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2257] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2260] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2263] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2266] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2269] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2272] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2275] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2278] \"Corpus_Christi_Bay\" \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2281] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2284] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2287] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2290] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2293] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Corpus_Christi_Bay\"\n[2296] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2299] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2302] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2305] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2308] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n[2311] \"Corpus_Christi_Bay\" \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2314] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Aransas_Bay\"       \n[2317] \"Aransas_Bay\"        \"Aransas_Bay\"        \"Aransas_Bay\"       \n[2320] \"Redfish_Bay\"        \"Redfish_Bay\"        \"Redfish_Bay\"       \n[2323] \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\" \"Corpus_Christi_Bay\"\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nCreate a vector of all the species in the data set called species.\n\n\nIf you call the vector by typing its name (species) in the console you will notice that it repeats the species names.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nExecute the following code chunk and describe what this function does:\n\nunique(species)\n\n\n\nUsing indices might seem a little bit clunky, e.g. you have to know which column and row is which by position but it has its practical applications and is computationally very fast. For most of our data wrangling we will be using functions from the tidyverse packages dplyr and tidyr which work a little bit more intuitively."
  },
  {
    "objectID": "06_data-frames.html#write-data.frame-to-file",
    "href": "06_data-frames.html#write-data.frame-to-file",
    "title": "6  Intro to dataframes",
    "section": "6.4 Write data.frame to file",
    "text": "6.4 Write data.frame to file\nFrequently, we will process raw data sets and then need to write intermediate or final results to file, for example to share them with collaborators. Here, the readr packages comes in handy.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nCreate a subset of our data set consisting of the first 100 rows and containing information on the species, sex and fork length. Then use the help page for the function write_delim() to figure out how to write out a tab-delimited file into your data folder."
  },
  {
    "objectID": "05_data-management.html#wait-spreadsheets",
    "href": "05_data-management.html#wait-spreadsheets",
    "title": "5  Data management using spreadsheets",
    "section": "5.1 Wait… spreadsheets?",
    "text": "5.1 Wait… spreadsheets?\nThe foundation of any research project is good data organization. This not only includes your actual data points (observations) but also things like keeping track of specimen and other samples along with all the meta-data2. Additionally, you should keep good records of how the data was produced (your methods). Thinking through ahead of time what measurements are important, i.e. what data you will record and how you will store your data is really important to make sure you are keeping track of the entire process. Good data management and clean data sets will make sharing and analyzing data a lot more straightforward.2 Metadata is data about your data. It helps describe, categorize, organize, and provide context to the main content or primary data it is associated with. It’s commonly used to provide additional information that helps users, systems, or processes understand and interpret the main data.\nWhile we are going to use R to wrangle, manipulate, analyze, and visualize data in R for a more efficient and reproducible approach compared to what can be using spreadsheets, spreadsheets are the better tool for data entry, data management/organization, and simple quality control (QC) and quality assurance (QA). Thinking ahead to how you want to organize and format your data in spreadsheets will prevent a lot of extra work and headaches down the line, especially when we plan ahead as to how we should organize it to make it more efficient to use with command-line computational tools such as R.\nSo, before we dive deep into manipulating data with R, we’ll take a small step back and think through a few fundamental rules for managing data in spreadsheets before learning how to do these and more advanced data wrangling and manipulation using R.\nWhile you can do some statistics and plotting using spreadsheet programs we will not be learning how to do this in this class. Data analysis in spreadsheets requires a lot of manual work and generally any time you want to change one parameter or if you have to update your spreadsheet with new entries or you need to apply the same analysis to another data set you end up having to redo everything by hand. The more things you do by hand, the more likely you are to make a mistake. Even if you do apply some sophisticated coding in spreadsheets and/or use it for analysis or plotting3 it is very difficult to track the exact steps or document them in a way that makes it fully reproducible for another person.3 It can be helpful to know the fundamentals for simple plots in spreadsheets for quick and dirty plotting to get a quick look at your data to get an idea of what it looks like and spot potential mistakes during data entry without having to export data and fire up R or a another command-line program."
  },
  {
    "objectID": "05_data-management.html#best-practices-for-formatting-data-in-spreadsheets",
    "href": "05_data-management.html#best-practices-for-formatting-data-in-spreadsheets",
    "title": "5  Data management using spreadsheets",
    "section": "5.2 Best practices for formatting data in spreadsheets",
    "text": "5.2 Best practices for formatting data in spreadsheets\n\n5.2.1 Format your data set for the tool you will use to analyze it with\nOur brains don’t work the same way as computers. Your spreadsheet is not a lab notebook and while a layout where there are notes in the margin, context of the experiment, or a specific layout of data might be something that you can interpret, it will more difficult for another person to forllow your through process and understand your records/notes. Another person might have the opportunity to ask follow up questions and get the clarifications they need, but a computer cannot.\nOccasionally, you might use a spreadsheet instead of a lab notebook where it is a way of keeping track of an experiment and various people interacting with samples, completing different steps etc. However, if you are using a spreadsheet for data entry and management, then you want to ensure that you have set up your spreadsheet in a way where a computer is going to be able to correctly interpret it as intended. This means that we need to think through how we want to set up spreadsheets. There are generally a few different ways you can set things up and some of them will limit how easy it is for you and/or a future collaborator to work with it down the line4.4 the optimum software/interface for data input and layout/formatting may differ depending on your intended analysis, so keep in mind how you want to be able to analyze your data and whether that will require specific formats. In general, try to pick a format that will give you the advantage of being able to easily convert it between different formats - which is something we will learn to do with R specifically in the tidyverse which centers on a specific concept of what makes data tidy.\n\n\n5.2.2 Never touch your raw data\nRaw data is the original, unaltered data that is collected or generated before any manipulation, transformation, or analysis takes place. It’s the most fundamental form of data, directly obtained from observations, measurements, or data sources. Raw data is often in its most unstructured and basic state, and it serves as the foundation for subsequent data processing and analysis.\nIn the biological and environmental sciences typical sources include direct observations made in experiments, field studies, or natural phenomena or measurments from sensors or other instruments measuring physical and chemical parameters such as temperature, GPS coordinate, pH etc.\n\n\n\n\n\n\nBe mindful\n\n\n\nNever touch your raw data. Always keep a copy of your raw data that you never modify directly.\n\n\nFor any kind of data related work it is important that you preserve the original, unaltered version of your data when conducting data analysis. Avoid making changes directly to the original data files or data set. Instead, You should work with copies of the data or use a structured workflow that ensures the integrity and reproducibility of your analysis.\nKeeping your raw data as a separate file that is never altered is important for\n\nData Integrity: Modifying the raw data directly could lead to unintended changes or loss of information. By keeping the raw data untouched, you ensure that you have a reliable source of truth to refer back to if needed.\nReproducibility: If you or others need to replicate your analysis in the future, having access to the exact original data is crucial. Changes made to the raw data could make it difficult or impossible to reproduce your results accurately.\nError Prevention: Working with copies of the raw data minimizes the risk of accidental changes or mistakes that could affect your analysis. If errors occur, you can always go back to the untouched raw data.\nData Auditing: In some cases, you might need to show the authenticity and accuracy of your data. Keeping the original data untouched allows you to demonstrate the reliability of your work.\nMultiple Analyses: If you’re working on different analyses, projects, or collaborations using the same data, maintaining the integrity of the raw data enables consistency across these efforts.\n\nBest practices of maintaining the integrity of your raw data include * making copies: Always work with copies of the original data files or datasets. This ensures that any changes you make are isolated from the raw data. * implementing a structured workflow: Develop a structured workflow that includes data cleaning, transformation, and analysis steps. Document each step thoroughly to ensure transparency and repeatability. * using version vontrol: Use version control systems like Git to track changes to your code and analysis scripts. This allows you to see how your analysis evolves over time. * creating backups: Regularly back up your data, including both the raw data and any processed versions, to prevent data loss. * creating documentation: Maintain clear and detailed documentation about the steps you’ve taken, the rationale behind your decisions, and any changes you’ve made to the data.\n\n\n5.2.3 Keep track of your formatting steps\nBy working with copies and following a structured workflow, you can ensure the accuracy, reproducibility, and integrity of your data analysis work. While you shouldn’t modify the raw data directly, it’s also important to apply necessary data preprocessing steps (like cleaning and transforming) as part of your analysis process. This means that you should do two things\n\nAny time you need to process or analyze your data make a copy instead of operating directly in your raw data5 and then create a new file with your cleaned or analyzed data.\nKeep track of the exact steps you took to clean or analyze your data6; this is just as important as keeping a detailed record of the steps you took in an experiment. Good practice would be to keep a plain text file or similar in the same folder as your data set where you record any steps you take.\n\n5 In our next lesson you are going to see that this is a key advantage of command line programs like R where you can read a raw data set into the program and then apply specific data wrangling, manipulation and analysis steps without altering the raw data.6 The second advantage of command-line programs like R is that because you are using a series of commands to wrangle and analyze your data your are automatically creating a very detailed, reproducible record of your your workflow\n\n5.2.4 Put variables in columns and observations in rows\nObservations and variables are two fundamental concepts that describe different aspects of data.\n\n\n\n\n\n\n Consider this\n\n\n\nCompare and contrast what an observation is compared to a variable.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nAn observation is a single data point or unit within a data set, while a variable is a characteristic that is being measured or observed for each of those data points.\nTogether, observations and variables make up the structure of a data set, where each observation has values for the various variables being measured.\n\n\n\nHere is the key rule for structuring data in spreadsheet:\nEvery variable gets its own column, every observation gets its own rule, do not combine multiple pieces of information in one cell7.7 This is what we will refer to as tidy data. We will explore this concept more in depth down the line and will play “Is it tidy?” regularly this semester.\n\n\n5.2.5 Export data as text-based formats\nWhile it is a lot easier to enter and look at data in a spreadsheet you should always export your raw and cleaned data set as a text-based format such as CSV, TSV, JSON, XML, etc.).\nThis offers several advantages compared to proprietary binary formats8:8 an example would be Excel’s .xlsx\n\nInteroperability: Text-based formats are widely supported by various software and programming languages. This means that data can be easily shared and integrated into different applications and systems, regardless of the software being used. Especially if program have proprietary formats having a format that is platform independent is really important.\nSimplicity: Text-based formats have a simple, human-readable structure. This makes it easier to understand the data’s content, and it allows manual inspection and editing using basic text editors.\nVersion Control: Text-based formats work well with version control systems (e.g., Git). Since changes can be easily tracked in plain text, it’s easier to collaborate, review, and manage changes made to the data. & Data Integrity: Text-based formats are less prone to corruption and data loss. Proprietary binary formats can sometimes become corrupted, making data recovery difficult.\nPlatform Independence: Text-based formats are platform-independent. They can be used on different operating systems without compatibility issues\nReduced File Size: Text-based formats generally have smaller file sizes compared to their binary counterparts. This can be advantageous for sharing and storage, especially when dealing with large datasets.\nAutomation and Scripting: Text-based formats are well-suited for automation and scripting tasks. Many programming languages have libraries and tools to read and write data from these formats easily.\nData Analysis: Text-based formats can be directly used in data analysis workflows. Data scientists and analysts often use tools like Python, R, and SQL to work with text-based data formats.\nData Accessibility: When sharing data with others, especially outside your organization, text-based formats offer a universal way to provide data that can be imported into various tools without compatibility issues."
  },
  {
    "objectID": "05_data-management.html#common-spreadsheet-formatting-issues",
    "href": "05_data-management.html#common-spreadsheet-formatting-issues",
    "title": "5  Data management using spreadsheets",
    "section": "5.3 Common spreadsheet formatting issues",
    "text": "5.3 Common spreadsheet formatting issues\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly describe common formatting mistakes formatting data in spreadsheets, explain why it might be tempting to format data in this way and why it might cause downstream issues for data analysis.\n\n\n\n\n\n\n\n\n Pointers\n\n\n\n\n\nHere are the key points you will want to discuss:\n\nmultiple tables in one tab\ndata spread across multiple tabs\nnot filling in zeros\nusing problematic null values for missing data\nusing formatting to convey information\nusing formatting to make the data sheet look pretty\nplacing comments or units in cells\nentering more than one piece of information per cell\nusing problematic field/column names\nusing special characters in data\nincluding metadata in the data table\ndate formatting"
  },
  {
    "objectID": "05_data-management.html#dates-are-data-but-like-the-worst-kind",
    "href": "05_data-management.html#dates-are-data-but-like-the-worst-kind",
    "title": "5  Data management using spreadsheets",
    "section": "5.4 Dates are data (but like, the worst kind)",
    "text": "5.4 Dates are data (but like, the worst kind)\nProbably the most intuitive way to store dates in a spreadsheet would be to create a column called date and then just store your dates in there.\n\n\n\n\n\n\n Consider this\n\n\n\nQuick. Off the top of your head come up with 10 ways that you could format a date.\n\n\nSo that’s the first problem - what should a date even look like? Problem two is that while to you the human this would be the most natural way to do this, the spreadsheet might be displaying it in a way that makes sense to you but is actually storing it in a very different format. Additionally, different spreadsheet programs (Microsoft Excel, Google Sheets, LibreOffice, OpenOffice) might be storing and handling dates slightly different from each other. In this case the date functions valid for one might be only somewhat-ish compatible with each other. Additionally, spreadsheet programs generally are trying to automatically recognize dates so e.g. gene/protein names like MAR1, OCT4 would be interpreted to dates and getting the original identifier back might be tricky.\nAdditionally spreadsheets sometimes try to be especially helpful by autocompleting information.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nOpen the exercise-dates Google Sheets document in the scratch folder of the 01_SharkNurseries folder. Label cell A1 as location and cell B1 as date_sample-1. In cell A2-16 type in A, B, … . Then in cell B2 type a date as just month/day. Hit enter, then click back on the cell and look at the value bar at the top. Describe what you observed and how this “helpful” behavior could lead to data entry problems.\n\n\nYou can switch between different data formats by customizing the format of the cell.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nIn your Google Sheets document type a few dates in cells B3 - B6. Next, highlight column A. and click on the 123 button in the tool bar. Select Custom Date and Time and describe what type of formatting options you have. Pick one, and see how it changes how the content of your cells is displayed.\n\n\nFor some of the more elaborate formats if you look at the value bar you will notice that even though the content of your cell has changed in terms of how it is formatted, that value might not necessarily match the cell content. How does the spreadsheet program so easily convert between all the different formats?\n\n\n\n\n\n\n Give it a whirl\n\n\n\nLet’s assume that you revisited every site 15 days after the initial visit. In your Google Sheets document type date_sample2 in cell C1. Now in cell C2 type B2 + 15. Describe what happens.\n\n\nWait? Since when can you just add an integer and a date? Aren’t those completely different data formats?\n\n\n\n\n\n\n Give it a whirl\n\n\n\nHighlight column B. Now Click on the 123 button in the toolbar and select Automatic. Describe what you see. Speculate what this means about how spreadsheet programs actually store dates and what implications this could have if you export spreadsheets as text files.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGoogle Sheets is actually storing dates as integers from a default day of December 31, 1899. This can be useful, spreadsheet programs were initially developed for and most heavily used for accounting, so the option of being able to in a straightfoward way add days, months, or years to a given date is quite practical.\nHowever, if you export as a text file you can run into the issue that you text file now has a column with an integer where you expected a date.\nAs a side note it also becomes problematic if you are using dates before December 31, 1899 because it cannot parse them correctly.\n\n\n\nIt is a lot safer to store dates in spreadsheets not as date but rather in three columns as year, month, day. Another option is to use Julian Day or day of the year. Or you can store as a single string as YYYYMMDD you can do the same for time stamps as YYYYMMDDhhmmss. This has advantages in terms of sorting by assending and descending order and you do not have to worry about converting to text.\nIf you were to read this format into R it would initially think that it is an integer, however there are functions that we can use to tell R that it is actually a date and what format it is, and then we would be able to apply functions to extract year, month etc into other programs.\nIn sum, treat dates as multiple pieces of data to make them easier to handle downstream."
  },
  {
    "objectID": "05_data-management.html#quality-assurance-and-control",
    "href": "05_data-management.html#quality-assurance-and-control",
    "title": "5  Data management using spreadsheets",
    "section": "5.5 Quality assurance and control",
    "text": "5.5 Quality assurance and control\nYou will frequently hear people say something along the lines of “oh we still have to QC the data” or “we need to complete QA/QC before we can analyze the data. QA stands for quality assurance and QC stands for quality control and both processes are critical to ensure that data being used moving forward is accurate, reliable and valid.\nQuality assurance focuses on preventing errors and ensuring that the proceses used to generate and enter the data are effective and efficient and minimize error. It involves establishing guidelines, standards, and best practices to be followed during the processes. The goal is to identify and address potential issues before they can occur or at least as early as possible in the process.\nBy contrast, quality control focuses on identifying errors that may have occured during the process of generating and entering data by performing checks and tests at various stages of the process to verify that the final output meets the predefined quality standards.\nEnsuring that we have accurate and consistent data collection methods, checking for and removing or correcting data entry errors, and validating data against predefined criteria is a critical step in (data) science. It is important that you keep a good record of the steps you took, rules you apply to discern “good” vs “bad” errors, and which data was removed to ensure transparency and repeatability.\nOne important component of quality assurance is stopping from bad data being entered in the first place by creating a list of valid values which will then prohibit false values from being entered. For example, we might be working with different types of gear to catch sharks at each location, longlines, gillnets, and hook-and-line. It would be easy to accidentally mistype one of these gear types or forget whether we are entering everything lowercase or using capitalization.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nIn your Google Sheet in column D type gear. Then place your cursor in cell D2 and navigate to Data &gt; Data Validation which will bring up a dialog on the right sight of your screen. Click on Add rule.\nIn the Apply to range box it will currently say Sheet1!D2, you can extend this to include all cells from D2 to D6 by modifying this to Sheet1!D2:D6 (or by marking the area in the spreadsheet). Click on the Criteria Dropdown menu to see how many different types of options you have to set rules in terms of what is allowed to be entered into the cells to which you are applying this rule.\nWe are going to use a Dropdown. By default you will have two fields. Fill those out as longline and gillnet. Then click on add another item and add hook-and-line.\nCheck out the advance options which allows you to change whether you just get a warning or the input is rejected if your entry is invalid, you can also play with the display style to see how that affects the formatting and ease of use. Then click Done.\nWe have a short list of options so you you can easily see all three and select the correct one. For longer lists it is more helpful that you can start typing in you data and then select it.\n\n\nYou can see how this option is helpful for categorical data where typos are an issue. But you can also restrict dates to certain time periods or numbers to certain values.\nUsing these types of rules help minimize errors, however it is almost inevitable that something will sneak in eventually which is where quality control comes in.\n\n\n\n\n\n\nBe mindful\n\n\n\nRemember, before you implement any quality control measure you want to make sure that you make a copy of your data and save the original data as your raw, unaltered data set. You will want to make sure that the file name reflects that it is your raw data.\nCreate a separate file that you will then clean, make sure that your filename includes some sort of versioning and/or a date so you have a good record of when you processed a data set. Then you want to make sure that your data are all values and not formulas which refer to specific cells. Once you start moving cells around this can screw with your data.\nYou will also want to create a text-file (a typical filename would be README) that keeps track of all your files and manipulations so that future you or a collaborator can easily understand and replicate any steps that you take.\n\n\nThe goal of QC is to find erroneous data. This means that it is generally going to stick out from the rest of the values in a specific column9.9 Errors are not the same as outliers. Sometimes you know that e.g. certain values cannot be true, for example if all your sample locations where in the northern hemisphere then you cannot have latitudes from the southern hemisphere.\nWe can generally make the assumption that the vast majority of your data is correct. This means that if we sort the values in a column if there are a few errors they will stick out and in many cases they will sort at the very top or very bottom. For example, if your column is numeric anything that is a character will pop out or if you have null values or empty cells they will generally sort to the bottom of a column.\n\n\n\n\n\n\nBe mindful\n\n\n\nAny time you are going to sort data, make sure that you are sorting the entire dataset not just a single column or you will corrupt your data set and everything will end up scrambled.\nGenerally, if you don’t have any empty columns or too much missing data if you place the cursor in a cell with a value you can use the shortcut Ctrl/Cmd + A to select all.\nAlways double check that you have expanded your sort to the entire data set\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nIn the scratch folder, open up the catchdata_messy Google Sheet. Then sort each column and see which errors you can spot.\nMake the entire data set is highlighted. Then go select Data &gt; Sort range &gt; Advanced sorting options. Make sure you check the Data has header row option. Then use the sort by drop down menu to select the column you want to sort. Once you are ready, cleock sort.\nThen inspect your column to determine if there are unexpected values and describe your observations. Discuss what you will do with you findings - consider whether it is better (more ethical/responsible) to remove them or correct them.\n\n\nSimilarly, we can use conditional formatting which allows you to apply specific rules for automatically color coding to a column based on specific rules. This makes it easier for unusual entries or entries outside the possible boundaries to stand out.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nIn the catchdata_messy Google Sheet, highlight the STL column. The select Format &gt; Conditional formatting from the toolbar. This will pull up a dialog on the right hand of your window.\nSimilar to the Data Validation dialog, you can select the range you want to apply this rule to either by typing it in or selecting it directly in the spreadsheet.\nClick on the Format rules dropdown menus and look through the available options. Let’s say that we know that the sharks cannot be smaller than 50cm or larger than 2m. Set up rules for conditional highlighting that will allow you to quickly pull out invalid entries.\nClick Done once you are all set and evaluate your results.\n\n\nEspecially for smaller data sets being able to quickly scan for errors can be really helpful, however, down the line we will also learn how to use similar principles to identify errors using R.\n\n\n\n\n\n\n Consider this\n\n\n\nArgue the pros and cons of doing QA/QC directly in the spreadsheet compared to using a command-line program like R."
  },
  {
    "objectID": "05_data-management.html#exporting-data",
    "href": "05_data-management.html#exporting-data",
    "title": "5  Data management using spreadsheets",
    "section": "5.6 Exporting data",
    "text": "5.6 Exporting data\nGenerally, want to make sure that we are storing our data in a universally accessible, open, and static format rather than e.g. the default Excel file format (*.xls or *.xlsx).\n\nExcel files have a proprietary format and it is possible that in the future technology will change and you will no longer be able to access your files.\nother program may not be able to read Excel formatted files.\ndifferent version of Excel may handle data differently which can lead to inconsistencies.\nfrequently journals or grant agencies require you to deposit your data in a data repository that only accepts certain formats which may not include Excel.\n\n\n\n\n\n\n\n Consider this\n\n\n\nDiscuss whether you think Google Sheets has the same problems or if it is an acceptable format to avoid these issues.\n\n\nText-based formats such as comma-delimited (*.csv) or tab-delimited (*.txt or *.txv) files overcome these issues. In CSV files, columnes are separated by commas and in tab-delimited files by tabs10. The advantage of text files is that they can be opened in any plain text editors11 but you can also import them into spreadsheet programs or command-line programs like R.10 This will look like whitespace if you look at it in a text editor, but tabs, but using whitespace can cause issues when command-line files parse them, tabs are less ambiguous11 Your operating system will have a built in plain text editors such as notepad. However, you are regularly operating with textfiles it can be helpful to have a more powerful program like Notepad++ or Atom.\n\n\n\n\n\n\n Give it a whirl\n\n\n\nOpen the Excel spreadsheet longline_catchdata.xlsx in the data folder of the project directory you downloaded.\nSelect File &gt; Save as from the ribbon, then select Comma Separated Values (*.csv) from the list. Double check the file location and name then click Save.\nNow, repeat the same process to export as a tab-delimited file. You will have multiple options to export as text file, make sure that it says tab-delimited.\nOpen both files in a text editor and compare them. If you double click on a *.csv file your computer will typically open it in excel, you may need to right click and then select open with to open in a text editor.\n\n\nYou will find that I habitually use tab-delimited files because in Germany we use a , instead of a . for our decimals which means that data values can include commas and therefore exporting as *.csv files can cause a bit of chaos. However, as you pick a data set for your course project you will more likely end up with *.csv files.\n\n\n\n\n\n\nTip\n\n\n\nGoogle Sheets now make it a lot easier to export and download copies of spreadsheets in different formats including *.csv by selecting File &gt; Download from the main toolbar and the choosing comma-delimited or tab-delimited from the drop down menu."
  },
  {
    "objectID": "05_data-management.html#acknowledgments",
    "href": "05_data-management.html#acknowledgments",
    "title": "5  Data management using spreadsheets",
    "section": "5.7 Acknowledgments",
    "text": "5.7 Acknowledgments\nThis chapter is adapted from data carpentries “Data Organization in Spreadsheets for Ecologists lesson."
  },
  {
    "objectID": "04_Rproj.html#learning-objectives",
    "href": "04_Rproj.html#learning-objectives",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.1 Learning Objectives",
    "text": "4.1 Learning Objectives\nAfter completing this tutorial you should\n\nbe able to set up a well structured research compendium1.\nunderstand what a working directory is and how to set up an R project.\nunderstand the value of using Rmarkdown and quarto documents to document your work.\nunderstand the core components of the markdown format.\nbe able to use basic markdown syntax to format a document (headers, bold/italics).\nbe able to add a code chunk to a .qmd file and add options.\nunderstand how to modify code chunk options to determine what is/is not rendered in the knitted document.\nknow how to render a document to produce an *.html file from an *.qmd2.\n\n1 We will at a later point in this semester revisit and determine if this truly is a well-structured folder structure2 the recent implementation of quarto has made exporting to other formats such as pdf a lot more straightforwardThe goal of open science and reproducible research is to make scientific methods, data, and results more transparent, available, and reproducible. Quarto documents written in markdown are a useful tool to be able to generate reports documenting your data, methods (code used to process data), and results. Recently quarto has been implemented as a authoring framework for data science that extends past previous use of Rmarkdown focused on R and makes it easy to include python and other coding languages.\nSimilar to R markdown (*.Rmd) files, quarto documents will let you document your workflow, share how you processed/analyzed your data and the resulting output along with any visualizations. Quarto unifies and extends the functionality of several packages that were devoloped around using R markdown unto a consistent system that supports several coding languages beyond R including python and Julia. This is a text based file format that consists of standard text, code chunks, and the resulting output using a very simple syntax (henc markdown as opposed to markup languages like html or LateX which have much more complicated syntax). When you render your document, the code is executed and the resulting output with be included in the rendered document (common formats are html or pdf). Advantages to a workflow centered around using quarto and markdown to document your work include:\n\nthe simple syntax makes it easy to learn the basics (but some of the more advance options will let you create some sophisticated reports)3.\nresulting files have a simple, standardized formatting that looks professional and is easy to read and understand (code, documentation, figures all in one place).\nfuture you will be thankful when you don’t have to remember your assumptions, individual steps, and modifications.\neasy modification to extend/refine analysis or re-run with updated data.\n\n3 Rstudio now also has a visual editor so you can really get away with knowing very little markdown, though the basics can’t hurt and knowing a few tricks like inline code will let you do some pretty cool stuff with your documents\n\n\n\n\n\nNote\n\n\n\nUse this link to access a quarto cheatsheet for a quick overview on publishing and sharing with quarto. You can also download a pdf summarizing the core quarto functionalities to keep handy as you get used to setting up quarto documents.\nSimilarly, Use this link to access a rmarkdown cheatsheet. We won’t be using Rmarkdown documents but the syntax of writing in markdown is the same. You can also download and print a pdf for easy access."
  },
  {
    "objectID": "04_Rproj.html#project-organization-101",
    "href": "04_Rproj.html#project-organization-101",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.2 Project organization 101",
    "text": "4.2 Project organization 101\nA key component to doing data analysis is organizing your working directory which will contain your data, scripts, quarto-documents, results, figures, and other output. Keeping this well organized will help you establish a reproducible workflow, collaborate well, and share your results.\n\n4.2.1 Organizing your files and directories\nFor each project/lab we will set up a project directory4 with the following set of sub-directories:4 We’ll use this term interchangeably with working directory and research compendium\n\ndata\nresults\nscr\nscratch\n\nYou will want to set up a folder (directory) locally5 on your computer called bi349 that you will use throughout this semester for all the project directories, a good place is your Documents directory or in a pinch your desktop. You will frequently download an entire research compendium with data and quarto documents “preloaded”. Macs will automatically unzip those folders on a Windows computer you will need to do this by hand (right click &gt; extract all), then move that folder into your bi329 directory. Make sure you are running your Rprojects out of the correct folder - this is one of the most common issues we run into when things aren’t working as they should.5 Local means that it is physically on your computer hard drive. If you have an automatic integration with a cloud storage service like OneDrive past experience has shown that you can run into difficulties, so yes, cloud backup is good but make sure that you are running your projects locally off your computer\n\n\n4.2.2 A note on Naming things\nNaming conventions for files, sub-directories etc. should conform to the following key principles that form the holy trinity of file naming6:6 see Jenny Bryan’s excellent summary of these principles\n\nHuman readable: keep it short but self-explanatory.\nMachine readable: don’t use special characters or spaces.\nSortable: standardize components of the file names to make it possible to sort files and find what you are looking for.\n\nApplying these principles includes conventions include sticking to all lowercase7, consistent use of _ and - instead of spaces, writing your dates as year-month-day, using leading zeros (e.g. 001, 002, … etc instead of 1, 2, ... 10, 11, 12... which will sort as 1, 11, 12, ... 2, 21, ... etc once you go into double digits).7 alternatives include uppercase or CamelCase, but since R is case sensitive this leads to mroe typos\n\n\n4.2.3 Set up your project directory using Rprojects\nIf you have not already, create a directory called bi328 locally on your computer. Make sure you know where it is, you will be adding to this directory throughout the semester.\nCreate a project directory 8 zz_skills9) within your bi328 folder, and within that directory create sub-directories data, results, scr, and scratch. Throughout the semester you will add quarto documents to this directory as you complete your weekly skills tests.8 Yes, a directory is essentially a folder, however when using the term directory we are considering the relationship between a folder and it’s full path.9 addin the zz before the folder name means that it will sort to the bottom of this directory, this is an example of sortable. Naming it skills is descriptive in terms that you know it refers to your skills tests (human readable) and using the _ makes it machine-readable, as you are avoiding issues with white spaces\nNow, we are going to create an R project within this directory.\n\nin the top right hand corner of Rstudio click on the project icon\nselect New Project and Create in existing directory\nfollow the prompts to navigate to your zz_skills directory to create a new Rproject.\n\nThis should create a new R project and open it (the R project name should be in the top right corner next to the icon).\nIf you look in the bottom left hand pane in the Files tab, the bread crumbs should lead to your project folder which has now become your working directory, i.e. all paths are relative to this location. 10 If you navigate away from your working directory (project directory) you can quickly get back to your project directory by clicking on the project icon in the Files pane or by clicking the cog icon (More) and selecting Go to Working Directory.10 If you weren’t working with an R project, you can set your working directory by navigating to your new working director and selecting More &gt; Set as working directory."
  },
  {
    "objectID": "04_Rproj.html#structure-of-an-quarto-document",
    "href": "04_Rproj.html#structure-of-an-quarto-document",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.3 Structure of an quarto document",
    "text": "4.3 Structure of an quarto document\nFor each skills test you will either be creating a quarto document your solutions or you may be asked to download a quarto document to work in. Let’s make sure you know how to create a new document and what the different component of that document are.\nCreate a new .qmd file using File -&gt; New File -&gt; Quarto Document and save that file in your project directory as Lastname_first-quarto-document.qmd.\nAn qmd-file consists of three components:\n\nHeader: written in YAML format the header contains all the information on how to render the .qmd file.\nMarkdown Sections: written in Rmarkdown syntax.\nCode chunks: Chunks of R code (or other code such as bash, python, …). These can be run interactively while generating your document and will be rendered when knitting the document."
  },
  {
    "objectID": "04_Rproj.html#yaml-header",
    "href": "04_Rproj.html#yaml-header",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.4 YAML header",
    "text": "4.4 YAML header\nThe header is written in YAML syntax, it begins and ends with ---. It will include a few default parameters. You will find that there is a wide range of parameters that you can use to customize the look of your document but for now we will add these four.\n\n---\ntitle: \"title\"\nauthor: \"name\"\ndate: \"Date\"\nformat: html\n----\n\nCustomize your .qmd by changing the title and add your name in the author line11. Changing the date to `r Sys.Date()` will automatically include the current date when you render the document instead of having to update that yourself.11 You can always do this when you start a new file, for a lot of case studies this semester you will download quarto documents where you will want to change those"
  },
  {
    "objectID": "04_Rproj.html#markdown-sections",
    "href": "04_Rproj.html#markdown-sections",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.5 Markdown sections",
    "text": "4.5 Markdown sections\nYour markdown sections can contain any text you want using the markdown syntax; once you render the .qmd the resulting (html) file will appear as text.\nMost of your text (without syntax) will appear as paragraph text but you can add additional syntax to format it in different ways.\nHere are the basics that are fairly consistent across a range of markdown flavors:\nText formatting\n\n*italic* **bold** ~~strikeout~~ `code`\n\nsuperscript^2^ subscript~2~\n\n[underline]{.underline} [small caps]{.smallcaps}\n\nHeadings\n\n# 1st Level Header\n\n## 2nd Level Header\n\n### 3rd Level Header\n\nLists\n\n-   Bulleted list item 1\n\n-   Item 2\n\n    -   Item 2a\n\n    -   Item 2b\n    \n\n1.  Numbered list item 1\n\n2.  Item 2.\n    The numbers are incremented automatically in the output.\n    \nLinks and images\n\n&lt;http://example.com&gt;\n\n[linked phrase](http://example.com)\n\n![optional caption text](quarto.png){fig-alt=\"Quarto logo and the word quarto spelled in small case letters\"}\n\nTables\n\n| First Header | Second Header |\n|--------------|---------------|\n| Content Cell | Content Cell  |\n| Content Cell | Content Cell  |\n\n\n\n\n\n\n\n\nNote\n\n\n\nCurrent Rstudio versions do have a visual editor that is WYSIWYG12 and will allow you to format your document similar to the way you would in Google Docs or Microsoft Word. However, it is helpful to know the basics because de-bugging can be more straightforward using the Source Editor, and if you are comfortable with the syntax it is also a lot faster to format.\n\n\n12 What you see is what you get"
  },
  {
    "objectID": "04_Rproj.html#code-chunks",
    "href": "04_Rproj.html#code-chunks",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.6 Code chunks",
    "text": "4.6 Code chunks\nCode chunks contain your R code and start and end with three back ticks; {r} determines that the code chunk should be interpreted as R code.\n\n\n\nYou can type it in manually but it is a lot quicker to add a code chunk using the shortcut Ctrl + Alt + I on a Windows computer or Command + Option + I for you Mac users.\n\n\n\n\n\n\nNote\n\n\n\nYou can also insert a code chunk using Code -&gt; Insert Chunk in the tool bar, the insert button in the tab bar (little green box with C and +) or if you are in the visual editor, your can use insert button in the editor bar.\nIn short, there is no excuse not to be adding code chunks and writing code!\n\n\nYou can run (execute) entire code chunks entire chunk by clicking the Run button in the tab bar or the little green arrow in the top right corner of an R chunk.\nIt is a lot faster to use shortcuts. You can execute and entire code chunk using Cmd/Ctrl + Shift + Enter. Or if you only want to execute a certain piece of code, using Cmd/Ctrl + Enter while your cursor is placed within that code, or highlight the code you want to execute and then hit Cmd/Ctrl + Enter.\nRemember to use # to comment your code, any lines following a # will not be run by R, you can use them to describe what your code is doing. Use comments liberally to document your code, future you will thank you!\n\n\n\n\n\n\nNote\n\n\n\nBefore submitting any of your skills tests or homework assignments you should always go through and make sure each piece of code has a descriptive comment. You do not need to add a comment for multi-line code that you are stringing together using a pipe %&gt;% but you should have one descriptive comment above the set of commands you are giving R and then make sure that you add any comments that you need to remember how the function works or which parameters might be useful to tweak/set differently if you were to reuse that code.\n\n\nOptionally you can add a label to your code chunks that can be used to navigate directly to code chunks using the drop-down menu in the bottom left of the script editor.\n\n```{r}\n#| label: code-label-1\n\n1 + 1\n```\n\n[1] 2\n\n\nIf you do this for figures or tables you can start your labels with fig- or tbl- which will allow them to be automatically numbered and you can link to them later in your document. Labels cannot be repeated (i.e. they all must be unique) and cannot have spaces, best practice here would be using dashes (-) to separate words.\nYou can add options to each code chunk to customize how/if a chunk is executed and appears in the rendered output. These options are added to within the curly brackets. For example, eval: false: results in code chunk not being evaluated or run though it will still be rendered in the knitted document13. You can apply multiple options to the same chunk.13 This can be useful for you if e.g. for one of your skill tests you cannot solve one of the challenges and the document will not render because your code won’t run, this way you can show you attempt but also run the document\n\n```{r}\n#| label: code-label-2\n#| eval: false\n\n1 + 1\n```\n\nYou do have options to add figure and table captions, you can also e.g. control figure width and height. See section in r4ds (2e) Chapter 29 for a list of commonly used code options and you can find additional options here."
  },
  {
    "objectID": "04_Rproj.html#render-your-document",
    "href": "04_Rproj.html#render-your-document",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.7 Render your document",
    "text": "4.7 Render your document\nknitr is an R package used to render quarto documents to another format (usually html or pdf). In Rstudio the most straightforward way of knitting a document is using the render button in the editor toolbar. This will open a new tab in your console titled Background Jobs that will show the knitting process; any errors that occur with show up here along with a line number so you can determine where the error is occurring in your .qmd file to troubleshoot the issue. The output will automatically be saved in your working directory."
  },
  {
    "objectID": "04_Rproj.html#some-advanced-options",
    "href": "04_Rproj.html#some-advanced-options",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.8 Some advanced options",
    "text": "4.8 Some advanced options\nYou can stylize your rendered document by modifying the YAML header to include a table of contents like this14:14 the option of toc-depth determines how many levels are included in the table of contents, e.g. here headers at level 1 and 2 will be included\n---\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n---\nIf you really want to jazz things up, you can change the theme15.15 you can choose from various options here\n---\nformat:\n  html:\n    theme: cosmo\n    toc: true\n    toc-depth: 2\n---\nYou may be noticing some similarities between this lab manual and the documents you are producing in terms of layout … for exactly the reasons you are suspecting!"
  },
  {
    "objectID": "03_Rbasics.html#learning-objectives",
    "href": "03_Rbasics.html#learning-objectives",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.1 Learning Objectives",
    "text": "3.1 Learning Objectives\nAfter completing this tutorial you should be able to\n\nname, create, and assign values to objects.\nsave a series of commands/code as an R script.\nuse comments to describe your code/scripts.\ncall functions and modify the default options using their arguments.\nunderstand what a vector is and distinguish between the main data types.\nto inspect, subset, and extract their content from a vector.\nunderstand how data.frames and vectors relate."
  },
  {
    "objectID": "03_Rbasics.html#r-is-all-about-objects",
    "href": "03_Rbasics.html#r-is-all-about-objects",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.2 R is all about Objects",
    "text": "3.2 R is all about Objects\nYou can think of the R console as a super-powerful calculator. You can get output from R by simply typing math directly into the console.\n\n13 + 29\n\n[1] 42\n\n\nor\n\n546 / 13\n\n[1] 42\n\n\nWell that’s fun - but not super helpful in our context.\nIn the R programming language, an object is a fundamental concept used to store, manipulate, and represent data. Everything in R is treated as an object, whether it’s a number (numeric), a text string (character), a dataset (data.frame), or even more complex data structures.\nObjects in R can be created, modified, and used to perform various operations. Objects are assigned names that you can then use to reference them in your code. When you create an object, you’re essentially creating a container that holds a value or data.\nCreating an object is straightforward. First, we give it a name, then we use the assignment operator to assign it a value.\nThe assignment operator (&lt;-) assigns the value on the right of the &lt;- to the object on the left1.1 Start building good habits starting now in terms of your coding style. For example, your code is a lot more readable if you use white space to your advantage. For example, make sure you have a space before and after your &lt;-\n\nfork_length_mm &lt;- 344\n\nType that into the console and execute the command using Enter. If you look at your Global Environment (bottom left panel) you should now see forklength and the value you assigned it.\nNotice, how when you assigned a value to your new object nothing was printed in the console compared to when you were typing in math.\nTo print the value of an object you can type the name of the object into the console.\n\n# print value\nfork_length_mm\n\n[1] 344\n\n\nNow that fork_length_mm is in your environment we can use it to compute instead of the value itself.\nFor example, we might need to convert our fork length from millimeters (mm) to centimeters (cm).\n\nfork_length_mm / 10 \n\n[1] 34.4\n\n\nWe can change the value of an object any time by assigning it a new one. Changing the value of one object does not change the values of other objects.\n\nfork_length_mm &lt;- 567\n\n\n\n\n\n\n\n Give it a whirl!\n\n\n\nCreate a new object with the fork length in centimeters. Then change then change the value of our fork length in millimeters object to 50. What do you think the value of fork_length_mm will be now?\n\n\nSome initial thoughts on naming things22 You will soon discover that coding is 90% naming things.\nTheoretically, we can name objects anything we want - but before that gets out of hand let’s think about some guidelines for naming objects.\n\nMake them simple, specific, and not too long (otherwise you will end up with a lot of typing to do and difficulties remembering which object is which).\nObject names cannot start with a number.\nR is case sensitive, fork_length is not the same as Fork_Length.\nAvoid using dots (.) in names. Typically dots are used in function names and also have special meaning (methods) in R.\nSome names are already taken by fundamental functions (e.g. if, else, for) and cannot be used as names for objects; in general avoid using names that have already been used by other function names.\nRule of thumb: nouns for object names, verbs for function names.\n\nUsing a consistent style for naming your objects is part of adopting a consistent styling of your code; this includes things like spacing, how you name objects, and upper/lower case. Clean, consistent code will make following your code a lot easier for yourself and others3.3 Remember, future you is your most important collaborator.\n\n\n\n\n\n\nNote\n\n\n\nOne of the criteria for your homework assignments and skills tests is your code style. Next to imitating the style of coding presented in this manual, you can refer to r4ds (2e) Ch 5 for some initial pointers, you can also access a short style guide here and a more detailed, tidyverse specific style guide here."
  },
  {
    "objectID": "03_Rbasics.html#saving-your-work",
    "href": "03_Rbasics.html#saving-your-work",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.3 Saving your work",
    "text": "3.3 Saving your work\nSo far, we have inputed all of our code directly into the console. If you scroll up in the console you will find that all the commands and results from your current R session are still in the console. Using Cmd/Ctrl + L will clear the entire console.\nUh-oh - what if we need to go back over the code we just cleared?\nWell, for one if you check the History tab in the top right panel you will see that all your commands have been recorded. If you highlight one of them and either click on To Console or hit Enter it will send it directly to the console.\nUsually your history will be saved automatically when you close R/end an R session (unless you have changed the settings) and it will be restored when you open R again. You can use the broom icon to clear your entire history.\nUh-oh - now what do we do?\nIn general, you should only be typing code directly into the console for quick queries or troubleshooting but since usually we want to be able to revisit and share our work you will want to be able to save your work in an R script (*.R) or include it in a quarto document (*.qmd) as a code chunk. For this course we will mostly be operating with quarto files (more on that in the next chapter).\nYou can open a new R script using Ctrl + Shift + C or using File &gt; New File &gt; R Script. This will open an R script in a new tab in the top left pane.\nSave your R script using Cmd/Ctrl + S or File &gt; Save As - this will open a dialogue box for you to save your R script with the file extension .R.\nCtrl + Enter will execute commands directly from the script editor by sending them through to the console. You can use this to run the line of code your cursor is currently in in the script editor or you can highlight a series of lines to execute. You can also run all the code in a script by clicking on the Run button.\nCreate a new R script to keep track of the rest of the things we will learn today."
  },
  {
    "objectID": "03_Rbasics.html#using-comments",
    "href": "03_Rbasics.html#using-comments",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.4 Using comments",
    "text": "3.4 Using comments\nYou can add comments to your R scripts using #. Essentially, once you type an # in a line anything to the right of it will be ignored.\nThis is really helpful as it will allow you to comment your script, i.e. you can leave notes and explanations as to what your code is doing for future you and for other collaborators. This is especially helpful if you come back to some of your code after a period of time, if you are sharing your code with others, and when you are debugging code. You will find that as you become more experienced your comments will become shorter and more concise and you might even be tempted to leave them out completely - don’t4!4 To help you build a habit of good commenting practice, commenting your code is a requirement for your homework assignment and skills tests.\nFor example you might find a comment like this more helpful at the moment:\n\n# assign value to new object total length\nfork_length &lt;- 436\n\nBut soon you’ll find this just as helpful:\n\n# total length fish\nfork_length &lt;- 436\n\n\n\n\n\n\n\n Consider this.\n\n\n\nPredict what value of the object total_length will be after executing this command.\n\n\n\nFL &lt;- 436  # total length fish\n\n\n\n\n\n\n\nProtip\n\n\n\nYou can comment/uncomment multiple lines at once by highlighting the lines you want to comment (or uncomment) and hitting Ctrl + Shift + C. This can be useful if you are playing around with code and don’t want to delete something but don’t want it to be run either."
  },
  {
    "objectID": "03_Rbasics.html#functions",
    "href": "03_Rbasics.html#functions",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.5 Functions",
    "text": "3.5 Functions\nWhen we installed R packages earlier we mentioned that they are sets of predefined functions. These are essentially mini-scripts that automate using specific sets of commands. So instead of having to run multiple lines of code (this can be 10s - 100s of lines code) you call the function instead.\nEach function usually requires multiple inputs (arguments) and once executed return a value (though this is not always the case).\nFor example the function round() can be used to round a number5.5 This is an excellent example of naming things well!\n\nfork_length_cm &lt;- round(34.8821)\n\nIf we print the value of our object we see the following value is returned.\n\nfork_length_cm\n\n[1] 35\n\n\nFor this function the input (argument) is a number and the returned value is also a number. This is not always the case, arguments can be numbers, objects, file paths …\nMany functions have set of arguments that alter the way a function operates - these are called options. Generally, they have a default value which are used unless specified otherwise by the user.\nYou can determine the arguments as function by calling the function args().\n\nargs(round)\n\nfunction (x, digits = 0) \nNULL\n\n\nOr you can call up the help page using ?round or by typing it into the search box in the help tab in the lower right panel.\nFor example, our round() function has an argument called digits, we can use this to specify the number of significant digits we want our rounded value to have.\n\nround(34.8821, digits = 2)\n\n[1] 34.88\n\n\nIf you provide the arguments in the exact same order as they are defined you do not have to specify them.\n\nround(34.8821, 2)\n\n[1] 34.88\n\n\nHowever, if you specify the arguments, you can switch their order.\n\nround(digits = 2, x = 34.8821)\n\n[1] 34.88\n\n\n\n\n\n\n\n\nProtip\n\n\n\nGood code style is to put the non-optional arguments (frequently the object, file path or value you are using) first and then specify the names of all the optional arguments you are specifying. This provides clarity and makes it easier for yourself and others to follow your code.\n\n\nOccasionally you might even want to use comments to further specify what each argument is doing or why you are choosing a specific option.\n\nround(34.8821,     # number to round\n      digits = 2)  # specify number of significant digits\n\n[1] 34.88"
  },
  {
    "objectID": "03_Rbasics.html#vectors-data-types-i",
    "href": "03_Rbasics.html#vectors-data-types-i",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.6 Vectors (data types I)",
    "text": "3.6 Vectors (data types I)\nNow that we’ve figured out what objects and functions are let’s get to know the two data types we will be spending the most time with this semester - vectors and data frames (data.frame)6.6 Other data types include lists (list), factors (factor) matrices (matrix), and arrays (array); we’ll introduce those later on.\nThe most simple data type in R is the (atomic) vector which is a linear vector of a single type. There are six main types -\n\ncharacter: strings or words.\nnumeric or double: numbers.\ninteger: integer numbers (usually indicated as 2L to distinguish from numeric).\nlogical: TRUE or FALSE (i.e. boolean data type).\ncomplex: complex numbers with real and imaginary parts (we’ll leave it at that).\nraw: bitstreams (we won’t use those either).\n\nYou can check the data type of any object using class().\n\nclass(fork_length)\n\n[1] \"numeric\"\n\n\nCurrently, our fork_length object consists of a single value. The function c() (concatenate) will allow us to assign a series of values to an object.\n\nfork_length &lt;- c(454, 234, 948, 201)\n\nfork_length\n\n[1] 454 234 948 201\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nPredict what data type you expect this vector to be.\n\n\nWe call the same function to create a character vector.\n\nsharks &lt;- c(\"bullshark\", \"blacktip\", \"scallopedhammerhead\")\n\nclass(sharks)\n\n[1] \"character\"\n\n\nThe quotes around \"bullshark\" etc. are essential because they indicate that this is a character.\n\n\n\n\n\n\nProtip\n\n\n\nIf we do not use quotes, R will assume that we are trying to call an object and you will get an error code along the lines of “! object 'bullshark' not found”.\n\n\nYou can use c() to combine an existing object with additional elements (assuming they are the same data type).\n\nspecies &lt;- c(sharks, \"gafftop\")\n\nspecies\n\n[1] \"bullshark\"           \"blacktip\"            \"scallopedhammerhead\"\n[4] \"gafftop\"            \n\n\nNext to class() there are other helpful functions to inspect the content of a vector. For example length() will tell you how many elements are in a particular vector.\n\nlength(fork_length)\n\n[1] 4\n\n\nThe function str() will give you an overview of the structure of any object and its elements.\n\nstr(fork_length)\n\n num [1:4] 454 234 948 201\n\n\nRecall, that an atomic vector is a linear vector of a single type. Let’s explore what that means by taking a look at what happens if we create atomic vectors where we mix the data types.\n\n\n\n\n\n\n Consider this\n\n\n\nDescribe what happens when data types are mixed in a single atomic vector based on the messages generated by the code chunk below to figure out what the rules are in terms of which data type is convered to match the others when they are mixed.\n\n\n\nnumeric_character &lt;- c(1, 2, 3, \"a\")\nnumeric_logical &lt;- c(1, 2, 3, TRUE)\ncharacter_logical &lt;- c(\"a\", \"b\", \"c\", TRUE)\nwtf &lt;- c(1, 2, 3, \"4\")\n\nWe already discovered that we can combine vectors - but can we extract certain components from vectors? Indeed, there are a variety of ways that we can subset vectors.\nThe most simple way is using square brackets to indicate which element (or elements) we can’t extract. In R, indices start at 1.77 This is not the case for all programming languages, e.g. Perl, Python, or C++ start with 0.\n\n# extract second element\nspecies[2]\n\n[1] \"blacktip\"\n\n# extract fourth and second element\nspecies[c(4, 2)]\n\n[1] \"gafftop\"  \"blacktip\"\n\n\nYou can also repeat indices to create a new object with additional elements.\n\nspecies_longer &lt;- species[c(2, 2, 4, 3, 4, 4, 1, 1)]\n\nspecies_longer\n\n[1] \"blacktip\"            \"blacktip\"            \"gafftop\"            \n[4] \"scallopedhammerhead\" \"gafftop\"             \"gafftop\"            \n[7] \"bullshark\"           \"bullshark\"          \n\n\nMore frequently, we will want to extract certain elements based on a specific condition (conditional subsetting).\nThis is done using a logical vector, here TRUE select the element with the same index and FALSE will not.\n\nfork_length &lt;- c(454, 234, 948, 201)\n\n# use logical vector to subset\nfork_length[c(TRUE, FALSE, TRUE, FALSE)]\n\n[1] 454 948\n\n\nThis seems like a very impractical option. However, normally we would not create the logical vector by hand as we have done here, rather it will be the output of a function or logical test. For example, we might want to identify fish with a fork length &gt; 300mm.\n\n# identify fish with fork length &gt; threshold\nfork_length &gt; 300\n\n[1]  TRUE FALSE  TRUE FALSE\n\n\nThis creates an output the same length as the vector we looked at (fork_length) consisting of TRUE/FALSE statements for each element by comparing the each element of the vector to the condition (&gt;300) and determining if the condition is met (the statement is true) or not.\nInstead of first creating a vector of TRUE/FALSE statements can use this condition to subset our vector directly.\n\n#  identify true/false of fish with fork length &gt; threshold\nfork_length[c(fork_length &gt; 300)]\n\n[1] 454 948\n\n\nThere are a series of boolean expressions8 we can use for subsetting vectors.8 Boolean expressions are logical statements that are either true or false; most of them you are probably already familiar with because math\n\n&gt; and &lt; (greater/less than)\n=&gt; and =&lt; (equal to or greater/less than)\n== (equal to) and != (is not equal to)\n\n\n\n\n\n\n\nProtip\n\n\n\nYou can combine to boolean expressions using &, (both conditions must be met) and | (at least one condition must be met).\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nSubset the fork_length vector to\n\ncontain only values equal to 234\ncontain all values but 948\ncontain all values larger than 230 but smaller than 900\ncontain all values smaller than 250 or larger that 900\n\n\n\nR is set apart from other programming languages because it was designed to analyze data9 it has straightforward ways to deal with missing data (NA or na values) because those are quite common in real world data sets.9 some people will argue that it is a ‘statistical language’ rather than a true programming language … don’t listen to them, they are just jealous of your R skillz!\nLet’s create a vector with a missing value.\n\ntotal_length &lt;- c(560, NA, 1021, 250)\n\nLet’s say we want to calculate the mean value.\n\nmean(total_length)\n\n[1] NA\n\n\nMost functions will return NA when doing operations on objects with missing values. As such, many functions include an argument to omit missing values.\n\nmean(total_length, na.rm = TRUE)\n\n[1] 610.3333\n\n\nOther functions that are helpful to deal with missing values are is.na(), na.omit(), and complete.cases().\n\n\n\n\n\n\n Give this a whirl.\n\n\n\nSubset the fork_length vector to\nRun each of these functions on our total_length vector and describe what they do.”"
  },
  {
    "objectID": "03_Rbasics.html#data-frames-data-types-ii",
    "href": "03_Rbasics.html#data-frames-data-types-ii",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.7 Data frames (data types II)",
    "text": "3.7 Data frames (data types II)\nRecall that atomic vectors are linear vectors of a simple type, essentially they are one dimensional. Frequently we will be using data frames (data.frame) which you can think of as consisting of several vectors of the same length where each vector becomes a column and the elements are the rows.\nLet’s create a new object that is a dataframe with three columns containing information on species, fork length, and total length.\n\n# combine vectors into data frame\ncatch &lt;- data.frame(species, fork_length, total_length)\n\nYou should now see a new object in your Global Environment and you will now also see that there are two categories of objects Data and Values. You will see that the data.frame is described as having 4 obs (observations, those are your rows) of 3 variables (those are your columns). If you click on the little blue arrow it will give you additional information on each column - note that because each column is essentially a vector, each one must consist of a single data type which is also indicated.\nCalling the str() will give you the same information.\n\nstr(catch)\n\n'data.frame':   4 obs. of  3 variables:\n $ species     : chr  \"bullshark\" \"blacktip\" \"scallopedhammerhead\" \"gafftop\"\n $ fork_length : num  454 234 948 201\n $ total_length: num  560 NA 1021 250\n\n\nYou can further inspect the data.frame by clicking on the little white box on the right which will open a tab in the top left panel next to your R script. You can also always view a data.frame by calling the View() function.\n\nView(catch)\n\nThis can be a helpful way to explore your data.frame, for example, clicking on the headers will sort the data frame by that column. Usually we won’t build or data.frames by hand, rather we will read them in from e.g. a tab-delimited text file - but more on that later."
  },
  {
    "objectID": "z_references.html",
    "href": "z_references.html",
    "title": "References",
    "section": "",
    "text": "Carlson, John K., and Ivy Baremore. 2005. “Growth Dynamics of the\nSpinner Shark (Carcharhinus Brevipinna) Off the\nUnited States Southeast and Gulf of\nMexico Coasts: A Comparison of Methods.” Fishery\nBulletin 103 (2). https://aquadocs.org/handle/1834/26223.\n\n\nHeupel, Michelle R., John K. Carlson, and Colin A. Simpfendorfer. 2007.\n“Shark Nursery Areas: Concepts, Definition, Characterization and\nAssumptions.” Marine Ecology Progress Series 337 (May):\n287–97. https://doi.org/10.3354/meps337287.\n\n\nHeupel, Michelle R., Shiori Kanno, Ana P. B. Martins, Colin A.\nSimpfendorfer, Michelle R. Heupel, Shiori Kanno, Ana P. B. Martins, and\nColin A. Simpfendorfer. 2018. “Advances in Understanding the Roles\nand Benefits of Nursery Areas for Elasmobranch Populations.”\nMarine and Freshwater Research 70 (7): 897–907. https://doi.org/10.1071/MF18081.\n\n\nNeer, J. A., B. A. Thompson, and John K. Carlson. 2005. “Age and\nGrowth of Carcharhinus Leucas in the Northern\nGulf of Mexico: Incorporating Variability in\nSize at Birth - Neer - 2005 - Journal of\nFish Biology - Wiley Online Library.”\nJournal of Fish Biology 67 (2): 370–83. https://onlinelibrary.wiley.com/doi/full/10.1111/j.0022-1112.2005.00743.x.\n\n\nPlumlee, Jeffrey D., Kaylan M. Dance, Philip Matich, John A. Mohan,\nTravis M. Richards, Thomas C. TinHan, Mark R. Fisher, and R. J. David\nWells. 2018. “Community Structure of Elasmobranchs in Estuaries\nAlong the Northwest Gulf of Mexico.”\nEstuarine, Coastal and Shelf Science 204 (May): 103–13. https://doi.org/10.1016/j.ecss.2018.02.023.\n\n\nSwift, Dominic G., and David S. Portnoy. 2021. “Identification and\nDelineation of Essential Habitat for\nElasmobranchs in Estuaries on the Texas\nCoast.” Estuaries and Coasts 44 (3): 788–800. https://doi.org/10.1007/s12237-020-00797-y."
  },
  {
    "objectID": "02_install-R.html#learning-objectives",
    "href": "02_install-R.html#learning-objectives",
    "title": "2  Getting set up with R and Rstudio",
    "section": "2.1 Learning Objectives",
    "text": "2.1 Learning Objectives\nAfter completing this activity you should\n\nbe able to download and install R and Rstudio on your laptop\nbe able to install Rtools & devtools to be able to compile R packages from source (Windows).\nunderstand the main use for each of the four main panes in the Rstudio GUI.\nunderstand what a package is in R and how to install them."
  },
  {
    "objectID": "02_install-R.html#install-set-up-r-and-rstudio-on-your-computer",
    "href": "02_install-R.html#install-set-up-r-and-rstudio-on-your-computer",
    "title": "2  Getting set up with R and Rstudio",
    "section": "2.2 Install & Set up R and Rstudio on your computer",
    "text": "2.2 Install & Set up R and Rstudio on your computer\nIf you have already installed R and Rstudio make sure your R version is up to date. Whenever you open Rstudio the version will be printed in the console (bottom left pane). In addition, you can always check what version is installed by typing sessionInfo() into your console. You should be using version 4.0.0 or later. You do not need to uninstall old version of R. If you do have to update, you will need to re-install packages (see below) for R4.0.0\n\n2.2.1 Windows\nInstall R\n\nDownload most recent version of R for Windows here.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard.\n\nInstall Rtools\n\nDownload Rtools here.\nRun the downloaded .exe file that was download and follow the instructions in the set-up wizard.\n\nInstall Rstudio\n\nGo to Rstudio download page.\nScroll down to select the Rstudio current version for Windows XP/Vista/7/8/10.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard.\n\nFinish setting up Rtools\n\nOpen Rstudio to make sure you aren’t getting any error messages.\nPut Rtools in your path by typing writeLines('PATH=\"${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}\"', con = \"~/.Renviron\") in the console window.\nInstall the devtools package by typing install.packages(\"devtools\") in the console.\n\nInstall quarto\nDownload quarto using this link. Pick the file according to your operating system Run the downloaded .exe file that was download and follow the instructions in the set-up wizard.\n\n\n2.2.2 Mac OS X\nDownload & install R\n\nGo to (CRAN)[http://cran.r-project.org/], select Download R for (Mac) OS X.\nDownload the .pkg file for your OS X version.\nRun the downloaded file to install R.\n\nDownload & install XQuartz (needed to run some R packages)\n\nDownload XQuartz\nRun the downloaded file to install\n\nDownload & install Rstudio\n\nGo to Rstudio download page.\nScroll down to select the Rstudio current version for Mac OS X.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard.\n\nInstall quarto\nDownload quarto using this link. Pick the file according to your operating system Run the downloaded .exe file that was download and follow the instructions in the set-up wizard."
  },
  {
    "objectID": "02_install-R.html#get-to-know-rstudio",
    "href": "02_install-R.html#get-to-know-rstudio",
    "title": "2  Getting set up with R and Rstudio",
    "section": "2.3 Get to know Rstudio",
    "text": "2.3 Get to know Rstudio\nRstudio is an Integrated Development Environment (IDE) that you can use to write code, navigate files, inspect objects, etc. The advantage of using an IDE is that you have access to shortcuts, visual cues, troubleshooting, navigation, and autocomplete help.\n\n2.3.1 GUI Layout\nGUI stands for graphic user interface and refers to a type of user interface that allows users to interact with software applications and electronic devices through visual elements such as icons, buttons, windows, and menus, rather than using text-based command-line interfaces.\nYou have probably mostly interacted with computer programs through a GUI, where you interact with the system by manipulating graphical elements using a pointing device like a mouse, touch screen, or stylus. GUIs provide a more intuitive and user-friendly way for individuals to interact with computers and software because you can “see” what the effect of what you are doing is having. Graphical User Interfaces are a major departure from earlier text-based interfaces like command-line interfaces. They have contributed significantly to the widespread adoption of computers and software by making them more accessible to a broader range of users. GUIs are used in various types of software, from operating systems to applications like web browsers, image editors, word processors, and more.\nNot too long ago, if you had wanted to learn R or another programming language you would have been working directly on a console instead of an IDE like Rstudio which has made coding a lot more accessible to beginners because you can more easily use scripts, interactively run code and visualize data.\n\n\n\n\n\n\nNote\n\n\n\nUse this link to access an Rstudio IDE Cheatsheet pointing out the key features using annotated impages of the different panes. You can also download a pdf version and keep a printout handy as you get used to the GUI.\n\n\nOpen Rstudio and identify the four panes in the interface (default layout).\n\nEditor (top left): edit scripts/other documents, code can be sent directly to the console.\nR console (bottom left): Run code either by directly typing the code or sending it from the editor pane.\nEnvironment/history (top right): Contains variables/objects as you create them & full history of functions/commands that have been run.\nfiles/plots/packages/help/viewer (bottom right): Different tabs in this pane wil let you explore files on your computer, view plots, loaded packages, and read manual pages for various functions.\n\nThe panes can be customized (Rstudio -&gt; Preferences -&gt; Pane Layout) and you can move/re-size them using your mouse.\n\n\n\n\n\n\nNote\n\n\n\nWe are going to switch to have the Console in our top right and the Environment in the bottom left which makes it easier to see your code output and your script/quarto document at the same time.\n\n\n\n\n2.3.2 Interacting with R in Rstudio\nThink of R as a language that allows you to give your computer precise instructions (code) to follow.\n\nCommands are the instructions we are giving the computer, usually as a series of functions.\nExecuting code or a program means you are telling the computer to run it.\n\nThere are three main ways to interact with R - directly using console, script files (*.R), or code chunks embedded in R markdown (*.Rmd) or quarto files (*.qmd). We will generally be working with the later.\nThe console is where you execute code and see the results of those commands. You can type your code directly into the console and hit Enter to execute it. You can review those commands in the history pane (or by saving the history) but if you close the session and don’t save the history to file those commands will be forgotten.\nBy contrast, writing your code in the script editor either as a standard script or as a code chunk in an quarto document allows you to have a reproducible workflow (future you and other collaborators will thank you).\nExecuting an entire script, a code chunk, or individual functions from a script will run them in the console.\n\nCtrl + Enter will execute commands directly from the script editor. You can use this to run the line of code your cursor is currently in in the script editor or you can highlight a series of lines to execute.\nIf you are using a quarto file you can execute an entire code chunk by pressing the green arrow in the top right corner.\n\nIf the console is ready for you to execute commands you should see a &gt; prompt. If you e.g. forget a ) you will see a + prompt - R is telling you that it is expecting further code. When this happens and you don’t know what you are missing (usually it is an unmatched quotation or parenthesis), make sure your cursor is in the console and hit the Esc key.\n\nWe will run through these options, but you can always check back here while you are getting used to R.\n\n\n\n2.3.3 Customize Rstudio\nThere are several options to customize Rstudio including setting a theme, and other formatting preferences. You can access this using Tools &gt; Global Options. I recommend using a dark theme (it’s a lot easier on the eyes) and keeping the panes in the same positions outlined above because it will make troubleshooting a lot easier1.1 “You should see xx in the top left” is a lot more helpful if your top left looks like my top left!"
  },
  {
    "objectID": "02_install-R.html#installing-and-using-packages-in-r",
    "href": "02_install-R.html#installing-and-using-packages-in-r",
    "title": "2  Getting set up with R and Rstudio",
    "section": "2.4 Installing and using packages in R",
    "text": "2.4 Installing and using packages in R\n\n2.4.1 Install a package\nThink of R packages or libraries as tool kit comprising a set of functions (tools) to perform specific tasks. R comes with a set of packages already installed that gives you base R functions; you can view these and determine which have been loaded in the Packages tab in the bottom right pane. For other tasks we will need additional packages. 22 Most R packages are found in the CRAN repository and on Bioconducter, developmental packages are available on github.\nA central group of packages for data wrangling and processing form the tidyverse, described as “… an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” - We are going to heavily rely on core functions from the tidyverse to wrangle, summarize, and analyze data.\nWhen you install packages they will be downloaded and installed onto your computer. Determine what your default path is using .libPaths() and change if necessary.\nThe easiest way to install packages directly in the console is to use the install.packages() function.\nUse the R console to install some libraries to get us started (we will install other libraries as needed for other labs).\n\n\nUsing # in an R script allows you to insert comments that are ignored by R when executing your code. Use comments to document your code, future you will thank you! Before submitting any of your skills tests or homework assignments you should always go through and make sure each piece of code has a descriptive comment. You do not need to add a comment for multi-line code that you are stringing together using a pipe %&gt;% but you should have one descriptive comment above the set of commands you are giving R and then make sure that you add any comments that you need to remember how the function works or which parameters might be useful to tweak/set differently if you were to reuse that code.\n\n# install central packages in the tidyverse\ninstall.packages(\"tidyverse\")\n\n# install additional packages\ninstall.packages(\"plyr\", \"ggthemes\", \"patchwork\", \"glue\")\n\nLet’s check if you were able to successfully install those packages by ensureing you can load them. Any time you start a new R session (e.g. by closing Rstudio and restarting it), you will need to load your libraries beyond the base libraries that are automatically loaded using the library() function in order to be able to use the functions specific to that package3.3 Troubleshooting tip: if you get an error along the lines of function() cannot be found the first thing you will want to do is check if your libraries are loaded!\n\n# load library\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nIf you don’t see any error messages in the console along the lines of there is no package called ... you are all set. If you look in the packages tab in the lower right panel you should also see that packages such as dplyr and tidyr (two of the central tidyverse packages) now have a little check box next to them.\n\n\n2.4.2 Updating R packages\nYou should generally make sure to keep your R packages up to date as new versions include important bugfixes and additional improvements. The easiest way to update packages is to use the Update button in the Packages tab in the bottom right panel. Over the course of the semester you should not have to do this, but when you install new packages you might get message that some of your packages need to be updated which you can then either choose to do at that point or ignore.\n\n\n\n\n\n\nWarning\n\n\n\nBe aware that updating packages might break some code you have previously written. For most of what we will be doing this should not be the case. If you used R for a previous course, make sure to update you packages at the beginning of this course and we should be set for the semester."
  },
  {
    "objectID": "01_intro-data-science.html#learning-objectives",
    "href": "01_intro-data-science.html#learning-objectives",
    "title": "1  What even is Data Science?",
    "section": "1.1 Learning Objectives",
    "text": "1.1 Learning Objectives\nAfter completing this lab you should be able to\n\ndefine what data is and what the structural/functional relationships to information, knowledge, insight and wisdom are.\ndescribe what data science is and the major field/skill sets that comprise it.\ndescribe the individual components that comprise the data science life cycle."
  },
  {
    "objectID": "01_intro-data-science.html#defining-data-and-science",
    "href": "01_intro-data-science.html#defining-data-and-science",
    "title": "1  What even is Data Science?",
    "section": "1.2 Defining “data” and “science”",
    "text": "1.2 Defining “data” and “science”\nData are qualitative and quantitative observations that are measured and collected.\n\n\n\n\n\n\n Consider this\n\n\n\nData fall in two distinct categories, categorical and numerical data. Briefly compare and contrast these two categories by describing the data types you would expect to find in each.\n\n\nThe ‘data - information - knowledge - wisdom pyramid’ gives us a framework to consider how data can be used to inform decision making and impact the world around us. Not until data is organized and processed thus adding context can we glean information from the signal. Additional meaning is transferred as we synthesize and further contextualize information resulting in knowledge.\nThese three categories look backwards - we describe the “what” and ask about the “why” to reveal patterns and relationships. At this point we start looking forward to determine what action(s) should be taken, we know seek to reveal principles and directions that can be applied.\nWe integrate knowledge across disciplines to gain insight and wisdom to further understanding of problems and derive actionable solutions. This culminates in the decision-making process resulting in change.\n\n\n\n\n\n\n Consider this\n\n\n\nThe science council defines science as the pursuit and application of knowledge and understanding of the natural and social world following a systematic methodology based on evidence. Compare and contrast this definition to the DIKW framework and make an argument that all science is data science."
  },
  {
    "objectID": "01_intro-data-science.html#what-even-is-data-science",
    "href": "01_intro-data-science.html#what-even-is-data-science",
    "title": "1  What even is Data Science?",
    "section": "1.3 What even is data science?",
    "text": "1.3 What even is data science?\nData science is a fuzzy term and no single definition exists. Most definitions emphasize that it is a interdisciplinary field and that it has arisen in response to the increasingly large data sets that are produced.\nA common way of defining data science is to describe it as being the intersection of domain knowledge, statistics/mathematics, and computer science - though different definitions will ascribe more importance to certain different components.\nOne distinction to the typical scientific process as you may have learned it to be is that a large component of data science is hypothesis generation through exploratory analysis rather than hypothesis confirmation.\nThe data science process generally starts by posing an interesting question and ends with visualizing and communicating the results. The key steps to the end results are obtaining the data, processing and exploring the data, and modeling the data to understand the data set and derive conclusions."
  },
  {
    "objectID": "01_intro-data-science.html#the-data-science-process",
    "href": "01_intro-data-science.html#the-data-science-process",
    "title": "1  What even is Data Science?",
    "section": "1.4 The data science process",
    "text": "1.4 The data science process\n\n1.4.1 Ask an interesting question\nLet’s start by asking an interesting question:\n\nWill Sasquatch by impacted by climate change?\n\nSpecifically, climate change could result in a shift in habitat availability, i.e. should we expect a species extinction because of habitat loss or a range expansion or range shift?\nTo do this we need to generate a species distribution model (SDM) for the Sasquatch, a large, hairy, bipedal ape-like creature found (or is it?) throughout North America1, i.e. first we need to understand where Sasquatch are currently distributed to then assess how that might change in the future.1 I suppose, technically, since we were venturing into cryptozoology here it is not a species, but rather a cryptid distribution model\n\n\n1.4.2 Get occurrence data\nThe first thing we need for any SDM is a data set documenting species occurrence, i.e. geo-coded observations of a given species in the wild.\nFour our purposes, we turn to the Bigfoot Field Researchers Organization (BFRO), founded in 1995 as the “only scientific research organization exploring the Bigfoot/Sasquatch mystery”. You can turn to their website for answers on important FAQs, including ‘Do Bigfoot Sasquatch bury their dead?’, ‘Where is the physical evidence?’, ‘Wasn’t this all shown to be a fake?, and ’Why do you want scientists to recognize the Sasquatch as a species? Isn’t it better to just leave them alone?’. Their main focus though is on compiling reports of sightings and investigating them. In other words, they have a database full of geo-coded reported sightings2.2 And even better, it has already been downloaded and wrangled and is accessible (with sightings through 2018) right here.\nLet’s read in the data and then we can take a look at the information we can glean from this data set by looking at the column names.\n\n# read data\noccurrence &lt;- read_delim(\"data/bfro_reports_geocoded.txt\", delim = \"\\t\")\n\n\n\n1.4.3 Tidy, Transform & Explore the data\nLet’s start by taking a look at our data set to determine how we need to wrangle to get the information we need process it so we can generate our species distribution model.\nBecause we need to be able to identify the exact locations Sasquatch occur, we are going to remove any observations that do not have latitude and longitude information.\n\n# filter NAs\noccurrence &lt;- occurrence %&gt;%\n  filter(!is.na(longitude),\n         !is.na(latitude))\n\nNext, let’s consider is what geographic extent of the observations is by looking at the distributions on a map.\n\n# get minimum and maximum lat/longs\nmax.lat &lt;- ceiling(max(occurrence$latitude))\nmin.lat &lt;- floor(min(occurrence$latitude))\nmax.lon &lt;- ceiling(max(occurrence$longitude))\nmin.lon &lt;- floor(min(occurrence$longitude))\n\n# create an extent object of the range of observations\ngeo_range &lt;- extent(x = c(min.lon, max.lon, min.lat, max.lat))\n\n# get base map\ndata(wrld_simpl)\n\n# plot the base map\nplot(wrld_simpl, \n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE, \n     col = \"grey75\")\n\n# add individual occurrences\npoints(x = occurrence$longitude, \n       y = occurrence$latitude, \n       col = \"darkorange\", \n       pch = 20, \n       cex = 0.75)\n\n# draw box around figure\nbox()\n\n\n\n\nFigure 1.1: Map of Sasquatch sighting in the United States based on the BFRO database (1950 - 2021).\n\n\n\n\nHere is an example of where domain knowledge comes in - while we are tidying and exploring the data set we need to assess whether there are artifacts our outlier data points that should be removed.\n\n\n\n\n\n\n Consider this\n\n\n\nGive a brief description of the spatial distribution of the occurrence of Sasquatch in the United States. Note areas where sightings appear to be random, clustered or more dispersed, determine if you think any points should be removed.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nDiscuss some possible explanations for the patterns you have observed to determine whether you think this data set is a reasonable representation of the ecological niche of the Sasquatch and can be used to create a species distribution model.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGood catch - those sightings in the middle of the ocean are probably errors in the geo-coding. Further, we don’t know how reliable the data for Alaska is as this data set is based on opportunistic sightings - at least for the most part, if you poke around the BFRO website you will find that people do plan expeditions.\n\n\n\nThe data for for observations in the lower 48 seems much more reliable, so let’s restrict our data to those observations.\n\n# load and filter data\noccurrence &lt;- read_delim(\"data/bfro_reports_geocoded.txt\", delim = \"\\t\") %&gt;%\n  filter(!is.na(longitude),\n         !is.na(latitude),\n         longitude &gt; -130,\n         latitude &lt; 55)\n\n# get minimum and maximum lat/longs\nmax.lat &lt;- ceiling(max(occurrence$latitude))\nmin.lat &lt;- floor(min(occurrence$latitude))\nmax.lon &lt;- ceiling(max(occurrence$longitude))\nmin.lon &lt;- floor(min(occurrence$longitude))\n\n# create an extent object\ngeo_range &lt;- extent(x = c(min.lon, max.lon, min.lat, max.lat))\n\n# get base map\ndata(wrld_simpl)\n\n# plot the base map\nplot(wrld_simpl, \n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE, \n     col = \"grey75\")\n\n# add individual occurrences\npoints(x = occurrence$longitude, \n       y = occurrence$latitude, \n       xlim = c(min.lon, max.lon),\n       ylim = c(min.lat, max.lat),\n       col = \"darkorange\", \n       pch = 20, \n       cex = 0.75)\n\n# draw box around figure\nbox()\n\n\n\n\nFigure 1.2: Map of Sasquatch sighting in the lower 48 states based on the BFRO database as (1950 - 2021).\n\n\n\n\nThis should work - on to the next step!\n\n\n1.4.4 Get more data\nOccurrence data along will not allow us to build a species distribution model; what we need is environmental data to go with the locations, i.e. we need a set of predictor variables.\nCombining multiple data sets is typical for data science projects, frequently the quality of a project hinges on the availability of hight quality data sets that can provide information to describe or preodict behavior if the data set you are exploring.\nClimate is complex and multidimensional, though at its core climate is determined by long-term patterns in mean and variability of temperature and precipitation.\nWe are going to use the bioclim data set from CliMond. Bioclim variables are commonly used for species distribution modeling as they are based on long-term trends (as opposed to e.g. the exact conditions when the species was observed).\n\n\n\n\n\n\n Consider this\n\n\n\nLook up the descriptions of the bioclim variables and give a brief description of the four abiotic parameters that are included and how they are being parameterized. Argue which you think are most important to describe a species distribution/ecological niche and whether you think overall this data set will help us understand Sasquatch species distribution.\n\n\nThe data set we are using includes a core set of 19 variables that describe temperature and precipitation, along with an additional 16 variables that describe solar radiation and soil moisture. This information is encoded in the raster files of the historical (contemporary) bioclim data sets at a resolution of 10’ (minutes) into the data folder. The “historical” data set consists of data from 1961 - 1990 centered on 1975.\nA raster file is an image file consisting of pixels with data associated with it. In this case, our “pixels” are 10’ x 10’ and depending on the layer the value associated with each pixel is the value for that bioclim value at that geographic location.\n\n# get list of files\nfiles &lt;- list.files(\"data/\", pattern='^CM10_1975H', full.names=TRUE )\n\n# import and convert to raster stack\npredictors &lt;- stack(files)\n\nWe have now created an object that at its core consists of a list where each element is a layer (bioclim variable raster).\n\n\n1.4.5 Tidy, transform & explore the data (again)\nLet’s plot the first bioclim variable (Bio01, annual mean temperature).\n\nplot(predictors@layers[[1]])\n\n\n\n\nFigure 1.3: Global distribution of annual mean temperature (1961 - 1990, centered on 1975).\n\n\n\n\nWe see the pattern we would intuitively expect, with temperatures decreasing as you move poleward and being warmest around the poles.\nLet’s extract the values for each bioclim variable at our occurrence points (observations).\n\n# create df with just xy coordinates\nxy &lt;- occurrence %&gt;%\n  dplyr::select(longitude, latitude)\n\n# crop bioclim data to geographic range\ncropped_predictors &lt;- crop(x = predictors, y = geo_range)\n\n# extract values\npresence &lt;- raster::extract(cropped_predictors, xy)\n\nLet’s take a quick look at the first few rows and columns of the matrix we just created.\n\nhead(presence[,1:3])\n\n     CM10_1975H_Bio01_V1.2 CM10_1975H_Bio02_V1.2 CM10_1975H_Bio03_V1.2\n[1,]              8.387707              15.84337             0.3534581\n[2,]             10.156170               9.49416             0.2941423\n[3,]             15.522450              13.50635             0.3474373\n[4,]             11.259700              12.40612             0.3456673\n[5,]             10.189860              11.02385             0.3073747\n[6,]              8.724987              10.20157             0.2807353\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly state what these values represent.\n\n\n\n\n1.4.6 Create species distribution model\nOur next step is to fit a bioclim model to the data set we just generated.\n\n# fit bioclim model\nmodel.fit &lt;- bioclim(presence)\n\nThe bioclim model is a classic climate-envelope-model3.3 You may remember reading about this in your reading assignments.\nBriefly, the algorithm computes the similarity of locations by comparing the value of each environmental variables being used (our bioclim data set) to a distribution of that values at all locations with known presence4. The closer that value is to the median (50th percentile), the more suitable that location is assumed to be. Suitability scores are between 0 and 1, with 1 indicating a “perfect suitability”.)4 Also called the training sites; these are our occurrence points.\nIn general, there is no distinction between the tails of the distribution (i.e. the 90th and 10th percentile are equivalent), though in some implementations you can specify those to be treated as distinct. As a result e.g. low levels of precipitation could be limiting but high levels would not be.\nFinally, we will use our suitability scores and the bioclim raster data set to generate a predictive map of the Sasquatch species distribution. This means that the algorithm will assign a suitability score to each pixel based on the model and create a new raster layer.\n\n# generate raster with predicted distribution\nprediction &lt;- dismo::predict(x = cropped_predictors, \n                             object = model.fit,\n                             ext = geo_range)\n\nLet’s plot our species distribution map.\n\n# plot model probabilities\nplot(prediction,\n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE)\n\n# add map\nplot(wrld_simpl, add = TRUE, border = \"black\")\n\n# draw box around it\nbox()\n\n\n\n\nFigure 1.4: Species distribution model for Sasquatch. Color indicates the probability of encountering Sasquatch in the lower 48 states based on habitat suitability.\n\n\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nGive a brief description of the habitat suitability map, including the maximum probabilities. Describe wether this result fits your expectations based on the distribution map of reports we looked at earlier. According to our map, if you were planning a Sasquatch research trip, where would you be headed?\n\n\nOur highest habitat suitability values (probability of occurring) seem pretty low. One reason for this is that we used presence-only data.\n\n\n\n\n\n\n Consider this\n\n\n\nThe alternative to presence-only models is to have presence-absence data. Discuss how this would improve the models. Argue why you think presence-only data sets are easier to generate.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nA work-around of not having absence data is to generate pseudo-absence data. This is done by generating random points within the geographic range and using those as proxies for absence data. Briefly argue the merits and limitations of such an approach.\n\n\n\n\n1.4.7 Model future climate change\nProjections of future climate change are heavily dependent on human activity and the resulting greenhouse gas emissions. Therefore the IPCC’s Assessment Reports contain scenario families that represent projected climate conditions based on emission scenarios resulting from future technological and economic development as defined by each scenario.\nLet’s look at how the species distribution map might change in response to a shift in environmental parameters.\nTo do this we will use bioclim raster files for 2100 generated using the A1B and A2 scenarios.\nThe A1 climate scenarios assume a more integrated world characterized by rapid economic growth, a global population that peaks at 9 billion (2050) and the gradually declines, rapid spread of new/efficient technologies, and a convergent world characterized by extensive worldwide social and cultural interactions. Scenario A1B further assumes a balanced emphasis on fossil and non-fossil fuels.\nBy contrast, A2 scenarios assume a more divided world consisting of independently operating and self-reliant nations and regionally-oriented economic development. The population is assumed to continuously grow. Finally, this scenario is characterized by high emissions.\nLet’s start with the A1 climate scenario to create our species distribution model.\n\n# get list of files\nfiles &lt;- list.files(\"data/\", pattern='^CM10_2100_A1B', full.names=TRUE )\n\n# import and convert to raster stack\npredictors_A1 &lt;- stack(files)\n\nNow let’s fit our model and create predictive map.\n\n# create df with just xy coordinates\nxy &lt;- occurrence %&gt;%\n  select(longitude, latitude)\n\n# crop bioclim data to geographic range\ncropped_predictors &lt;- crop(x = predictors_A1, y = geo_range)\n\n# extract values\npresence &lt;- raster::extract(cropped_predictors, xy)\n\n# fit the bioclim model\nmodel.fit &lt;- bioclim(presence)\n\n# create raster layer of predicted distribution\nprediction &lt;- dismo::predict(x = cropped_predictors, \n                             object = model.fit,\n                             ext = geo_range)\n\nFinally, let’s plot our species distribution map.\n\n# plot model probabilities\nplot(prediction,\n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE)\n\n# add map\nplot(wrld_simpl, add = TRUE, border = \"black\")\n\n# draw box around it\nbox()\n\n\n\n\nFigure 1.5: Predicted species distribution for Sasquatch in the lower 48 in 2100 (climate scenario A1B). Color indicates the probability of encountering Sasquatch in the lower 48 states based on habitat suitability.\n\n\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nGive a brief description of the habitat suitability map, including the maximum probabilities. Describe whether this fit your expectations based on the change in bioclim variables. Describe the shift in habitat suitability relative to our current model.\n\n\nHow about our A2 climate scenario?\n\n# get list of files\nfiles &lt;- list.files(\"data/\", pattern='^CM10_2100_A2', full.names=TRUE )\n\n# import and convert to raster stack\npredictors_A2 &lt;- stack(files)\n\n# create df with just xy coordinates\nxy &lt;- occurrence %&gt;%\n  select(longitude, latitude)\n\n# crop bioclim data to geographic range\ncropped_predictors &lt;- crop(x = predictors_A2, y = geo_range)\n\n# extract values\npresence &lt;- raster::extract(cropped_predictors, xy)\n\n# fit the bioclim model\nmodel.fit &lt;- bioclim(presence)\n\n# create raster layer of predicted distribution\nprediction &lt;- dismo::predict(x = cropped_predictors, \n                             object = model.fit,\n                             ext = geo_range)\n\n# plot model probabilities\nplot(prediction,\n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE)\n\n# add map\nplot(wrld_simpl, add = TRUE, border = \"black\")\n\n# draw box around it\nbox()\n\n\n\n\nFigure 1.6: Predicted species distribution for Sasquatch in the lower 48 in 2100 (climate scenario A2). Color indicates the probability of encountering Sasquatch in the lower 48 states based on habitat suitability.\n\n\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly compare this model to the previous two. Comment on whether you expected to see greater or smaller difference to the other future climate prediction based on the scenarios that they are based on.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nDiscuss whether you think bioclim variables are good models to predict a species’ respone to climate change. In your discussion consider how future bioclim data sets are generated, as well as, whether abiotic conditions along will determine range changes."
  },
  {
    "objectID": "01_intro-data-science.html#visualize-and-communicate-your-results",
    "href": "01_intro-data-science.html#visualize-and-communicate-your-results",
    "title": "1  What even is Data Science?",
    "section": "1.5 Visualize and Communicate your results",
    "text": "1.5 Visualize and Communicate your results\nPrinting our maps side by side for better comparison would be a good way to visualize and communicate our results. We would probably include a discussion of our our approach (we should probably validate our model too which we haven’t done here) and make recommendations based on our findings."
  },
  {
    "objectID": "01_intro-data-science.html#acknowledgments",
    "href": "01_intro-data-science.html#acknowledgments",
    "title": "1  What even is Data Science?",
    "section": "1.6 Acknowledgments",
    "text": "1.6 Acknowledgments\nSince I’m not the first person to create a lab/tutorial on species distribution modeling, I drew inspiration from various educators, R and data enthusiasts to shape this tutorial, most notably:\nAnna L. Carter. November 2017, posting date. Painting turtles: an introduction to species distribution modeling in R. Teaching Issues and Experiments in Ecology, Vol. 13: Practice #1 [online]. http://tiee.esa.org/vol/v13/issues/data_sets/carter/abstract.html\nWendy L. Clement, Kathleen L. Prudic, and Jeffrey C. Oliver. 16 August 2018, posting date. Exploring how climate will impact plant-insect distributions and interactions using open data and informatics. Teaching Issues and Experiments in Ecology, Vol. 14: Experiment #1 [online]. http://tiee.esa.org/vol/v14/experiments/clement/abstract.html\nhttps://jcoliver.github.io/learn-r/011-species-distribution-models.html"
  }
]