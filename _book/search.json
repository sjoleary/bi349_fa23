[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for a Changing Planet",
    "section": "",
    "text": "Overview"
  },
  {
    "objectID": "index.html#course-format",
    "href": "index.html#course-format",
    "title": "Data Science for a Changing Planet",
    "section": "Course Format",
    "text": "Course Format\nThis is a lecture/lab course meeting three times a week (MWF 10:25-11:15am & 11:30am - 12:20pm). Key concepts will be introduced in reading and annotation assignments, short ‘prelab’-type tutorials, or exercises that you will be expected to complete before class as specified on Canvas.\nLecture/lab time will incorporate brief refreshers and more in-depth demonstrations of some of the more complex topics (participatory code-alongs), with a the focus on applying the concepts and ‘learning by doing’ by directly applying new skills to case studies and data sets from ecology, environmental science and public health."
  },
  {
    "objectID": "index.html#byod-bring-your-own-device-to-lab",
    "href": "index.html#byod-bring-your-own-device-to-lab",
    "title": "Data Science for a Changing Planet",
    "section": "BYOD: Bring your own device (to lab)",
    "text": "BYOD: Bring your own device (to lab)\nYou are required to bring your laptop for use during class times; a tablet will not be sufficient to participate though you are welcome to bring an additional device to have an extra screen to follow along an electronic version of the lab handbook. Make sure to have a power cable and/or fully charged battery! If you run into computer issues please let Dr. O’Leary know as soon as possible so we can come up with a back-up plan such as organizing a laptop to use during/outside of class time to complete activities."
  },
  {
    "objectID": "A_hello-world.html",
    "href": "A_hello-world.html",
    "title": "Hello world",
    "section": "",
    "text": "The phrase “hello world” is a popular and simple introductory program that is often used to demonstrate the basic syntax and structure of a programming language. It’s typically one of the first programs that people write when learning a new programming language.\nIt is usually a simple program that prints the text Hellow World to the output, typically a console or terminal window. Writing and running a “hello world” program helps beginners understand the essential steps of writing, compiling, and executing code in a specific programming language.\nTo create a “Hello, World!” program in R, you can use the print() function:\nprint(\"Hello, World!\")\n\nIn this section, we will get an overview of what Data Science is, install R/Rstudio and orient ourselves in how to use Rstudio and learn the basics about using R as an object-oriented language."
  },
  {
    "objectID": "01_intro-data-science.html#learning-objectives",
    "href": "01_intro-data-science.html#learning-objectives",
    "title": "1  What even is Data Science?",
    "section": "1.1 Learning Objectives",
    "text": "1.1 Learning Objectives\nAfter completing this lab you should be able to\n\ndefine what data is and what the structural/functional relationships to information, knowledge, insight and wisdom are.\ndescribe what data science is and the major field/skill sets that comprise it.\ndescribe the individual components that comprise the data science life cycle."
  },
  {
    "objectID": "01_intro-data-science.html#defining-data-and-science",
    "href": "01_intro-data-science.html#defining-data-and-science",
    "title": "1  What even is Data Science?",
    "section": "1.2 Defining “data” and “science”",
    "text": "1.2 Defining “data” and “science”\nData are qualitative and quantitative observations that are measured and collected.\n\n\n\n\n\n\n Consider this\n\n\n\nData fall in two distinct categories, categorical and numerical data. Briefly compare and contrast these two categories by describing the data types you would expect to find in each.\n\n\nThe ‘data - information - knowledge - wisdom pyramid’ gives us a framework to consider how data can be used to inform decision making and impact the world around us. Not until data is organized and processed thus adding context can we glean information from the signal. Additional meaning is transferred as we synthesize and further contextualize information resulting in knowledge.\nThese three categories look backwards - we describe the “what” and ask about the “why” to reveal patterns and relationships. At this point we start looking forward to determine what action(s) should be taken, we know seek to reveal principles and directions that can be applied.\nWe integrate knowledge across disciplines to gain insight and wisdom to further understanding of problems and derive actionable solutions. This culminates in the decision-making process resulting in change.\n\n\n\n\n\n\n Consider this\n\n\n\nThe science council defines science as the pursuit and application of knowledge and understanding of the natural and social world following a systematic methodology based on evidence. Compare and contrast this definition to the DIKW framework and make an argument that all science is data science."
  },
  {
    "objectID": "01_intro-data-science.html#what-even-is-data-science",
    "href": "01_intro-data-science.html#what-even-is-data-science",
    "title": "1  What even is Data Science?",
    "section": "1.3 What even is data science?",
    "text": "1.3 What even is data science?\nData science is a fuzzy term and no single definition exists. Most definitions emphasize that it is a interdisciplinary field and that it has arisen in response to the increasingly large data sets that are produced.\nA common way of defining data science is to describe it as being the intersection of domain knowledge, statistics/mathematics, and computer science - though different definitions will ascribe more importance to certain different components.\nOne distinction to the typical scientific process as you may have learned it to be is that a large component of data science is hypothesis generation through exploratory analysis rather than hypothesis confirmation.\nThe data science process generally starts by posing an interesting question and ends with visualizing and communicating the results. The key steps to the end results are obtaining the data, processing and exploring the data, and modeling the data to understand the data set and derive conclusions."
  },
  {
    "objectID": "01_intro-data-science.html#the-data-science-process",
    "href": "01_intro-data-science.html#the-data-science-process",
    "title": "1  What even is Data Science?",
    "section": "1.4 The data science process",
    "text": "1.4 The data science process\n\n1.4.1 Ask an interesting question\nLet’s start by asking an interesting question:\n\nWill Sasquatch by impacted by climate change?\n\nSpecifically, climate change could result in a shift in habitat availability, i.e. should we expect a species extinction because of habitat loss or a range expansion or range shift?\nTo do this we need to generate a species distribution model (SDM) for the Sasquatch, a large, hairy, bipedal ape-like creature found (or is it?) throughout North America1, i.e. first we need to understand where Sasquatch are currently distributed to then assess how that might change in the future.1 I suppose, technically, since we were venturing into cryptozoology here it is not a species, but rather a cryptid distribution model\n\n\n1.4.2 Get occurrence data\nThe first thing we need for any SDM is a data set documenting species occurrence, i.e. geo-coded observations of a given species in the wild.\nFour our purposes, we turn to the Bigfoot Field Researchers Organization (BFRO), founded in 1995 as the “only scientific research organization exploring the Bigfoot/Sasquatch mystery”. You can turn to their website for answers on important FAQs, including ‘Do Bigfoot Sasquatch bury their dead?’, ‘Where is the physical evidence?’, ‘Wasn’t this all shown to be a fake?, and ’Why do you want scientists to recognize the Sasquatch as a species? Isn’t it better to just leave them alone?’. Their main focus though is on compiling reports of sightings and investigating them. In other words, they have a database full of geo-coded reported sightings2.2 And even better, it has already been downloaded and wrangled and is accessible (with sightings through 2018) right here.\nLet’s read in the data and then we can take a look at the information we can glean from this data set by looking at the column names.\n\n# read data\noccurrence &lt;- read_delim(\"data/bfro_reports_geocoded.txt\", delim = \"\\t\")\n\n\n\n1.4.3 Tidy, Transform & Explore the data\nLet’s start by taking a look at our data set to determine how we need to wrangle to get the information we need process it so we can generate our species distribution model.\nBecause we need to be able to identify the exact locations Sasquatch occur, we are going to remove any observations that do not have latitude and longitude information.\n\n# filter NAs\noccurrence &lt;- occurrence %&gt;%\n  filter(!is.na(longitude),\n         !is.na(latitude))\n\nNext, let’s consider is what geographic extent of the observations is by looking at the distributions on a map.\n\n# get minimum and maximum lat/longs\nmax.lat &lt;- ceiling(max(occurrence$latitude))\nmin.lat &lt;- floor(min(occurrence$latitude))\nmax.lon &lt;- ceiling(max(occurrence$longitude))\nmin.lon &lt;- floor(min(occurrence$longitude))\n\n# create an extent object of the range of observations\ngeo_range &lt;- extent(x = c(min.lon, max.lon, min.lat, max.lat))\n\n# get base map\ndata(wrld_simpl)\n\n# plot the base map\nplot(wrld_simpl, \n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE, \n     col = \"grey75\")\n\n# add individual occurrences\npoints(x = occurrence$longitude, \n       y = occurrence$latitude, \n       col = \"darkorange\", \n       pch = 20, \n       cex = 0.75)\n\n# draw box around figure\nbox()\n\n\n\n\nFigure 1.1: Map of Sasquatch sighting in the United States based on the BFRO database (1950 - 2021).\n\n\n\n\nHere is an example of where domain knowledge comes in - while we are tidying and exploring the data set we need to assess whether there are artifacts our outlier data points that should be removed.\n\n\n\n\n\n\n Consider this\n\n\n\nGive a brief description of the spatial distribution of the occurrence of Sasquatch in the United States. Note areas where sightings appear to be random, clustered or more dispersed, determine if you think any points should be removed.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nDiscuss some possible explanations for the patterns you have observed to determine whether you think this data set is a reasonable representation of the ecological niche of the Sasquatch and can be used to create a species distribution model.\n\n\n\n\n\n\n\n\nSolution\n\n\n\n\n\nGood catch - those sightings in the middle of the ocean are probably errors in the geo-coding. Further, we don’t know how reliable the data for Alaska is as this data set is based on opportunistic sightings - at least for the most part, if you poke around the BFRO website you will find that people do plan expeditions.\n\n\n\nThe data for for observations in the lower 48 seems much more reliable, so let’s restrict our data to those observations.\n\n# load and filter data\noccurrence &lt;- read_delim(\"data/bfro_reports_geocoded.txt\", delim = \"\\t\") %&gt;%\n  filter(!is.na(longitude),\n         !is.na(latitude),\n         longitude &gt; -130,\n         latitude &lt; 55)\n\n# get minimum and maximum lat/longs\nmax.lat &lt;- ceiling(max(occurrence$latitude))\nmin.lat &lt;- floor(min(occurrence$latitude))\nmax.lon &lt;- ceiling(max(occurrence$longitude))\nmin.lon &lt;- floor(min(occurrence$longitude))\n\n# create an extent object\ngeo_range &lt;- extent(x = c(min.lon, max.lon, min.lat, max.lat))\n\n# get base map\ndata(wrld_simpl)\n\n# plot the base map\nplot(wrld_simpl, \n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE, \n     col = \"grey75\")\n\n# add individual occurrences\npoints(x = occurrence$longitude, \n       y = occurrence$latitude, \n       xlim = c(min.lon, max.lon),\n       ylim = c(min.lat, max.lat),\n       col = \"darkorange\", \n       pch = 20, \n       cex = 0.75)\n\n# draw box around figure\nbox()\n\n\n\n\nFigure 1.2: Map of Sasquatch sighting in the lower 48 states based on the BFRO database as (1950 - 2021).\n\n\n\n\nThis should work - on to the next step!\n\n\n1.4.4 Get more data\nOccurrence data along will not allow us to build a species distribution model; what we need is environmental data to go with the locations, i.e. we need a set of predictor variables.\nCombining multiple data sets is typical for data science projects, frequently the quality of a project hinges on the availability of hight quality data sets that can provide information to describe or preodict behavior if the data set you are exploring.\nClimate is complex and multidimensional, though at its core climate is determined by long-term patterns in mean and variability of temperature and precipitation.\nWe are going to use the bioclim data set from CliMond. Bioclim variables are commonly used for species distribution modeling as they are based on long-term trends (as opposed to e.g. the exact conditions when the species was observed).\n\n\n\n\n\n\n Consider this\n\n\n\nLook up the descriptions of the bioclim variables and give a brief description of the four abiotic parameters that are included and how they are being parameterized. Argue which you think are most important to describe a species distribution/ecological niche and whether you think overall this data set will help us understand Sasquatch species distribution.\n\n\nThe data set we are using includes a core set of 19 variables that describe temperature and precipitation, along with an additional 16 variables that describe solar radiation and soil moisture. This information is encoded in the raster files of the historical (contemporary) bioclim data sets at a resolution of 10’ (minutes) into the data folder. The “historical” data set consists of data from 1961 - 1990 centered on 1975.\nA raster file is an image file consisting of pixels with data associated with it. In this case, our “pixels” are 10’ x 10’ and depending on the layer the value associated with each pixel is the value for that bioclim value at that geographic location.\n\n# get list of files\nfiles &lt;- list.files(\"data/\", pattern='^CM10_1975H', full.names=TRUE )\n\n# import and convert to raster stack\npredictors &lt;- stack(files)\n\nWe have now created an object that at its core consists of a list where each element is a layer (bioclim variable raster).\n\n\n1.4.5 Tidy, transform & explore the data (again)\nLet’s plot the first bioclim variable (Bio01, annual mean temperature).\n\nplot(predictors@layers[[1]])\n\n\n\n\nFigure 1.3: Global distribution of annual mean temperature (1961 - 1990, centered on 1975).\n\n\n\n\nWe see the pattern we would intuitively expect, with temperatures decreasing as you move poleward and being warmest around the poles.\nLet’s extract the values for each bioclim variable at our occurrence points (observations).\n\n# create df with just xy coordinates\nxy &lt;- occurrence %&gt;%\n  dplyr::select(longitude, latitude)\n\n# crop bioclim data to geographic range\ncropped_predictors &lt;- crop(x = predictors, y = geo_range)\n\n# extract values\npresence &lt;- raster::extract(cropped_predictors, xy)\n\nLet’s take a quick look at the first few rows and columns of the matrix we just created.\n\nhead(presence[,1:3])\n\n     CM10_1975H_Bio01_V1.2 CM10_1975H_Bio02_V1.2 CM10_1975H_Bio03_V1.2\n[1,]              8.387707              15.84337             0.3534581\n[2,]             10.156170               9.49416             0.2941423\n[3,]             15.522450              13.50635             0.3474373\n[4,]             11.259700              12.40612             0.3456673\n[5,]             10.189860              11.02385             0.3073747\n[6,]              8.724987              10.20157             0.2807353\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly state what these values represent.\n\n\n\n\n1.4.6 Create species distribution model\nOur next step is to fit a bioclim model to the data set we just generated.\n\n# fit bioclim model\nmodel.fit &lt;- bioclim(presence)\n\nThe bioclim model is a classic climate-envelope-model3.3 You may remember reading about this in your reading assignments.\nBriefly, the algorithm computes the similarity of locations by comparing the value of each environmental variables being used (our bioclim data set) to a distribution of that values at all locations with known presence4. The closer that value is to the median (50th percentile), the more suitable that location is assumed to be. Suitability scores are between 0 and 1, with 1 indicating a “perfect suitability”.)4 Also called the training sites; these are our occurrence points.\nIn general, there is no distinction between the tails of the distribution (i.e. the 90th and 10th percentile are equivalent), though in some implementations you can specify those to be treated as distinct. As a result e.g. low levels of precipitation could be limiting but high levels would not be.\nFinally, we will use our suitability scores and the bioclim raster data set to generate a predictive map of the Sasquatch species distribution. This means that the algorithm will assign a suitability score to each pixel based on the model and create a new raster layer.\n\n# generate raster with predicted distribution\nprediction &lt;- dismo::predict(x = cropped_predictors, \n                             object = model.fit,\n                             ext = geo_range)\n\nLet’s plot our species distribution map.\n\n# plot model probabilities\nplot(prediction,\n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE)\n\n# add map\nplot(wrld_simpl, add = TRUE, border = \"black\")\n\n# draw box around it\nbox()\n\n\n\n\nFigure 1.4: Species distribution model for Sasquatch. Color indicates the probability of encountering Sasquatch in the lower 48 states based on habitat suitability.\n\n\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nGive a brief description of the habitat suitability map, including the maximum probabilities. Describe wether this result fits your expectations based on the distribution map of reports we looked at earlier. According to our map, if you were planning a Sasquatch research trip, where would you be headed?\n\n\nOur highest habitat suitability values (probability of occurring) seem pretty low. One reason for this is that we used presence-only data.\n\n\n\n\n\n\n Consider this\n\n\n\nThe alternative to presence-only models is to have presence-absence data. Discuss how this would improve the models. Argue why you think presence-only data sets are easier to generate.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nA work-around of not having absence data is to generate pseudo-absence data. This is done by generating random points within the geographic range and using those as proxies for absence data. Briefly argue the merits and limitations of such an approach.\n\n\n\n\n1.4.7 Model future climate change\nProjections of future climate change are heavily dependent on human activity and the resulting greenhouse gas emissions. Therefore the IPCC’s Assessment Reports contain scenario families that represent projected climate conditions based on emission scenarios resulting from future technological and economic development as defined by each scenario.\nLet’s look at how the species distribution map might change in response to a shift in environmental parameters.\nTo do this we will use bioclim raster files for 2100 generated using the A1B and A2 scenarios.\nThe A1 climate scenarios assume a more integrated world characterized by rapid economic growth, a global population that peaks at 9 billion (2050) and the gradually declines, rapid spread of new/efficient technologies, and a convergent world characterized by extensive worldwide social and cultural interactions. Scenario A1B further assumes a balanced emphasis on fossil and non-fossil fuels.\nBy contrast, A2 scenarios assume a more divided world consisting of independently operating and self-reliant nations and regionally-oriented economic development. The population is assumed to continuously grow. Finally, this scenario is characterized by high emissions.\nLet’s start with the A1 climate scenario to create our species distribution model.\n\n# get list of files\nfiles &lt;- list.files(\"data/\", pattern='^CM10_2100_A1B', full.names=TRUE )\n\n# import and convert to raster stack\npredictors_A1 &lt;- stack(files)\n\nNow let’s fit our model and create predictive map.\n\n# create df with just xy coordinates\nxy &lt;- occurrence %&gt;%\n  select(longitude, latitude)\n\n# crop bioclim data to geographic range\ncropped_predictors &lt;- crop(x = predictors_A1, y = geo_range)\n\n# extract values\npresence &lt;- raster::extract(cropped_predictors, xy)\n\n# fit the bioclim model\nmodel.fit &lt;- bioclim(presence)\n\n# create raster layer of predicted distribution\nprediction &lt;- dismo::predict(x = cropped_predictors, \n                             object = model.fit,\n                             ext = geo_range)\n\nFinally, let’s plot our species distribution map.\n\n# plot model probabilities\nplot(prediction,\n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE)\n\n# add map\nplot(wrld_simpl, add = TRUE, border = \"black\")\n\n# draw box around it\nbox()\n\n\n\n\nFigure 1.5: Predicted species distribution for Sasquatch in the lower 48 in 2100 (climate scenario A1B). Color indicates the probability of encountering Sasquatch in the lower 48 states based on habitat suitability.\n\n\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nGive a brief description of the habitat suitability map, including the maximum probabilities. Describe whether this fit your expectations based on the change in bioclim variables. Describe the shift in habitat suitability relative to our current model.\n\n\nHow about our A2 climate scenario?\n\n# get list of files\nfiles &lt;- list.files(\"data/\", pattern='^CM10_2100_A2', full.names=TRUE )\n\n# import and convert to raster stack\npredictors_A2 &lt;- stack(files)\n\n# create df with just xy coordinates\nxy &lt;- occurrence %&gt;%\n  select(longitude, latitude)\n\n# crop bioclim data to geographic range\ncropped_predictors &lt;- crop(x = predictors_A2, y = geo_range)\n\n# extract values\npresence &lt;- raster::extract(cropped_predictors, xy)\n\n# fit the bioclim model\nmodel.fit &lt;- bioclim(presence)\n\n# create raster layer of predicted distribution\nprediction &lt;- dismo::predict(x = cropped_predictors, \n                             object = model.fit,\n                             ext = geo_range)\n\n# plot model probabilities\nplot(prediction,\n     xlim = c(min.lon, max.lon),\n     ylim = c(min.lat, max.lat),\n     axes = TRUE)\n\n# add map\nplot(wrld_simpl, add = TRUE, border = \"black\")\n\n# draw box around it\nbox()\n\n\n\n\nFigure 1.6: Predicted species distribution for Sasquatch in the lower 48 in 2100 (climate scenario A2). Color indicates the probability of encountering Sasquatch in the lower 48 states based on habitat suitability.\n\n\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nBriefly compare this model to the previous two. Comment on whether you expected to see greater or smaller difference to the other future climate prediction based on the scenarios that they are based on.\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nDiscuss whether you think bioclim variables are good models to predict a species’ respone to climate change. In your discussion consider how future bioclim data sets are generated, as well as, whether abiotic conditions along will determine range changes."
  },
  {
    "objectID": "01_intro-data-science.html#visualize-and-communicate-your-results",
    "href": "01_intro-data-science.html#visualize-and-communicate-your-results",
    "title": "1  What even is Data Science?",
    "section": "1.5 Visualize and Communicate your results",
    "text": "1.5 Visualize and Communicate your results\nPrinting our maps side by side for better comparison would be a good way to visualize and communicate our results. We would probably include a discussion of our our approach (we should probably validate our model too which we haven’t done here) and make recommendations based on our findings."
  },
  {
    "objectID": "01_intro-data-science.html#acknowledgments",
    "href": "01_intro-data-science.html#acknowledgments",
    "title": "1  What even is Data Science?",
    "section": "1.6 Acknowledgments",
    "text": "1.6 Acknowledgments\nSince I’m not the first person to create a lab/tutorial on species distribution modeling, I drew inspiration from various educators, R and data enthusiasts to shape this tutorial, most notably:\nAnna L. Carter. November 2017, posting date. Painting turtles: an introduction to species distribution modeling in R. Teaching Issues and Experiments in Ecology, Vol. 13: Practice #1 [online]. http://tiee.esa.org/vol/v13/issues/data_sets/carter/abstract.html\nWendy L. Clement, Kathleen L. Prudic, and Jeffrey C. Oliver. 16 August 2018, posting date. Exploring how climate will impact plant-insect distributions and interactions using open data and informatics. Teaching Issues and Experiments in Ecology, Vol. 14: Experiment #1 [online]. http://tiee.esa.org/vol/v14/experiments/clement/abstract.html\nhttps://jcoliver.github.io/learn-r/011-species-distribution-models.html"
  },
  {
    "objectID": "02_install-R.html#learning-objectives",
    "href": "02_install-R.html#learning-objectives",
    "title": "2  Getting set up with R and Rstudio",
    "section": "2.1 Learning Objectives",
    "text": "2.1 Learning Objectives\nAfter completing this activity you should\n\nbe able to download and install R and Rstudio on your laptop\nbe able to install Rtools & devtools to be able to compile R packages from source (Windows).\nunderstand the main use for each of the four main panes in the Rstudio GUI.\nunderstand what a package is in R and how to install them."
  },
  {
    "objectID": "02_install-R.html#install-set-up-r-and-rstudio-on-your-computer",
    "href": "02_install-R.html#install-set-up-r-and-rstudio-on-your-computer",
    "title": "2  Getting set up with R and Rstudio",
    "section": "2.2 Install & Set up R and Rstudio on your computer",
    "text": "2.2 Install & Set up R and Rstudio on your computer\nIf you have already installed R and Rstudio make sure your R version is up to date. Whenever you open Rstudio the version will be printed in the console (bottom left pane). In addition, you can always check what version is installed by typing sessionInfo() into your console. You should be using version 4.0.0 or later. You do not need to uninstall old version of R. If you do have to update, you will need to re-install packages (see below) for R4.0.0\n\n2.2.1 Windows\nInstall R\n\nDownload most recent version of R for Windows here.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard.\n\nInstall Rtools\n\nDownload Rtools here.\nRun the downloaded .exe file that was download and follow the instructions in the set-up wizard.\n\nInstall Rstudio\n\nGo to Rstudio download page.\nScroll down to select the Rstudio current version for Windows XP/Vista/7/8/10.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard.\n\nFinish setting up Rtools\n\nOpen Rstudio to make sure you aren’t getting any error messages.\nPut Rtools in your path by typing writeLines('PATH=\"${RTOOLS40_HOME}\\\\usr\\\\bin;${PATH}\"', con = \"~/.Renviron\") in the console window.\nInstall the devtools package by typing install.packages(\"devtools\") in the console.\n\nInstall quarto\nDownload quarto using this link. Pick the file according to your operating system Run the downloaded .exe file that was download and follow the instructions in the set-up wizard.\n\n\n2.2.2 Mac OS X\nDownload & install R\n\nGo to (CRAN)[http://cran.r-project.org/], select Download R for (Mac) OS X.\nDownload the .pkg file for your OS X version.\nRun the downloaded file to install R.\n\nDownload & install XQuartz (needed to run some R packages)\n\nDownload XQuartz\nRun the downloaded file to install\n\nDownload & install Rstudio\n\nGo to Rstudio download page.\nScroll down to select the Rstudio current version for Mac OS X.\nRun the .exe file that was downloaded and follow instructions in the set-up wizard.\n\nInstall quarto\nDownload quarto using this link. Pick the file according to your operating system Run the downloaded .exe file that was download and follow the instructions in the set-up wizard."
  },
  {
    "objectID": "02_install-R.html#get-to-know-rstudio",
    "href": "02_install-R.html#get-to-know-rstudio",
    "title": "2  Getting set up with R and Rstudio",
    "section": "2.3 Get to know Rstudio",
    "text": "2.3 Get to know Rstudio\nRstudio is an Integrated Development Environment (IDE) that you can use to write code, navigate files, inspect objects, etc. The advantage of using an IDE is that you have access to shortcuts, visual cues, troubleshooting, navigation, and autocomplete help.\n\n2.3.1 GUI Layout\nGUI stands for graphic user interface and refers to a type of user interface that allows users to interact with software applications and electronic devices through visual elements such as icons, buttons, windows, and menus, rather than using text-based command-line interfaces.\nYou have probably mostly interacted with computer programs through a GUI, where you interact with the system by manipulating graphical elements using a pointing device like a mouse, touch screen, or stylus. GUIs provide a more intuitive and user-friendly way for individuals to interact with computers and software because you can “see” what the effect of what you are doing is having. Graphical User Interfaces are a major departure from earlier text-based interfaces like command-line interfaces. They have contributed significantly to the widespread adoption of computers and software by making them more accessible to a broader range of users. GUIs are used in various types of software, from operating systems to applications like web browsers, image editors, word processors, and more.\nNot too long ago, if you had wanted to learn R or another programming language you would have been working directly on a console instead of an IDE like Rstudio which has made coding a lot more accessible to beginners because you can more easily use scripts, interactively run code and visualize data.\n\n\n\n\n\n\nNote\n\n\n\nUse this link to access an Rstudio IDE Cheatsheet pointing out the key features using annotated impages of the different panes. You can also download a pdf version and keep a printout handy as you get used to the GUI.\n\n\nOpen Rstudio and identify the four panes in the interface (default layout).\n\nEditor (top left): edit scripts/other documents, code can be sent directly to the console.\nR console (bottom left): Run code either by directly typing the code or sending it from the editor pane.\nEnvironment/history (top right): Contains variables/objects as you create them & full history of functions/commands that have been run.\nfiles/plots/packages/help/viewer (bottom right): Different tabs in this pane wil let you explore files on your computer, view plots, loaded packages, and read manual pages for various functions.\n\nThe panes can be customized (Rstudio -&gt; Preferences -&gt; Pane Layout) and you can move/re-size them using your mouse.\n\n\n\n\n\n\nNote\n\n\n\nWe are going to switch to have the Console in our top right and the Environment in the bottom left which makes it easier to see your code output and your script/quarto document at the same time.\n\n\n\n\n2.3.2 Interacting with R in Rstudio\nThink of R as a language that allows you to give your computer precise instructions (code) to follow.\n\nCommands are the instructions we are giving the computer, usually as a series of functions.\nExecuting code or a program means you are telling the computer to run it.\n\nThere are three main ways to interact with R - directly using console, script files (*.R), or code chunks embedded in R markdown (*.Rmd) or quarto files (*.qmd). We will generally be working with the later.\nThe console is where you execute code and see the results of those commands. You can type your code directly into the console and hit Enter to execute it. You can review those commands in the history pane (or by saving the history) but if you close the session and don’t save the history to file those commands will be forgotten.\nBy contrast, writing your code in the script editor either as a standard script or as a code chunk in an quarto document allows you to have a reproducible workflow (future you and other collaborators will thank you).\nExecuting an entire script, a code chunk, or individual functions from a script will run them in the console.\n\nCtrl + Enter will execute commands directly from the script editor. You can use this to run the line of code your cursor is currently in in the script editor or you can highlight a series of lines to execute.\nIf you are using a quarto file you can execute an entire code chunk by pressing the green arrow in the top right corner.\n\nIf the console is ready for you to execute commands you should see a &gt; prompt. If you e.g. forget a ) you will see a + prompt - R is telling you that it is expecting further code. When this happens and you don’t know what you are missing (usually it is an unmatched quotation or parenthesis), make sure your cursor is in the console and hit the Esc key.\n\nWe will run through these options, but you can always check back here while you are getting used to R.\n\n\n\n2.3.3 Customize Rstudio\nThere are several options to customize Rstudio including setting a theme, and other formatting preferences. You can access this using Tools &gt; Global Options. I recommend using a dark theme (it’s a lot easier on the eyes) and keeping the panes in the same positions outlined above because it will make troubleshooting a lot easier1.1 “You should see xx in the top left” is a lot more helpful if your top left looks like my top left!"
  },
  {
    "objectID": "02_install-R.html#installing-and-using-packages-in-r",
    "href": "02_install-R.html#installing-and-using-packages-in-r",
    "title": "2  Getting set up with R and Rstudio",
    "section": "2.4 Installing and using packages in R",
    "text": "2.4 Installing and using packages in R\n\n2.4.1 Install a package\nThink of R packages or libraries as tool kit comprising a set of functions (tools) to perform specific tasks. R comes with a set of packages already installed that gives you base R functions; you can view these and determine which have been loaded in the Packages tab in the bottom right pane. For other tasks we will need additional packages. 22 Most R packages are found in the CRAN repository and on Bioconducter, developmental packages are available on github.\nA central group of packages for data wrangling and processing form the tidyverse, described as “… an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures.” - We are going to heavily rely on core functions from the tidyverse to wrangle, summarize, and analyze data.\nWhen you install packages they will be downloaded and installed onto your computer. Determine what your default path is using .libPaths() and change if necessary.\nThe easiest way to install packages directly in the console is to use the install.packages() function.\nUse the R console to install some libraries to get us started (we will install other libraries as needed for other labs).\n\n\nUsing # in an R script allows you to insert comments that are ignored by R when executing your code. Use comments to document your code, future you will thank you! Before submitting any of your skills tests or homework assignments you should always go through and make sure each piece of code has a descriptive comment. You do not need to add a comment for multi-line code that you are stringing together using a pipe %&gt;% but you should have one descriptive comment above the set of commands you are giving R and then make sure that you add any comments that you need to remember how the function works or which parameters might be useful to tweak/set differently if you were to reuse that code.\n\n# install central packages in the tidyverse\ninstall.packages(\"tidyverse\")\n\n# install additional packages\ninstall.packages(\"plyr\", \"ggthemes\", \"patchwork\", \"glue\")\n\nLet’s check if you were able to successfully install those packages by ensureing you can load them. Any time you start a new R session (e.g. by closing Rstudio and restarting it), you will need to load your libraries beyond the base libraries that are automatically loaded using the library() function in order to be able to use the functions specific to that package3.3 Troubleshooting tip: if you get an error along the lines of function() cannot be found the first thing you will want to do is check if your libraries are loaded!\n\n# load library\nlibrary(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.3.1\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nIf you don’t see any error messages in the console along the lines of there is no package called ... you are all set. If you look in the packages tab in the lower right panel you should also see that packages such as dplyr and tidyr (two of the central tidyverse packages) now have a little check box next to them.\n\n\n2.4.2 Updating R packages\nYou should generally make sure to keep your R packages up to date as new versions include important bugfixes and additional improvements. The easiest way to update packages is to use the Update button in the Packages tab in the bottom right panel. Over the course of the semester you should not have to do this, but when you install new packages you might get message that some of your packages need to be updated which you can then either choose to do at that point or ignore.\n\n\n\n\n\n\nWarning\n\n\n\nBe aware that updating packages might break some code you have previously written. For most of what we will be doing this should not be the case. If you used R for a previous course, make sure to update you packages at the beginning of this course and we should be set for the semester."
  },
  {
    "objectID": "03_Rbasics.html#learning-objectives",
    "href": "03_Rbasics.html#learning-objectives",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.1 Learning Objectives",
    "text": "3.1 Learning Objectives\nAfter completing this tutorial you should be able to\n\nname, create, and assign values to objects.\nsave a series of commands/code as an R script.\nuse comments to describe your code/scripts.\ncall functions and modify the default options using their arguments.\nunderstand what a vector is and distinguish between the main data types.\nto inspect, subset, and extract their content from a vector.\nunderstand how data.frames and vectors relate."
  },
  {
    "objectID": "03_Rbasics.html#r-is-all-about-objects",
    "href": "03_Rbasics.html#r-is-all-about-objects",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.2 R is all about Objects",
    "text": "3.2 R is all about Objects\nYou can think of the R console as a super-powerful calculator. You can get output from R by simply typing math directly into the console.\n\n13 + 29\n\n[1] 42\n\n\nor\n\n546 / 13\n\n[1] 42\n\n\nWell that’s fun - but not super helpful in our context.\nIn the R programming language, an object is a fundamental concept used to store, manipulate, and represent data. Everything in R is treated as an object, whether it’s a number (numeric), a text string (character), a dataset (data.frame), or even more complex data structures.\nObjects in R can be created, modified, and used to perform various operations. Objects are assigned names that you can then use to reference them in your code. When you create an object, you’re essentially creating a container that holds a value or data.\nCreating an object is straightforward. First, we give it a name, then we use the assignment operator to assign it a value.\nThe assignment operator (&lt;-) assigns the value on the right of the &lt;- to the object on the left1.1 Start building good habits starting now in terms of your coding style. For example, your code is a lot more readable if you use white space to your advantage. For example, make sure you have a space before and after your &lt;-\n\nfork_length_mm &lt;- 344\n\nType that into the console and execute the command using Enter. If you look at your Global Environment (bottom left panel) you should now see forklength and the value you assigned it.\nNotice, how when you assigned a value to your new object nothing was printed in the console compared to when you were typing in math.\nTo print the value of an object you can type the name of the object into the console.\n\n# print value\nfork_length_mm\n\n[1] 344\n\n\nNow that fork_length_mm is in your environment we can use it to compute instead of the value itself.\nFor example, we might need to convert our fork length from millimeters (mm) to centimeters (cm).\n\nfork_length_mm / 10 \n\n[1] 34.4\n\n\nWe can change the value of an object any time by assigning it a new one. Changing the value of one object does not change the values of other objects.\n\nfork_length_mm &lt;- 567\n\n\n\n\n\n\n\n Give it a whirl!\n\n\n\nCreate a new object with the fork length in centimeters. Then change then change the value of our fork length in millimeters object to 50. What do you think the value of fork_length_mm will be now?\n\n\nSome initial thoughts on naming things22 You will soon discover that coding is 90% naming things.\nTheoretically, we can name objects anything we want - but before that gets out of hand let’s think about some guidelines for naming objects.\n\nMake them simple, specific, and not too long (otherwise you will end up with a lot of typing to do and difficulties remembering which object is which).\nObject names cannot start with a number.\nR is case sensitive, fork_length is not the same as Fork_Length.\nAvoid using dots (.) in names. Typically dots are used in function names and also have special meaning (methods) in R.\nSome names are already taken by fundamental functions (e.g. if, else, for) and cannot be used as names for objects; in general avoid using names that have already been used by other function names.\nRule of thumb: nouns for object names, verbs for function names.\n\nUsing a consistent style for naming your objects is part of adopting a consistent styling of your code; this includes things like spacing, how you name objects, and upper/lower case. Clean, consistent code will make following your code a lot easier for yourself and others3.3 Remember, future you is your most important collaborator.\n\n\n\n\n\n\nNote\n\n\n\nOne of the criteria for your homework assignments and skills tests is your code style. Next to imitating the style of coding presented in this manual, you can refer to r4ds (2e) Ch 5 for some initial pointers, you can also access a short style guide here and a more detailed, tidyverse specific style guide here."
  },
  {
    "objectID": "03_Rbasics.html#saving-your-work",
    "href": "03_Rbasics.html#saving-your-work",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.3 Saving your work",
    "text": "3.3 Saving your work\nSo far, we have inputed all of our code directly into the console. If you scroll up in the console you will find that all the commands and results from your current R session are still in the console. Using Cmd/Ctrl + L will clear the entire console.\nUh-oh - what if we need to go back over the code we just cleared?\nWell, for one if you check the History tab in the top right panel you will see that all your commands have been recorded. If you highlight one of them and either click on To Console or hit Enter it will send it directly to the console.\nUsually your history will be saved automatically when you close R/end an R session (unless you have changed the settings) and it will be restored when you open R again. You can use the broom icon to clear your entire history.\nUh-oh - now what do we do?\nIn general, you should only be typing code directly into the console for quick queries or troubleshooting but since usually we want to be able to revisit and share our work you will want to be able to save your work in an R script (*.R) or include it in a quarto document (*.qmd) as a code chunk. For this course we will mostly be operating with quarto files (more on that in the next chapter).\nYou can open a new R script using Ctrl + Shift + C or using File &gt; New File &gt; R Script. This will open an R script in a new tab in the top left pane.\nSave your R script using Cmd/Ctrl + S or File &gt; Save As - this will open a dialogue box for you to save your R script with the file extension .R.\nCtrl + Enter will execute commands directly from the script editor by sending them through to the console. You can use this to run the line of code your cursor is currently in in the script editor or you can highlight a series of lines to execute. You can also run all the code in a script by clicking on the Run button.\nCreate a new R script to keep track of the rest of the things we will learn today."
  },
  {
    "objectID": "03_Rbasics.html#using-comments",
    "href": "03_Rbasics.html#using-comments",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.4 Using comments",
    "text": "3.4 Using comments\nYou can add comments to your R scripts using #. Essentially, once you type an # in a line anything to the right of it will be ignored.\nThis is really helpful as it will allow you to comment your script, i.e. you can leave notes and explanations as to what your code is doing for future you and for other collaborators. This is especially helpful if you come back to some of your code after a period of time, if you are sharing your code with others, and when you are debugging code. You will find that as you become more experienced your comments will become shorter and more concise and you might even be tempted to leave them out completely - don’t4!4 To help you build a habit of good commenting practice, commenting your code is a requirement for your homework assignment and skills tests.\nFor example you might find a comment like this more helpful at the moment:\n\n# assign value to new object total length\nfork_length &lt;- 436\n\nBut soon you’ll find this just as helpful:\n\n# total length fish\nfork_length &lt;- 436\n\n\n\n\n\n\n\n Consider this.\n\n\n\nPredict what value of the object total_length will be after executing this command?\n\n\n\nFL &lt;- 436  # total length fish\n\n\n\n\n\n\n\nProtip\n\n\n\nYou can comment/uncomment multiple lines at once by highlighting the lines you want to comment (or uncomment) and hitting Ctrl + Shift + C. This can be useful if you are playing around with code and don’t want to delete something but don’t want it to be run either."
  },
  {
    "objectID": "03_Rbasics.html#functions",
    "href": "03_Rbasics.html#functions",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.5 Functions",
    "text": "3.5 Functions\nWhen we installed R packages earlier we mentioned that they are sets of predefined functions. These are essentially mini-scripts that automate using specific sets of commands. So instead of having to run multiple lines of code (this can be 10s - 100s of lines code) you call the function instead.\nEach function usually requires multiple inputs (arguments) and once executed return a value (though this is not always the case).\nFor example the function round() can be used to round a number5.5 This is an excellent example of naming things well!\n\nfork_length_cm &lt;- round(34.8821)\n\nIf we print the value of our object we see the following value is returned.\n\nfork_length_cm\n\n[1] 35\n\n\nFor this function the input (argument) is a number and the returned value is also a number. This is not always the case, arguments can be numbers, objects, file paths …\nMany functions have set of arguments that alter the way a function operates - these are called options. Generally, they have a default value which are used unless specified otherwise by the user.\nYou can determine the arguments as function by calling the function args().\n\nargs(round)\n\nfunction (x, digits = 0) \nNULL\n\n\nOr you can call up the help page using ?round or by typing it into the search box in the help tab in the lower right panel.\nFor example, our round() function has an argument called digits, we can use this to specify the number of significant digits we want our rounded value to have.\n\nround(34.8821, digits = 2)\n\n[1] 34.88\n\n\nIf you provide the arguments in the exact same order as they are defined you do not have to specify them.\n\nround(34.8821, 2)\n\n[1] 34.88\n\n\nHowever, if you specify the arguments, you can switch their order.\n\nround(digits = 2, x = 34.8821)\n\n[1] 34.88\n\n\n\n\n\n\n\n\nProtip\n\n\n\nGood code style is to put the non-optional arguments (frequently the object, file path or value you are using) first and then specify the names of all the optional arguments you are specifying. This provides clarity and makes it easier for yourself and others to follow your code.\n\n\nOccasionally you might even want to use comments to further specify what each argument is doing or why you are choosing a specific option.\n\nround(34.8821,     # number to round\n      digits = 2)  # specify number of significant digits\n\n[1] 34.88"
  },
  {
    "objectID": "03_Rbasics.html#vectors-data-types-i",
    "href": "03_Rbasics.html#vectors-data-types-i",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.6 Vectors (data types I)",
    "text": "3.6 Vectors (data types I)\nNow that we’ve figured out what objects and functions are let’s get to know the two data types we will be spending the most time with this semester - vectors and data frames (data.frame)6.6 Other data types include lists (list), factors (factor) matrices (matrix), and arrays (array); we’ll introduce those later on.\nThe most simple data type in R is the (atomic) vector which is a linear vector of a single type. There are six main types -\n\ncharacter: strings or words.\nnumeric or double: numbers.\ninteger: integer numbers (usually indicated as 2L to distinguish from numeric).\nlogical: TRUE or FALSE (i.e. boolean data type).\ncomplex: complex numbers with real and imaginary parts (we’ll leave it at that).\nraw: bitstreams (we won’t use those either).\n\nYou can check the data type of any object using class().\n\nclass(fork_length)\n\n[1] \"numeric\"\n\n\nCurrently, our fork_length object consists of a single value. The function c() (concatenate) will allow us to assign a series of values to an object.\n\nfork_length &lt;- c(454, 234, 948, 201)\n\nfork_length\n\n[1] 454 234 948 201\n\n\n\n\n\n\n\n\n Consider this\n\n\n\nPredict what data type you expect this vector to be.\n\n\nWe call the same function to create a character vector.\n\nsharks &lt;- c(\"bullshark\", \"blacktip\", \"scallopedhammerhead\")\n\nclass(sharks)\n\n[1] \"character\"\n\n\nThe quotes around \"bullshark\" etc. are essential because they indicate that this is a character.\n\n\n\n\n\n\nTip\n\n\n\nIf we do not use quotes, R will assume that we are trying to call an object and you will get an error code along the lines of “! object ‘bullshark’ not found”.\n\n\nYou can use c() to combine an existing object with additional elements (assuming they are the same data type).\n\nspecies &lt;- c(sharks, \"gafftop\")\n\nspecies\n\n[1] \"bullshark\"           \"blacktip\"            \"scallopedhammerhead\"\n[4] \"gafftop\"            \n\n\nNext to class() there are other helpful functions to inspect the content of a vector. For example length() will tell you how many elements are in a particular vector.\n\nlength(fork_length)\n\n[1] 4\n\n\nThe function str() will give you an overview of the structure of any object and its elements.\n\nstr(fork_length)\n\n num [1:4] 454 234 948 201\n\n\nRecall, that an atomic vector is a linear vector of a single type. Let’s explore what that means by taking a look at what happens if we create atomic vectors where we mix the data types.\n\n\n\n\n\n\n Consier this\n\n\n\nDescribe what happens when data types are mixed in a single atomic vector based on the messages generated by the code chunk below to figure out what the rules are in terms of which data type is convered to match the others when they are mixed.\n\n\n\nnumeric_character &lt;- c(1, 2, 3, \"a\")\nnumeric_logical &lt;- c(1, 2, 3, TRUE)\ncharacter_logical &lt;- c(\"a\", \"b\", \"c\", TRUE)\nwtf &lt;- c(1, 2, 3, \"4\")\n\nWe already discovered that we can combine vectors - but can we extract certain components from vectors? Indeed, there are a variety of ways that we can subset vectors.\nThe most simple way is using square brackets to indicate which element (or elements) we can’t extract. In R, indices start at 1.77 This is not the case for all programming languages, e.g. Perl, Python, or C++ start with 0.\n\n# extract second element\nspecies[2]\n\n[1] \"blacktip\"\n\n# extract fourth and second element\nspecies[c(4, 2)]\n\n[1] \"gafftop\"  \"blacktip\"\n\n\nYou can also repeat indices to create a new object with additional elements.\n\nspecies_longer &lt;- species[c(2, 2, 4, 3, 4, 4, 1, 1)]\n\nspecies_longer\n\n[1] \"blacktip\"            \"blacktip\"            \"gafftop\"            \n[4] \"scallopedhammerhead\" \"gafftop\"             \"gafftop\"            \n[7] \"bullshark\"           \"bullshark\"          \n\n\nMore frequently, we will want to extract certain elements based on a specific condition (conditional subsetting).\nThis is done using a logical vector, here TRUE select the element with the same index and FALSE will not.\n\nfork_length &lt;- c(454, 234, 948, 201)\n\n# use logical vector to subset\nfork_length[c(TRUE, FALSE, TRUE, FALSE)]\n\n[1] 454 948\n\n\nThis seems like a very impractical option. However, normally we would not create the logical vector by hand as we have done here, rather it will be the output of a function or logical test. For example, we might want to identify fish with a fork length &gt; 300mm.\n\n# identify fish with fork length &gt; threshold\nfork_length &gt; 300\n\n[1]  TRUE FALSE  TRUE FALSE\n\n\nThis creates an output the same length as the vector we looked at (fork_length) consisting of TRUE/FALSE statements for each element by comparing the each element of the vector to the condition (&gt;300) and determining if the condition is met (the statement is true) or not.\nInstead of first creating a vector of TRUE/FALSE statements can use this condition to subset our vector directly.\n\n#  identify true/false of fish with fork length &gt; threshold\nfork_length[c(fork_length &gt; 300)]\n\n[1] 454 948\n\n\nThere are a series of boolean expressions8 we can use for subsetting vectors.8 Boolean expressions are logical statements that are either true or false; most of them you are probably already familiar with because math\n\n&gt; and &lt; (greater/less than)\n=&gt; and =&lt; (equal to or greater/less than)\n== (equal to) and != (is not equal to)\n\n\n\n\n\n\n\nProtip\n\n\n\nYou can combine to boolean expressions using &, (both conditions must be met) and | (at least one condition must be met).\n\n\n\n\n\n\n\n\n Give it a whirl\n\n\n\nSubset the fork_length vector to\n\ncontain only values equal to 234\ncontain all values but 948\ncontain all values larger than 230 but smaller than 900\ncontain all values smaller than 250 or larger that 900\n\n\n\nR is set apart from other programming languages because it was designed to analyze data9 it has straightforward ways to deal with missing data (NA or na values) because those are quite common in real world data sets.9 some people will argue that it is a ‘statistical language’ rather than a true programming language … don’t listen to them, they are just jealous of your R skillz!\nLet’s create a vector with a missing value.\n\ntotal_length &lt;- c(560, NA, 1021, 250)\n\nLet’s say we want to calculate the mean value.\n\nmean(total_length)\n\n[1] NA\n\n\nMost functions will return NA when doing operations on objects with missing values. As such, many functions include an argument to omit missing values.\n\nmean(total_length, na.rm = TRUE)\n\n[1] 610.3333\n\n\nOther functions that are helpful to deal with missing values are is.na(), na.omit(), and complete.cases().\n\n\n\n\n\n\n Let’s give this a whirrl.\n\n\n\nSubset the fork_length vector to\nRun each of these functions on our total_length vector and describe what they do.”"
  },
  {
    "objectID": "03_Rbasics.html#data-frames-data-types-ii",
    "href": "03_Rbasics.html#data-frames-data-types-ii",
    "title": "3  R: Functions, Objects, Vectors - oh my!",
    "section": "3.7 Data frames (data types II)",
    "text": "3.7 Data frames (data types II)\nRecall that atomic vectors are linear vectors of a simple type, essentially they are one dimensional. Frequently we will be using data frames (data.frame) which you can think of as consisting of several vectors of the same length where each vector becomes a column and the elements are the rows.\nLet’s create a new object that is a dataframe with three columns containing information on species, fork length, and total length.\n\n# combine vectors into data frame\ncatch &lt;- data.frame(species, fork_length, total_length)\n\nYou should now see a new object in your Global Environment and you will now also see that there are two categories of objects Data and Values. You will see that the data.frame is described as having 4 obs (observations, those are your rows) of 3 variables (those are your columns). If you click on the little blue arrow it will give you additional information on each column - note that because each column is essentially a vector, each one must consist of a single data type which is also indicated.\nCalling the str() will give you the same information.\n\nstr(catch)\n\n'data.frame':   4 obs. of  3 variables:\n $ species     : chr  \"bullshark\" \"blacktip\" \"scallopedhammerhead\" \"gafftop\"\n $ fork_length : num  454 234 948 201\n $ total_length: num  560 NA 1021 250\n\n\nYou can further inspect the data.frame by clicking on the little white box on the right which will open a tab in the top left panel next to your R script. You can also always view a data.frame by calling the View() function.\n\nView(catch)\n\nThis can be a helpful way to explore your data.frame, for example, clicking on the headers will sort the data frame by that column. Usually we won’t build or data.frames by hand, rather we will read them in from e.g. a tab-delimited text file - but more on that later."
  },
  {
    "objectID": "04_Rproj.html#learning-objectives",
    "href": "04_Rproj.html#learning-objectives",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.1 Learning Objectives",
    "text": "4.1 Learning Objectives\nAfter completing this tutorial you should\n\nbe able to set up a well structured research compendium1.\nunderstand what a working directory is and how to set up an R project.\nunderstand the value of using Rmarkdown and quarto documents to document your work.\nunderstand the core components of the markdown format.\nbe able to use basic markdown syntax to format a document (headers, bold/italics).\nbe able to add a code chunk to a .qmd file and add options.\nunderstand how to modify code chunk options to determine what is/is not rendered in the knitted document.\nknow how to render a document to produce an *.html file from an *.qmd2.\n\n1 We will at a later point in this semester revisit and determine if this truly is a well-structured folder structure2 the recent implementation of quarto has made exporting to other formats such as pdf a lot more straightforwardThe goal of open science and reproducible research is to make scientific methods, data, and results more transparent, available, and reproducible. Quarto documents written in markdown are a useful tool to be able to generate reports documenting your data, methods (code used to process data), and results. Recently quarto has been implemented as a authoring framework for data science that extends past previous use of Rmarkdown focused on R and makes it easy to include python and other coding languages.\nSimilar to R markdown (*.Rmd) files, quarto documents will let you document your workflow, share how you processed/analyzed your data and the resulting output along with any visualizations. Quarto unifies and extends the functionality of several packages that were devoloped around using R markdown unto a consistent system that supports several coding languages beyond R including python and Julia. This is a text based file format that consists of standard text, code chunks, and the resulting output using a very simple syntax (henc markdown as opposed to markup languages like html or LateX which have much more complicated syntax). When you render your document, the code is executed and the resulting output with be included in the rendered document (common formats are html or pdf). Advantages to a workflow centered around using quarto and markdown to document your work include:\n\nthe simple syntax makes it easy to learn the basics (but some of the more advance options will let you create some sophisticated reports)3.\nresulting files have a simple, standardized formatting that looks professional and is easy to read and understand (code, documentation, figures all in one place).\nfuture you will be thankful when you don’t have to remember your assumptions, individual steps, and modifications.\neasy modification to extend/refine analysis or re-run with updated data.\n\n3 Rstudio now also has a visual editor so you can really get away with knowing very little markdown, though the basics can’t hurt and knowing a few tricks like inline code will let you do some pretty cool stuff with your documents\n\n\n\n\n\nNote\n\n\n\nUse this link to access a quarto cheatsheet for a quick overview on publishing and sharing with quarto. You can also download a pdf summarizing the core quarto functionalities to keep handy as you get used to setting up quarto documents.\nSimilarly, Use this link to access a rmarkdown cheatsheet. We won’t be using Rmarkdown documents but the syntax of writing in markdown is the same. You can also download and print a pdf for easy access."
  },
  {
    "objectID": "04_Rproj.html#project-organization-101",
    "href": "04_Rproj.html#project-organization-101",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.2 Project organization 101",
    "text": "4.2 Project organization 101\nA key component to doing data analysis is organizing your working directory which will contain your data, scripts, quarto-documents, results, figures, and other output. Keeping this well organized will help you establish a reproducible workflow, collaborate well, and share your results.\n\n4.2.1 Organizing your files and directories\nFor each project/lab we will set up a project directory4 with the following set of sub-directories:4 We’ll use this term interchangeably with working directory and research compendium\n\ndata\nresults\nscr\n\nYou will want to set up a folder (directory) locally5 on your computer called bi349 that you will use throughout this semester for all the project directories, a good place is your Documents directory or in a pinch your desktop. You will frequently download an entire research compendium with data and quarto documents “preloaded”. Macs will automatically unzip those folders on a Windows computer you will need to do this by hand (right click &gt; extract all), then move that folder into your bi329 directory. Make sure you are running your Rprojects out of the correct folder - this is one of the most common issues we run into when things aren’t working as they should.5 Local means that it is physically on your computer hard drive. If you have an automatic integration with a cloud storage service like OneDrive past experience has shown that you can run into difficulties, so yes, cloud backup is good but make sure that you are running your projects locally off your computer\n\n\n4.2.2 A note on Naming things\nNaming conventions for files, sub-directories etc. should conform to the following key principles6:6 see Jenny Bryan’s excellent summary of these principles\n\nHuman readable: keep it short but self-explanatory.\nMachine readable: don’t use special characters or spaces.\nSortable: standardize components of the file names to make it possible to sort files and find what you are looking for.\n\nLet’s consider these the holy trinity of naming things. Other helpful conventions include sticking to all lowercase7, consistent use of _ and - instead of spaces, writing your dates as year-month-day, using leading zeros (e.g. 001, 002, … etc instead of 1, 2, ... 10, 11, 12... which will sort as 1, 11, 12, ... 2, 21, ... etc once you go into double digits).7 alternatives include uppercase or CamelCase, but since R is case sensitive this leads to mroe typos\n\n\n4.2.3 Set up your project directory using Rprojects\nCreate a directory called bi328 locally on your computer. Make sure you know where it is, you will be adding to this directory throughout the semester.\nCreate a project directory 8 (e.g. IntroR) within your bi328 folder, and within that directory create sub-directories data, results, scr.8 Yes, a directory is essentially a folder, however when using the term directory we are considering the relationship between a folder and it’s full path.\nNow, we are going to create an R project within this directory.\n\nin the top right hand corner of Rstudio click on the project icon\nselect New Project and Create in existing directory\nfollow the prompts to navigate to your IntroR directory to create a new Rproject.\n\nThis should create a new R project and open it (the R project name should be in the top right corner next to the icon).\nIf you look in the bottom left hand pane in the Files tab, the bread crumbs should lead to your project folder which has now become your working directory, i.e. all paths are relative to this location. 9 If you navigate away from your working directory (project directory) you can quickly get back to your project directory by clicking on the project icon in the Files pane or by clicking the cog icon (More) and selecting Go to Working Directory.9 If you weren’t working with an R project, you can set your working directory by navigating to your new working director and selecting More &gt; Set as working directory."
  },
  {
    "objectID": "04_Rproj.html#structure-of-an-quarto-document",
    "href": "04_Rproj.html#structure-of-an-quarto-document",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.3 Structure of an quarto document",
    "text": "4.3 Structure of an quarto document\nCreate a new .qmd file using File -&gt; New File -&gt; Quarto Document and save that file in your project directory as Lastname_IntroR.qmd.\nAn qmd-file consists of three components:\n\nHeader: written in YAML format the header contains all the information on how to render the .qmd file.\nMarkdown Sections: written in Rmarkdown syntax.\nCode chunks: Chunks of R code (or other code such as bash, python, …). These can be run interactively while generating your document and will be rendered when knitting the document."
  },
  {
    "objectID": "04_Rproj.html#yaml-header",
    "href": "04_Rproj.html#yaml-header",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.4 YAML header",
    "text": "4.4 YAML header\nThe header is written in YAML syntax, it begins and ends with ---. It will include a few default parameters. You will find that there is a wide range of parameters that you can use to customize the look of your document but for now we will add these four.\n\n---\ntitle: \"title\"\nauthor: \"name\"\ndate: \"Date\"\nformat: html\n----\n\nCustomize your .qmd by changing the title and add your name in the author line10. Changing the date to `r Sys.Date()` will automatically include the current date when you render the document instead of having to update that yourself.10 You can always do this when you start a new file, for a lot of case studies this semester you will download quarto documents where you will want to change those"
  },
  {
    "objectID": "04_Rproj.html#markdown-sections",
    "href": "04_Rproj.html#markdown-sections",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.5 Markdown sections",
    "text": "4.5 Markdown sections\nYour markdown sections can contain any text you want using the markdown syntax; once you render the .qmd the resulting (html) file will appear as text.\nMost of your text (without syntax) will appear as paragraph text but you can add additional syntax to format it in different ways.\nHere are the basics that are fairly consistent across a range of markdown flavors:\nText formatting\n\n*italic* **bold** ~~strikeout~~ `code`\n\nsuperscript^2^ subscript~2~\n\n[underline]{.underline} [small caps]{.smallcaps}\n\nHeadings\n\n# 1st Level Header\n\n## 2nd Level Header\n\n### 3rd Level Header\n\nLists\n\n-   Bulleted list item 1\n\n-   Item 2\n\n    -   Item 2a\n\n    -   Item 2b\n    \n\n1.  Numbered list item 1\n\n2.  Item 2.\n    The numbers are incremented automatically in the output.\n    \nLinks and images\n\n&lt;http://example.com&gt;\n\n[linked phrase](http://example.com)\n\n![optional caption text](quarto.png){fig-alt=\"Quarto logo and the word quarto spelled in small case letters\"}\n\nTables\n\n| First Header | Second Header |\n|--------------|---------------|\n| Content Cell | Content Cell  |\n| Content Cell | Content Cell  |\n\n\n\n\n\n\n\n\nNote\n\n\n\nCurrent Rstudio versions do have a visual editor that is WYSIWYG11 and will allow you to format your document similar to the way you would in Google Docs or Microsoft Word. However, it is helpful to know the basics because de-bugging can be more straightforward using the Source Editor, and if you are comfortable with the syntax it is also a lot faster to format.\n\n\n11 What you see is what you get"
  },
  {
    "objectID": "04_Rproj.html#code-chunks",
    "href": "04_Rproj.html#code-chunks",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.6 Code chunks",
    "text": "4.6 Code chunks\nCode chunks contain your R code and start and end with three back ticks; {r} determines that the code chunk should be interpreted as R code.\n\n\n\nYou can type it in manually but it is a lot quicker to add a code chunk using the shortcut Ctrl + Alt + I on a Windows computer or Command + Option + I for you Mac users.\n\n\n\n\n\n\nNote\n\n\n\nYou can also insert a code chunk using Code -&gt; Insert Chunk in the tool bar, the insert button in the tab bar (little green box with C and +) or if you are in the visual editor, your can use insert button in the editor bar.\nIn short, there is no excuse not to be adding code chunks and writing code!\n\n\nYou can run (execute) entire code chunks entire chunk by clicking the Run button in the tab bar or the little green arrow in the top right corner of an R chunk.\nIt is a lot faster to use shortcuts. You can execute and entire code chunk using Cmd/Ctrl + Shift + Enter. Or if you only want to execute a certain piece of code, using Cmd/Ctrl + Enter while your cursor is placed within that code, or highlight the code you want to execute and then hit Cmd/Ctrl + Enter.\nRemember to use # to comment your code, any lines following a # will not be run by R, you can use them to describe what your code is doing. Use comments liberally to document your code, future you will thank you!\n\n\n\n\n\n\nNote\n\n\n\nBefore submitting any of your skills tests or homework assignments you should always go through and make sure each piece of code has a descriptive comment. You do not need to add a comment for multi-line code that you are stringing together using a pipe %&gt;% but you should have one descriptive comment above the set of commands you are giving R and then make sure that you add any comments that you need to remember how the function works or which parameters might be useful to tweak/set differently if you were to reuse that code.\n\n\nOptionally you can add a label to your code chunks that can be used to navigate directly to code chunks using the drop-down menu in the bottom left of the script editor.\n\n```{r}\n#| label: code-label-1\n\n1 + 1\n```\n\n[1] 2\n\n\nIf you do this for figures or tables you can start your labels with fig- or tbl- which will allow them to be automatically numbered and you can link to them later in your document. Labels cannot be repeated (i.e. they all must be unique) and cannot have spaces, best practice here would be using dashes (-) to separate words.\nYou can add options to each code chunk to customize how/if a chunk is executed and appears in the rendered output. These options are added to within the curly brackets. For example, eval: false: results in code chunk not being evaluated or run though it will still be rendered in the knitted document12. You can apply multiple options to the same chunk.12 This can be useful for you if e.g. for one of your skill tests you cannot solve one of the challenges and the document will not render because your code won’t run, this way you can show you attempt but also run the document\n\n```{r}\n#| label: code-label-2\n#| eval: false\n\n1 + 1\n```\n\nYou do have options to add figure and table captions, you can also e.g. control figure width and height. See section in r4ds (2e) Chapter 29 for a list of commonly used code options and you can find additional options here."
  },
  {
    "objectID": "04_Rproj.html#render-your-document",
    "href": "04_Rproj.html#render-your-document",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.7 Render your document",
    "text": "4.7 Render your document\nknitr is an R package used to render quarto documents to another format (usually html or pdf). In Rstudio the most straightforward way of knitting a document is using the render button in the editor toolbar. This will open a new tab in your console titled Background Jobs that will show the knitting process; any errors that occur with show up here along with a line number so you can determine where the error is occurring in your .qmd file to troubleshoot the issue. The output will automatically be saved in your working directory."
  },
  {
    "objectID": "04_Rproj.html#some-advanced-options",
    "href": "04_Rproj.html#some-advanced-options",
    "title": "4  Project management and Rmarkdown Basics",
    "section": "4.8 Some advanced options",
    "text": "4.8 Some advanced options\nYou can stylize your rendered document by modifying the YAML header to include a table of contents like this13:13 the option of toc-depth determines how many levels are included in the table of contents, e.g. here headers at level 1 and 2 will be included\n---\nformat:\n  html:\n    toc: true\n    toc-depth: 2\n---\nIf you really want to jazz things up, you can change the theme14.14 you can choose from various options here\n---\nformat:\n  html:\n    theme: cosmo\n    toc: true\n    toc-depth: 2\n---\nYou may be noticing some similarities between this lab manual and the documents you are producing in terms of layout … for exactly the reasons you are suspecting!"
  }
]